[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lectures from MTH 142 Fall 2024",
    "section": "",
    "text": "These are the lectures from MTH 142, you can also find the direct links via Canvas.\nLecture 1 Statistical Thinking\nLecture 2 Study Design and Variables\nLecture 3 Categorical Data\nLecture 4 Numeric Data\nLecture 5 Linear Correlation\nLecture 6 Linear Correlation\nLecture 7 Regression math\nLecture 8 Probability\nLecture 9 Probability 2\nLecture 10 Continuous Random Variables\nLecture 11 The Normal Distribution\nLecture 12 Hypothesis Testing Proportion\nLecture 13 Parametric bootstrap Hypothesis Testing\nLecture 14 Confidence Intervals with Math\nLecture 15 Visualizing the CLT\nLecture 16 Distributions and Two Proportions\nLecture 17 Decision Errors\nLecture 18 Hypothesis Test for a single mean\nLecture 19 Hypothesis Test for a difference of means (unpaired)\nLecture 20 ANOVA\nLecture 21 Regression with a Single Predictor"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#this-is-a-bonus-lecture",
    "href": "lectures/7_regression-by-hand.html#this-is-a-bonus-lecture",
    "title": "Regression Math",
    "section": "This is a bonus lecture",
    "text": "This is a bonus lecture\nThis is a lecture to explain the math behind linear regression.\nIt is not necessary to watch it and you do not need it to complete the course."
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#we-will-do-three-things",
    "href": "lectures/7_regression-by-hand.html#we-will-do-three-things",
    "title": "Regression Math",
    "section": "We will do three things",
    "text": "We will do three things\n\nFind the slope of the linear model using standard deviations\nMake the linear model considering \\(\\overline{x}\\) and \\(\\overline{y}\\)\nFind \\(R^2\\) from a simple ratio of the \\(s_y\\) and \\(s_e\\)"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#find-slope-of-the-linear-model",
    "href": "lectures/7_regression-by-hand.html#find-slope-of-the-linear-model",
    "title": "Regression Math",
    "section": "Find slope of the linear model",
    "text": "Find slope of the linear model\n\n\n\\(b=\\frac{s_y}{s_x}r\\)\n\\(s_y\\) is the sample standard deviation in the y values.\n\\(s_x\\) is the sample standard deviation in the x values.\n\\(r\\) is the correlation coefficient.\nWe know these values from the last video."
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#recall",
    "href": "lectures/7_regression-by-hand.html#recall",
    "title": "Regression Math",
    "section": "Recall",
    "text": "Recall\nWe can get our std.errors and r:\n\ncats |&gt;\n  summarize(\n    r = cor( Hwt, Bwt ),\n    r2 =  (cor( Hwt, Bwt ))^2,\n    sd_y = sd(Hwt),\n    sd_x = sd(Bwt)\n  )\n\n          r        r2     sd_y      sd_x\n1 0.8041274 0.6466209 2.434636 0.4853066"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#we-are-lucky",
    "href": "lectures/7_regression-by-hand.html#we-are-lucky",
    "title": "Regression Math",
    "section": "We are lucky",
    "text": "We are lucky\nTo find the sample standard deviation in the past people had to use this:"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#slope-calculation",
    "href": "lectures/7_regression-by-hand.html#slope-calculation",
    "title": "Regression Math",
    "section": "Slope calculation",
    "text": "Slope calculation\n\\(m = b_1 = \\frac{s_y}{s_x} r=\\frac{2.434}{0.485}(0.804)=4.035\\)\nWe still don’t know how to find r"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#the-means-are-on-the-regression-line.",
    "href": "lectures/7_regression-by-hand.html#the-means-are-on-the-regression-line.",
    "title": "Regression Math",
    "section": "The means are on the regression line.",
    "text": "The means are on the regression line.\n\\(\\overline{x}\\) and \\(\\overline{y}\\) are on the regression line \\(\\hat{y}\\)\n\ncats |&gt;\n  summarize(\n    mean_y = mean(Hwt),\n    mean_x = mean(Bwt)\n  )\n\n    mean_y   mean_x\n1 10.63056 2.723611"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#solve-for-the-intercept",
    "href": "lectures/7_regression-by-hand.html#solve-for-the-intercept",
    "title": "Regression Math",
    "section": "Solve for the intercept",
    "text": "Solve for the intercept\nNow we plug everything into the equation of a line and solve for \\(b_0\\)\nI’m rounding for ease.\n\\(\\hat{y} = b_0 + b_1 x\\)\n\\(10.631 = b_0 + 4.035 (2.724)\\)\n\\(10.631 = b_0 + 10.991\\)\n\\(- 0.36 = b_0\\)\nSo our line is: \\(\\hat{y} = - 0.36 + 4.03 x\\) or\n\\(\\widehat{Hwt} = -0.36+ 4.03 \\text{Bwt}\\)"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#those-are-the-same-numbers-we-had-before",
    "href": "lectures/7_regression-by-hand.html#those-are-the-same-numbers-we-had-before",
    "title": "Regression Math",
    "section": "Those are the same numbers we had before",
    "text": "Those are the same numbers we had before\n\n\n\nCall:\nlm(formula = Hwt ~ Bwt, data = cats)\n\nCoefficients:\n(Intercept)          Bwt  \n    -0.3567       4.0341"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#standard-deviation-of-residuals",
    "href": "lectures/7_regression-by-hand.html#standard-deviation-of-residuals",
    "title": "Regression Math",
    "section": "Standard Deviation of Residuals",
    "text": "Standard Deviation of Residuals\n\ncat_model_aug &lt;- augment(cat_model)\ntidy(cat_model_aug)\n\n# A tibble: 8 × 13\n  column         n     mean      sd   median  trimmed     mad        min     max\n  &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;\n1 Hwt          144 1.06e+ 1 2.43    10.1     10.5     1.55       6.3 e+0 20.5   \n2 Bwt          144 2.72e+ 0 0.485    2.7      2.69    0.4        2   e+0  3.9   \n3 .fitted      144 1.06e+ 1 1.96    10.5     10.5     1.61       7.71e+0 15.4   \n4 .resid       144 7.55e-15 1.45    -0.0921  -0.0473  1.04      -3.57e+0  5.12  \n5 .hat         144 1.39e- 2 0.00797  0.0117   0.0125  0.00384    6.96e-3  0.0480\n6 .sigma       144 1.45e+ 0 0.00789  1.46     1.45    0.00203    1.39e+0  1.46  \n7 .cooksd      144 9.15e- 3 0.0298   0.00307  0.00448 0.00253    1.01e-6  0.330 \n8 .std.resid   144 5.37e- 4 1.01    -0.0637  -0.0325  0.719     -2.50e+0  3.62  \n# ℹ 4 more variables: range &lt;dbl&gt;, skew &lt;dbl&gt;, kurtosis &lt;dbl&gt;, se &lt;dbl&gt;"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#we-are-lucky-again",
    "href": "lectures/7_regression-by-hand.html#we-are-lucky-again",
    "title": "Regression Math",
    "section": "We are lucky again",
    "text": "We are lucky again\nTo find the standard deviation in the past people had to use this:"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#to-calculate-r2",
    "href": "lectures/7_regression-by-hand.html#to-calculate-r2",
    "title": "Regression Math",
    "section": "To calculate \\(R^2\\)",
    "text": "To calculate \\(R^2\\)\nThe book shows an equivalent method to do this. Using SST and SSE.\n\\(r^2=0.65=65\\%\\)\n“65% in the variation of Heart Weight can be explained by the Body Weight”\nRounding again for ease.\n\\(R^2 = \\frac{s_y-s_e}{s_y} = \\frac{2.4^2-1.4^2}{2.4^2} \\approx 0.65\\)\n\\(r=\\sqrt{0.65}\\approx 0.80\\)"
  },
  {
    "objectID": "lectures/7_regression-by-hand.html#try-problem-22",
    "href": "lectures/7_regression-by-hand.html#try-problem-22",
    "title": "Regression Math",
    "section": "Try Problem 22",
    "text": "Try Problem 22"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#homework-notes",
    "href": "lectures/6_Linear_regression_part_2.html#homework-notes",
    "title": "Linear Regression part 2",
    "section": "Homework notes",
    "text": "Homework notes"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#copy-and-paste-into-r",
    "href": "lectures/6_Linear_regression_part_2.html#copy-and-paste-into-r",
    "title": "Linear Regression part 2",
    "section": "Copy and paste into r",
    "text": "Copy and paste into r\nUse c() function. Add commas. (Note we all have different numbers)\n\nColesterol_Lvl &lt;- c(\n244,\n278,\n272,\n160,\n226,\n210,\n318,\n236,\n186,\n142,\n360,\n288,\n220,\n206,\n282,\n270,\n282,\n234,\n266,\n276,\n294,\n224,\n310,\n242,\n236,\n288)"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#cats-hearts",
    "href": "lectures/6_Linear_regression_part_2.html#cats-hearts",
    "title": "Linear Regression part 2",
    "section": "Cats’ hearts",
    "text": "Cats’ hearts\n\nYou stole Meow Heart"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#a-big-heart-may-cause-problems",
    "href": "lectures/6_Linear_regression_part_2.html#a-big-heart-may-cause-problems",
    "title": "Linear Regression part 2",
    "section": "A big heart may cause problems",
    "text": "A big heart may cause problems\nFinding the size of a cat’s heart is hard.\nEstimate with a model a model."
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#data-from-the-40s",
    "href": "lectures/6_Linear_regression_part_2.html#data-from-the-40s",
    "title": "Linear Regression part 2",
    "section": "Data from the 40s",
    "text": "Data from the 40s\nThis data cites this source, which you may be inclined to look over.\n\n\nCode\nlibrary(tidyverse)\n\n#install.packages(\"MASS\")\n#library(MASS)\ncats &lt;- read_csv(\"cats.csv\")"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#look-at-data",
    "href": "lectures/6_Linear_regression_part_2.html#look-at-data",
    "title": "Linear Regression part 2",
    "section": "Look at data",
    "text": "Look at data\n\n?cats\n\nNo documentation for 'cats' in specified packages and libraries:\nyou could try '??cats'\n\ntail(cats,6)\n\n# A tibble: 6 × 3\n  Sex     Bwt   Hwt\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 M       3.6  15  \n2 M       3.7  11  \n3 M       3.8  14.8\n4 M       3.8  16.8\n5 M       3.9  14.4\n6 M       3.9  20.5"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#which-variable-is-which",
    "href": "lectures/6_Linear_regression_part_2.html#which-variable-is-which",
    "title": "Linear Regression part 2",
    "section": "Which variable is which?",
    "text": "Which variable is which?\nWhich should be the predictor and response variables?"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#plot",
    "href": "lectures/6_Linear_regression_part_2.html#plot",
    "title": "Linear Regression part 2",
    "section": "Plot",
    "text": "Plot"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#describe-trend",
    "href": "lectures/6_Linear_regression_part_2.html#describe-trend",
    "title": "Linear Regression part 2",
    "section": "Describe Trend",
    "text": "Describe Trend\n\nShape\nDirection\nStrength"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#add-a-regression-line",
    "href": "lectures/6_Linear_regression_part_2.html#add-a-regression-line",
    "title": "Linear Regression part 2",
    "section": "Add a regression line",
    "text": "Add a regression line\nand some labels.\n\nggplot(data = cats, aes(x = Bwt, y = Hwt))+\n  geom_point(aes(color=Sex) )+\n  geom_smooth(method = lm, se = FALSE) +\n  xlab(\"Body Weight in Kg\") +\n  ylab(\"Heart Weight in Grams\")"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#find-correlation-coefficient",
    "href": "lectures/6_Linear_regression_part_2.html#find-correlation-coefficient",
    "title": "Linear Regression part 2",
    "section": "Find correlation coefficient",
    "text": "Find correlation coefficient\n\nsummarize(.data= cats , r = cor(Bwt, Hwt, use=\"complete.obs\"))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.804"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#find-the-coefficents",
    "href": "lectures/6_Linear_regression_part_2.html#find-the-coefficents",
    "title": "Linear Regression part 2",
    "section": "Find the coefficents",
    "text": "Find the coefficents\n\n#install.packages(\"broom\")\nlibrary(broom)\ncat_model &lt;- lm(Hwt ~ Bwt, data = cats)\ntidy(cat_model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -0.357     0.692    -0.515 6.07e- 1\n2 Bwt            4.03      0.250    16.1   6.97e-34"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#the-equation",
    "href": "lectures/6_Linear_regression_part_2.html#the-equation",
    "title": "Linear Regression part 2",
    "section": "The Equation",
    "text": "The Equation\nIntercept is the y-intercept of our linear model (\\(\\beta_0 = -0.36\\)).\nThe number next to Bwt is the slope (\\(\\beta_1 = 4.03\\)).\nThe equations is: \\[\n\\hat{y} = \\beta_0 + \\beta_1 x \\\\\n\\text{or} \\\\\n\\widehat{Hwt} = -0.36 + 4.03 \\times Bwt \\]"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#summary",
    "href": "lectures/6_Linear_regression_part_2.html#summary",
    "title": "Linear Regression part 2",
    "section": "Summary",
    "text": "Summary\n Stolen from Prof Kurtz Garcia at Smith College"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#interpretation",
    "href": "lectures/6_Linear_regression_part_2.html#interpretation",
    "title": "Linear Regression part 2",
    "section": "Interpretation",
    "text": "Interpretation\nSlope: For every kilogram increase in body weight we expect a 4.03 gram increase in the heart weight.\nIntercept: If we found a cat they weighed nothing its heart would be -0.36 grams?"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#more-complete-outputs",
    "href": "lectures/6_Linear_regression_part_2.html#more-complete-outputs",
    "title": "Linear Regression part 2",
    "section": "More Complete outputs",
    "text": "More Complete outputs\n\n# Alternative to tidy()\nsummary(cat_model)\n\n\nCall:\nlm(formula = Hwt ~ Bwt, data = cats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5694 -0.9634 -0.0921  1.0426  5.1238 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.3567     0.6923  -0.515    0.607    \nBwt           4.0341     0.2503  16.119   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.452 on 142 degrees of freedom\nMultiple R-squared:  0.6466,    Adjusted R-squared:  0.6441 \nF-statistic: 259.8 on 1 and 142 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#if-a-cat-weighs",
    "href": "lectures/6_Linear_regression_part_2.html#if-a-cat-weighs",
    "title": "Linear Regression part 2",
    "section": "If a cat weighs:",
    "text": "If a cat weighs:\n\n\n3.5 kg how large a heart would we expect?\nCan we estimate the heart size for a 5kg cat?\n\nCaution against extrapolation."
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#due-diligence",
    "href": "lectures/6_Linear_regression_part_2.html#due-diligence",
    "title": "Linear Regression part 2",
    "section": "Due Diligence",
    "text": "Due Diligence\nCheck for normal residual distribution\nCheck for residual linearity"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#linearity-of-the-residuals",
    "href": "lectures/6_Linear_regression_part_2.html#linearity-of-the-residuals",
    "title": "Linear Regression part 2",
    "section": "Linearity of the residuals",
    "text": "Linearity of the residuals\nAre the residuals close to the zero?\n\n#install.packages(\"broom\")\nlibrary(broom)\n\ncat_model_aug &lt;- augment(cat_model)\n\n\nggplot(data = cat_model_aug, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  xlab(\"Fitted values\") +\n  ylab(\"Residuals\")"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#normal-distributions-of-residuals",
    "href": "lectures/6_Linear_regression_part_2.html#normal-distributions-of-residuals",
    "title": "Linear Regression part 2",
    "section": "Normal distributions of residuals",
    "text": "Normal distributions of residuals\n\nggplot(data = cat_model_aug, aes(x = .resid)) +\n  geom_histogram(binwidth = 0.25) +\n  xlab(\"Residuals\")\n\n\nThe data looks roughly normal."
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#citations",
    "href": "lectures/6_Linear_regression_part_2.html#citations",
    "title": "Linear Regression part 2",
    "section": "Citations",
    "text": "Citations\nStreet cats from https://petlifesa.com/wp-content/uploads/2019/08/SA0057-Petlifesa-health-conditions-diseases-heart-disease-facts-about-your-cats-heart-Header-FA.jpg\nYou stole Meow Heart https://drbillspetnutrition.com/feline-heart-conditions/"
  },
  {
    "objectID": "lectures/8_Probability_1.html#read-before-hand",
    "href": "lectures/8_Probability_1.html#read-before-hand",
    "title": "Probability part 1",
    "section": "Read before hand:",
    "text": "Read before hand:\nOpen Intro Statistics Chapter 3.1."
  },
  {
    "objectID": "lectures/8_Probability_1.html#the-law-of-large-numbers",
    "href": "lectures/8_Probability_1.html#the-law-of-large-numbers",
    "title": "Probability part 1",
    "section": "The Law of Large numbers",
    "text": "The Law of Large numbers\nThe theoretical probability of getting a heads is 0.5 on a coin.\nLet’s test it empirically.\nFlip a coin\nVisualize the law of large numbers"
  },
  {
    "objectID": "lectures/8_Probability_1.html#empirical-vs-theoretical-probabilities",
    "href": "lectures/8_Probability_1.html#empirical-vs-theoretical-probabilities",
    "title": "Probability part 1",
    "section": "Empirical vs Theoretical Probabilities",
    "text": "Empirical vs Theoretical Probabilities\n\nWe just found the probability of flipping a coin empirically.\nWe know what it is in theory. ( 0.5)\nToday we will discuss theoretical probabilities."
  },
  {
    "objectID": "lectures/8_Probability_1.html#probability",
    "href": "lectures/8_Probability_1.html#probability",
    "title": "Probability part 1",
    "section": "Probability",
    "text": "Probability\n\nThe probability of an event is the proportion of times we would see the event occur if the process could happen an infinite number of times.\n\nConsider a fair six sided die.\nEvent A = Rolling a 4.\nA random variable X might be:\n\nX~The number that shows up on a die."
  },
  {
    "objectID": "lectures/8_Probability_1.html#rolling-a-4",
    "href": "lectures/8_Probability_1.html#rolling-a-4",
    "title": "Probability part 1",
    "section": "Rolling a 4",
    "text": "Rolling a 4\nThere are 6 possible outcomes so the\n\nSample space = {1,2,3,4,5,6 } = \\(\\Omega\\)\n\nWe want 1 outcome of the 6.\n\nP(Rolling a 4) = P( X = 4) = \\(\\frac{1}{6}\\)"
  },
  {
    "objectID": "lectures/8_Probability_1.html#not-rolling-a-4.",
    "href": "lectures/8_Probability_1.html#not-rolling-a-4.",
    "title": "Probability part 1",
    "section": "Not rolling a 4.",
    "text": "Not rolling a 4.\nWe want 5 outcomes of the 6.\n\\(\\Omega = \\{1,2,3,4,5,6 \\}\\)\n\nP(Not Rolling a 4) = \\(P( X \\ne 4) = \\frac{5}{6}\\)\n\nThis is called the complement and is denoted \\(\\bar{A}\\)"
  },
  {
    "objectID": "lectures/8_Probability_1.html#simulate-die-rolling-in-r",
    "href": "lectures/8_Probability_1.html#simulate-die-rolling-in-r",
    "title": "Probability part 1",
    "section": "Simulate die rolling in R",
    "text": "Simulate die rolling in R\n(optional code)\n\n# This is to get consistent answers. \nset.seed(1)\n\n# Roll the die once\nsample(x = c(1,2,3,4,5,6), size = 1, replace = TRUE)\n\n[1] 1\n\n# Roll the die 1000 times and keep the number of 4s. \nthousand_rolls = sample(x = c(1,2,3,4,5,6), size = 10000, replace = TRUE)\n\n# Check to see if each value equals 4. If it does equal 4 a 1 is returned, if not a zero.\nsum(thousand_rolls == 4)\n\n[1] 1701\n\n# Number of fours from our simulation\n1701/10000\n\n[1] 0.1701\n\n#Theoredical probability\n1/6\n\n[1] 0.1666667"
  },
  {
    "objectID": "lectures/8_Probability_1.html#an-event-and-its-complement",
    "href": "lectures/8_Probability_1.html#an-event-and-its-complement",
    "title": "Probability part 1",
    "section": "An event and its complement",
    "text": "An event and its complement\nAn event and its complement sum to 1.\n\\(P(A) + P(\\bar{A}) = 1\\)"
  },
  {
    "objectID": "lectures/8_Probability_1.html#you-try",
    "href": "lectures/8_Probability_1.html#you-try",
    "title": "Probability part 1",
    "section": "You try",
    "text": "You try\nWe are rolling two fair die.\n\nWhat is the theoretical probability their sum is 7? Call this event B.\n\nHere is the sample space 1\n\nWrite the event and the probability notation.\nFind the compliment of the value above.\n\nDo this by hand.\nhttps://spreadsheetsolving.com/probabilities-dice-simulations/"
  },
  {
    "objectID": "lectures/8_Probability_1.html#disjoint-mutually-exclusive-events",
    "href": "lectures/8_Probability_1.html#disjoint-mutually-exclusive-events",
    "title": "Probability part 1",
    "section": "Disjoint (Mutually Exclusive) Events",
    "text": "Disjoint (Mutually Exclusive) Events\n\nTwo events that cannot happen simultaneously.\n\nConsider the single six sided die.\nA = Rolling a 3\nB = Rolling an even number\n\n\\(P(A \\text{ and } B) = 0\\)\n\\(P(A \\text{ or } B) = \\frac{1}{6}+\\frac{3}{6}\\)"
  },
  {
    "objectID": "lectures/8_Probability_1.html#what-is-disjoint-with",
    "href": "lectures/8_Probability_1.html#what-is-disjoint-with",
    "title": "Probability part 1",
    "section": "What is disjoint with?",
    "text": "What is disjoint with?\n\n\nA = Flipping heads on a coin\nB = Going to class\nC = Eating a cheeseburger"
  },
  {
    "objectID": "lectures/8_Probability_1.html#what-is-not-disjoint-with",
    "href": "lectures/8_Probability_1.html#what-is-not-disjoint-with",
    "title": "Probability part 1",
    "section": "What is not disjoint with?",
    "text": "What is not disjoint with?\n\nA = Flipping heads on a coin\nB = Going to class\nC = Eating a cheeseburger"
  },
  {
    "objectID": "lectures/8_Probability_1.html#independence",
    "href": "lectures/8_Probability_1.html#independence",
    "title": "Probability part 1",
    "section": "Independence",
    "text": "Independence\n\nTwo outcomes are independent if knowing the outcome of one gives no useful information about the other.\n\n\nI flip a tails on a coin. Does that tell me the probability of the next flip?\nI pull an Ace of Spades from a deck but don’t replace it. Does that tell me about the probability of the next card I pull?\nOne person in class is left handed does that effect the probability of another person being left handed."
  },
  {
    "objectID": "lectures/8_Probability_1.html#an-incomplete-list-of-formulas",
    "href": "lectures/8_Probability_1.html#an-incomplete-list-of-formulas",
    "title": "Probability part 1",
    "section": "An incomplete list of formulas",
    "text": "An incomplete list of formulas\n\nAddition Rule \\(P(A \\text{ or } B) = P(A) + P(B) - P(A \\text{ and } B)\\)\nRules for probability distributions.\nMultiplication rule for independence. \\(P(A \\text{ and } B) = P(A) \\times P(B)\\)\n\nYou’ve read chapter 3.1 and made note of these formulas."
  },
  {
    "objectID": "lectures/8_Probability_1.html#try-some-for-practice",
    "href": "lectures/8_Probability_1.html#try-some-for-practice",
    "title": "Probability part 1",
    "section": "Try some for practice:",
    "text": "Try some for practice:\nOI: 3.2, 3.5, 3.11"
  },
  {
    "objectID": "lectures/9_Probability_2.html#probability-functions",
    "href": "lectures/9_Probability_2.html#probability-functions",
    "title": "Random Variables",
    "section": "Probability Functions",
    "text": "Probability Functions\n\\(0&lt;P(x_i)&lt;1\\)\n\\(\\sum_i P(x_i) = 1\\)"
  },
  {
    "objectID": "lectures/9_Probability_2.html#process-vs-variable",
    "href": "lectures/9_Probability_2.html#process-vs-variable",
    "title": "Random Variables",
    "section": "Process vs Variable",
    "text": "Process vs Variable\n\n\n\n\n\n\n\nRandom Process\nRandom Variable\n\n\n\n\nRolling a two six sided die\nX = Sum of faces\n\n\nFlip a coin 10 times\nX = # Number of Tails\n\n\nBody Dimensions\nX = Foot size\nY = Neck Circumference Z = Height"
  },
  {
    "objectID": "lectures/9_Probability_2.html#random-variables",
    "href": "lectures/9_Probability_2.html#random-variables",
    "title": "Random Variables",
    "section": "Random variables",
    "text": "Random variables\n\n\nAre like functions that map onto the real line\nOften given the names X, Y, and Z\nCapital X is the name of the variable\nLowercase x is the value the variable takes\nType of Random variables:\n\nContinuous Random Variables\nDiscrete Random Variables"
  },
  {
    "objectID": "lectures/9_Probability_2.html#discrete-random-variables",
    "href": "lectures/9_Probability_2.html#discrete-random-variables",
    "title": "Random Variables",
    "section": "Discrete Random Variables",
    "text": "Discrete Random Variables\nGet a Probability Mass Function\nStates their probability of any value of x\n\nExample: Value of face on a die"
  },
  {
    "objectID": "lectures/9_Probability_2.html#continuous-random-variables",
    "href": "lectures/9_Probability_2.html#continuous-random-variables",
    "title": "Random Variables",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\nGet a Probability Density Function\nThis states there probability for any value less than or grater than little x.\n\nHeight"
  },
  {
    "objectID": "lectures/9_Probability_2.html#optional-material",
    "href": "lectures/9_Probability_2.html#optional-material",
    "title": "Random Variables",
    "section": "Optional Material",
    "text": "Optional Material\nIf you are interested in further studying statistics, data science or math you should go through the next few slides with me.\nIt is not required for this course."
  },
  {
    "objectID": "lectures/9_Probability_2.html#expectation",
    "href": "lectures/9_Probability_2.html#expectation",
    "title": "Random Variables",
    "section": "Expectation",
    "text": "Expectation\nExpectation is another word for average.\n\n\nIt is \\(E[X] = \\sum_i P(x_i) x_i\\)\nLet’s make a probability model for X = The value on the face of a dice.\nLet’s graph the model.\nThen let’s calculate its expectation."
  },
  {
    "objectID": "lectures/9_Probability_2.html#variance",
    "href": "lectures/9_Probability_2.html#variance",
    "title": "Random Variables",
    "section": "Variance",
    "text": "Variance\nThe Variance is given by the following formula.\n\\(V[X] = E[(X-\\mu)^2] = \\sum_i (x_i-\\mu)^2 P(X=x_i)\\)\nLet’s calculate the variance of the variable X from the previous slide."
  },
  {
    "objectID": "lectures/9_Probability_2.html#you-try",
    "href": "lectures/9_Probability_2.html#you-try",
    "title": "Random Variables",
    "section": "You try",
    "text": "You try\nWrite the random variable.\nFind the expectation for the sum of two die.\nWrite the probability model (as a table or graph).\nHere is the sample space for rolling two die 1\nhttps://spreadsheetsolving.com/probabilities-dice-simulations/"
  },
  {
    "objectID": "lectures/9_Probability_2.html#examples",
    "href": "lectures/9_Probability_2.html#examples",
    "title": "Random Variables",
    "section": "Examples",
    "text": "Examples\nProblem 3.30"
  },
  {
    "objectID": "lectures/10-Probability_Wrap_Up.html#general-multiplication-rule",
    "href": "lectures/10-Probability_Wrap_Up.html#general-multiplication-rule",
    "title": "Probability Wrap up",
    "section": "General Multiplication Rule:",
    "text": "General Multiplication Rule:\n\\(P(A \\text{ and } B) = P(A|B)P(B)\\)"
  },
  {
    "objectID": "lectures/10-Probability_Wrap_Up.html#law-of-total-probability",
    "href": "lectures/10-Probability_Wrap_Up.html#law-of-total-probability",
    "title": "Probability Wrap up",
    "section": "Law of Total Probability:",
    "text": "Law of Total Probability:\n\\(P(A) = P(A|B_1)P(B_1)+P(A|B_2)P(B_2)+…+P(A|B_k)P(B_k)\\)\nWhere each \\(B_i\\) is disjoint."
  },
  {
    "objectID": "lectures/10-Probability_Wrap_Up.html#conditional-probability",
    "href": "lectures/10-Probability_Wrap_Up.html#conditional-probability",
    "title": "Probability Wrap up",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\\(P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\\)"
  },
  {
    "objectID": "lectures/11_continuous_rv.html#continuous-rv",
    "href": "lectures/11_continuous_rv.html#continuous-rv",
    "title": "Continuous RV",
    "section": "Continuous RV",
    "text": "Continuous RV\n\n\nA continuous random variable can take any numeric value.\n(Discrete can only take integers.)\nX- Face value of a die\nY- Sum of two die.\nX and Y are discrete r.v. because their outcomes are whole numbers."
  },
  {
    "objectID": "lectures/11_continuous_rv.html#height",
    "href": "lectures/11_continuous_rv.html#height",
    "title": "Continuous RV",
    "section": "Height",
    "text": "Height\nX- height (inches)\nX is a continuous random variable.\n(people usually report is as a discrete RV.)"
  },
  {
    "objectID": "lectures/11_continuous_rv.html#tanget-precision-matters",
    "href": "lectures/11_continuous_rv.html#tanget-precision-matters",
    "title": "Continuous RV",
    "section": "Tanget: Precision matters",
    "text": "Tanget: Precision matters\nWho is 65 inches tall?\nNone of us really know how tall we are exactly."
  },
  {
    "objectID": "lectures/11_continuous_rv.html#convenience-sample-on-heights",
    "href": "lectures/11_continuous_rv.html#convenience-sample-on-heights",
    "title": "Continuous RV",
    "section": "Convenience Sample on heights",
    "text": "Convenience Sample on heights\nLast semester my in person class told me how tall they are. I made a histogram of their heights."
  },
  {
    "objectID": "lectures/11_continuous_rv.html#probabilities-from-our-sample",
    "href": "lectures/11_continuous_rv.html#probabilities-from-our-sample",
    "title": "Continuous RV",
    "section": "Probabilities from our sample",
    "text": "Probabilities from our sample\nThere are 34 students in my sample (n = 34).\nTreat the data as discrete.\n\nEstimate the following probabilities.\n\nP( X &lt; 65 )\nP( 60 &lt; X &lt; 63 )\nP( X = 65 )\n\n\n\n\nheights\n59 61 62 63 64 65 66 67 68 69 70 71 \n 1  4  3  4  6  2  2  3  2  4  2  1"
  },
  {
    "objectID": "lectures/11_continuous_rv.html#cont.-height-histogram",
    "href": "lectures/11_continuous_rv.html#cont.-height-histogram",
    "title": "Continuous RV",
    "section": "Cont. Height Histogram",
    "text": "Cont. Height Histogram"
  },
  {
    "objectID": "lectures/11_continuous_rv.html#probability-height-questions",
    "href": "lectures/11_continuous_rv.html#probability-height-questions",
    "title": "Continuous RV",
    "section": "Probability Height Questions",
    "text": "Probability Height Questions\nLet’s pretend our sample is representative of all students\n\n\nP( X &lt; 65 )\nP( 60 &lt; X &lt; 63 )\nP( X = 65 )\n\nCannot be equal to exactly 1 number with continuous distributions. There is an \\(\\infty\\) number of values."
  },
  {
    "objectID": "lectures/11_continuous_rv.html#you-try.",
    "href": "lectures/11_continuous_rv.html#you-try.",
    "title": "Continuous RV",
    "section": "You try.",
    "text": "You try.\n3.37"
  },
  {
    "objectID": "lectures/11_continuous_rv.html#section",
    "href": "lectures/11_continuous_rv.html#section",
    "title": "Continuous RV",
    "section": "3.37",
    "text": "3.37"
  },
  {
    "objectID": "lectures/2_sampling.html#read-beforehand",
    "href": "lectures/2_sampling.html#read-beforehand",
    "title": "Intro to Study Vocabulary",
    "section": "Read beforehand",
    "text": "Read beforehand\nChapter 2 on Study Design"
  },
  {
    "objectID": "lectures/2_sampling.html#blue-whales",
    "href": "lectures/2_sampling.html#blue-whales",
    "title": "Intro to Study Vocabulary",
    "section": "Blue whales",
    "text": "Blue whales\nStudy: In Breeding in blue whales.\n\n\n\nNew York Times, 1/23/2024 photo cred: Burton Lim"
  },
  {
    "objectID": "lectures/2_sampling.html#some-info-on-blue-whales",
    "href": "lectures/2_sampling.html#some-info-on-blue-whales",
    "title": "Intro to Study Vocabulary",
    "section": "Some info on Blue whales:",
    "text": "Some info on Blue whales:\nn = 3500\nFour subspecies1:\n\nNorthern\nNorthern Indian Ocean\nPygmy blue whale\nAntarctic subspecies"
  },
  {
    "objectID": "lectures/2_sampling.html#population-vs-sample",
    "href": "lectures/2_sampling.html#population-vs-sample",
    "title": "Intro to Study Vocabulary",
    "section": "Population vs Sample",
    "text": "Population vs Sample\nThe population is all the Blue Whales left in the world\nThe sample is the 35 Blue Whales that have washed ashore."
  },
  {
    "objectID": "lectures/2_sampling.html#sampling-some",
    "href": "lectures/2_sampling.html#sampling-some",
    "title": "Studies",
    "section": "Sampling some",
    "text": "Sampling some\n\nSimple random sampling\nStratified sampling\nConvience sample"
  },
  {
    "objectID": "lectures/2_sampling.html#experimental-design",
    "href": "lectures/2_sampling.html#experimental-design",
    "title": "Intro to Study Vocabulary",
    "section": "Experimental Design",
    "text": "Experimental Design\n\nControl vs Treatment\nRandomization - Effect of Confounding Variables.\nReplication - Repeat experiments have the similar results."
  },
  {
    "objectID": "lectures/2_sampling.html#experiments-vs-observational-studies",
    "href": "lectures/2_sampling.html#experiments-vs-observational-studies",
    "title": "Intro to Study Vocabulary",
    "section": "Experiments vs Observational Studies",
    "text": "Experiments vs Observational Studies\n\nExperiments have a control\n\nUse for causal conclusions\n\nObservational Studies often gather information\n\nCannot be used for casual conclusions"
  },
  {
    "objectID": "lectures/2_sampling.html#variables",
    "href": "lectures/2_sampling.html#variables",
    "title": "Studies",
    "section": "Variables",
    "text": "Variables\nIf we suspect a causal relationship we have an explanatory (independent) and response variable (dependent).\n\nNegative relationship\nPositive Relationship\nNo Relationship"
  },
  {
    "objectID": "lectures/2_sampling.html#confounder-variables",
    "href": "lectures/2_sampling.html#confounder-variables",
    "title": "Intro to Study Vocabulary",
    "section": "Confounder Variables",
    "text": "Confounder Variables\nVariables that have an unanticipated effect on the study."
  },
  {
    "objectID": "lectures/2_sampling.html#you-try",
    "href": "lectures/2_sampling.html#you-try",
    "title": "Intro to Study Vocabulary",
    "section": "You try",
    "text": "You try\nChapter 2 2.12 and 2.20"
  },
  {
    "objectID": "lectures/2_sampling.html#solution-2.12",
    "href": "lectures/2_sampling.html#solution-2.12",
    "title": "Intro to Study Vocabulary",
    "section": "Solution 2.12",
    "text": "Solution 2.12\na. Observational Study. There is no control group.\nb. No we cannot see for sure if there is a link between stress and muscle cramps.\nc. It could be that (perhaps) there is a link between excess coffee and lack of sleep that causes cramps"
  },
  {
    "objectID": "lectures/2_sampling.html#solution-2.20",
    "href": "lectures/2_sampling.html#solution-2.20",
    "title": "Intro to Study Vocabulary",
    "section": "Solution 2.20",
    "text": "Solution 2.20\na. This was an experiment there is a control group (placebo).\nb. Explanatory is the quantity of vitamin C. The response is cold duration\nc. The patients were blind during their treatment, all pills look the same\nd. The study is not double blind as the nurses knew which patient got which pill\ne. A Confounding variable is whether a patient takes the pill."
  },
  {
    "objectID": "lectures/2_sampling.html#next-reading",
    "href": "lectures/2_sampling.html#next-reading",
    "title": "Intro to Study Vocabulary",
    "section": "Next Reading",
    "text": "Next Reading\nChapter 4 Exploring Categorical Data"
  },
  {
    "objectID": "lectures/2_sampling.html#sampling-strategies",
    "href": "lectures/2_sampling.html#sampling-strategies",
    "title": "Intro to Study Vocabulary",
    "section": "Sampling Strategies",
    "text": "Sampling Strategies\n\nSimple random sampling\nStratified sampling\nConvenience sample"
  },
  {
    "objectID": "lectures/2_sampling.html#explanatory-and-response",
    "href": "lectures/2_sampling.html#explanatory-and-response",
    "title": "Intro to Study Vocabulary",
    "section": "Explanatory and Response",
    "text": "Explanatory and Response\nIf we suspect a causal relationship we have an explanatory (independent) and response variable (dependent).\n\nNegative relationship\nPositive Relationship\nNo Relationship"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#read-before-lecture",
    "href": "lectures/5_linear_regression_1_predictor.html#read-before-lecture",
    "title": "Intro to Linear Regression",
    "section": "Read Before Lecture",
    "text": "Read Before Lecture\nChapter 7 Linear Regression with a single predictor"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#graph-of-arbuthonot",
    "href": "lectures/5_linear_regression_1_predictor.html#graph-of-arbuthonot",
    "title": "Intro to Linear Regression",
    "section": "Graph of Arbuthonot",
    "text": "Graph of Arbuthonot"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#scatterplot-for-two-numerical-variables",
    "href": "lectures/5_linear_regression_1_predictor.html#scatterplot-for-two-numerical-variables",
    "title": "Intro to Linear Regression",
    "section": "Scatterplot for two numerical variables",
    "text": "Scatterplot for two numerical variables\n\n\nresponse variable on \\(y\\)-axis and explanatory variable on \\(x\\)-axis\ngeom_point()\nWhat are we looking for?\n\nOverall patterns and deviations from those patterns\nForm (e.g. linear, quadratic, etc.), direction (positive or negative), and strength (how much scatter?)\nOutliers"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#you-try",
    "href": "lectures/5_linear_regression_1_predictor.html#you-try",
    "title": "Intro to Linear Regression",
    "section": "You try",
    "text": "You try\nFind the correlation coefficient for StarWars height vs mass. Hint: copy and edit the code from above."
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#solution-birthweight-of-babies",
    "href": "lectures/5_linear_regression_1_predictor.html#solution-birthweight-of-babies",
    "title": "Intro to Linear Regression",
    "section": "Solution: birthweight of babies",
    "text": "Solution: birthweight of babies\n\nggplot(data = babies, aes(x = gestation, y = bwt)) +\n  geom_point()\n\n\n\nhelp(babies)"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#your-turn",
    "href": "lectures/5_linear_regression_1_predictor.html#your-turn",
    "title": "Intro to Linear Regression",
    "section": "Your turn",
    "text": "Your turn\n\n\nUse a scatter plot to analyze the relationship between the height and mass of characters in the starwars data frame\nCharacterize the distribution\n\nForm\nDirection\nStrength\nOutliers"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#solution-starwars-characters-height-vs.-mass.",
    "href": "lectures/5_linear_regression_1_predictor.html#solution-starwars-characters-height-vs.-mass.",
    "title": "Intro to Linear Regression",
    "section": "Solution: starwars characters height vs. mass.",
    "text": "Solution: starwars characters height vs. mass.\nThere is one outlier, it is Jaba the Hut.\n\nggplot(data = starwars, aes(x = height, y = mass)) +\n  geom_point()"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#pearson-product-moment-correlation-coefficient",
    "href": "lectures/5_linear_regression_1_predictor.html#pearson-product-moment-correlation-coefficient",
    "title": "Intro to Linear Regression",
    "section": "(Pearson Product-Moment) correlation coefficient",
    "text": "(Pearson Product-Moment) correlation coefficient\n\n\nmeasure of the strength and direction of the linear relationship between two numerical variables\ndenoted \\(r\\)\nmeasured on the scale of \\([-1, 1]\\)\ncor(data1,data2,use = \"complete.obs\")\n\n\n\nhttps://en.wikipedia.org/wiki/Correlation"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#find-the-correlation-for-babies",
    "href": "lectures/5_linear_regression_1_predictor.html#find-the-correlation-for-babies",
    "title": "Intro to Linear Regression",
    "section": "Find the correlation for babies",
    "text": "Find the correlation for babies\n\nsummarise(.data = babies, r = cor(gestation,bwt,use=\"complete.obs\"))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.408"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#you-try-1",
    "href": "lectures/5_linear_regression_1_predictor.html#you-try-1",
    "title": "Intro to Linear Regression",
    "section": "You try",
    "text": "You try\nFind the correlation coefficient for StarWars height vs mass. Hint: copy and edit the code from above."
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#solution",
    "href": "lectures/5_linear_regression_1_predictor.html#solution",
    "title": "Intro to Linear Regression",
    "section": "Solution",
    "text": "Solution\n\nsummarise(.data = starwars, r = cor(height, mass ,use=\"complete.obs\"))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.131"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#filtering-out-outliers",
    "href": "lectures/5_linear_regression_1_predictor.html#filtering-out-outliers",
    "title": "Intro to Linear Regression",
    "section": "Filtering out outliers",
    "text": "Filtering out outliers\nWe might want to remove Jaba The Hut from the data. This is not something you need to know how to do. But if I filter data you are expected to graph it.\n\nfilter() out the one massive character and create a new df\nfind the new correlation coefficient"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#graph-the-new-starwars-scatter-plot",
    "href": "lectures/5_linear_regression_1_predictor.html#graph-the-new-starwars-scatter-plot",
    "title": "Intro to Linear Regression",
    "section": "Graph the new starwars scatter plot",
    "text": "Graph the new starwars scatter plot\n\nnew_starwars &lt;- filter(.data = starwars, mass &lt; 500)\nsummarise(.data = new_starwars, r = cor(height, mass ,use=\"complete.obs\"))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.751"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#add-the-regression-line-to-babies.",
    "href": "lectures/5_linear_regression_1_predictor.html#add-the-regression-line-to-babies.",
    "title": "Intro to Linear Regression",
    "section": "Add the regression line to babies.",
    "text": "Add the regression line to babies.\n\n#Filter out the babies born before 259 days. They are premature\nbabies &lt;- filter(.data = babies, gestation &gt; 259)\n\nggplot(data=babies, aes(x = gestation, y = bwt)) +\n  geom_point()+\n  geom_smooth(method = \"lm\", se=FALSE)"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#the-equation-of-that-regression.",
    "href": "lectures/5_linear_regression_1_predictor.html#the-equation-of-that-regression.",
    "title": "Intro to Linear Regression",
    "section": "The equation of that regression.",
    "text": "The equation of that regression.\n\n# Save the linear regression object. \nbaby_model &lt;- lm(bwt~gestation,data=babies)\n\n# Look at the summary output of that object. \ntidy(baby_model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    3.14    11.4        0.277 7.82e- 1\n2 gestation      0.419    0.0402    10.4   2.46e-24"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#add-the-regression-line-to-new_starwars",
    "href": "lectures/5_linear_regression_1_predictor.html#add-the-regression-line-to-new_starwars",
    "title": "Intro to Linear Regression",
    "section": "Add the regression line to new_starwars",
    "text": "Add the regression line to new_starwars\n\n\nDo you think it is fair to remove the outlier from starwars?\nCan we remove outliers from babies?"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#anscombe",
    "href": "lectures/5_linear_regression_1_predictor.html#anscombe",
    "title": "Intro to Linear Regression",
    "section": "Anscombe",
    "text": "Anscombe\n\n\n# A tibble: 4 × 5\n  set       N `mean(x)` `mean(y)` `cor(x, y)`\n  &lt;chr&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 1        11         9      7.50       0.816\n2 2        11         9      7.50       0.816\n3 3        11         9      7.5        0.816\n4 4        11         9      7.50       0.817\n\n\n\n\nsame mean\nsame standard deviation\nsame correlation coefficient is the same (up to three digits)!"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#anscombe-plots",
    "href": "lectures/5_linear_regression_1_predictor.html#anscombe-plots",
    "title": "Intro to Linear Regression",
    "section": "Anscombe plots",
    "text": "Anscombe plots\n\nggplot(data = ds, aes(x = x, y = y)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = 0) + \n  facet_wrap(~set)"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#datasaurus",
    "href": "lectures/5_linear_regression_1_predictor.html#datasaurus",
    "title": "Intro to Linear Regression",
    "section": "Datasaurus",
    "text": "Datasaurus"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#more-examples",
    "href": "lectures/5_linear_regression_1_predictor.html#more-examples",
    "title": "Intro to Linear Regression",
    "section": "More examples",
    "text": "More examples"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#beware",
    "href": "lectures/5_linear_regression_1_predictor.html#beware",
    "title": "Intro to Linear Regression",
    "section": "Beware",
    "text": "Beware\n\n\nNote that correlation only measures the strength of a linear relationship\nAlways graph your data!"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#reading-for-next-lecture",
    "href": "lectures/5_linear_regression_1_predictor.html#reading-for-next-lecture",
    "title": "Intro to Linear Regression",
    "section": "Reading for next lecture",
    "text": "Reading for next lecture\nNo additional reading"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#degrees-of-freedom",
    "href": "lectures/22_ANOVA2.html#degrees-of-freedom",
    "title": "ANOVA 2",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nLet’s consider the iris data.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading required package: airports\n\nLoading required package: cherryblossom\n\nLoading required package: usdata\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\n\n\nSpecies\nmean\nsd\ncount\n\n\n\n\nsetosa\n5.0\n0.4\n50\n\n\nversicolor\n5.9\n0.5\n50\n\n\nvirginica\n6.6\n0.6\n50\n\n\n\n\n\n\\[H_o: \\mu_1 = \\mu_2 = \\mu_3 \\\\\nH_a: \\text{At least one of these is different}\\]"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#rule-of-thumb",
    "href": "lectures/22_ANOVA2.html#rule-of-thumb",
    "title": "ANOVA 2",
    "section": "Rule of Thumb",
    "text": "Rule of Thumb\n\nThe variance are equal condition has a rule of thumb.\nIf the largest is not more than four times the smallest all is well.\n\\[\n\\frac{s^2_{max}}{s^2_{min}}\\le 4\n\\]\nor\nIf the largest SD/ smallest SD is between 0.5 and 2.\n\\[\n\\frac{s_{max}}{s_{min}}\\le 2\n\\]"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#variability-in-anova",
    "href": "lectures/22_ANOVA2.html#variability-in-anova",
    "title": "ANOVA 2",
    "section": "Variability in ANOVA",
    "text": "Variability in ANOVA\nThere are two types of Variability\n\nThe variability between the groups. This is called mean square between groups (MSG).\nThe variability within the groups. This is called mean square error (MSE)."
  },
  {
    "objectID": "lectures/22_ANOVA2.html#degrees-of-freedom-1",
    "href": "lectures/22_ANOVA2.html#degrees-of-freedom-1",
    "title": "ANOVA 2",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nLet k be the number of groups.\nLet n be the total number of observations.\nThe MSG has \\(df_G = k-1\\) degrees of freedom.\nThe MSE has \\(df_E = n-k\\) degrees of freedom.\nThe aov() function calculates these for you."
  },
  {
    "objectID": "lectures/22_ANOVA2.html#anova-output",
    "href": "lectures/22_ANOVA2.html#anova-output",
    "title": "ANOVA 2",
    "section": "ANOVA output",
    "text": "ANOVA output\n\nlibrary(broom)\n\nresults &lt;- aov(Sepal.Length ~ Species, data=iris)\n\n#Note: you can also use summary(results). Then you don't have to load the broom package. \ntidy(results) |&gt;\n  kable(digits = 1)\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\nSpecies\n2\n63.2\n31.6\n119.3\n0\n\n\nResiduals\n147\n39.0\n0.3\nNA\nNA"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#the-f-statistic",
    "href": "lectures/22_ANOVA2.html#the-f-statistic",
    "title": "ANOVA 2",
    "section": "The f statistic",
    "text": "The f statistic\nThe f statistic arises as a ratio of the MSG and MSE.\nIf the ratio is large it means that the event is unlikely and we should reject the null hypothesis.\n\\[f=\\frac{MSG}{MSE}\\]\n(see page 289 to calculate SSG and SSE)."
  },
  {
    "objectID": "lectures/22_ANOVA2.html#post-hoc-tests",
    "href": "lectures/22_ANOVA2.html#post-hoc-tests",
    "title": "ANOVA 2",
    "section": "Post hoc tests",
    "text": "Post hoc tests\nIf we reject the null hypothesis we want to be able to identify which mean is different.\nSometimes it is obvious and we can do this graphically."
  },
  {
    "objectID": "lectures/22_ANOVA2.html#post-hoc-setup",
    "href": "lectures/22_ANOVA2.html#post-hoc-setup",
    "title": "ANOVA 2",
    "section": "Post hoc setup",
    "text": "Post hoc setup\nLet k be the number of groups we are comparing.\nLet K = the number of possible pairs compared.\n\\(K = \\frac{k(k-1)}{2}\\)"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#adjust-the-pvalue-to-reduce-type-1-error.",
    "href": "lectures/22_ANOVA2.html#adjust-the-pvalue-to-reduce-type-1-error.",
    "title": "ANOVA 2",
    "section": "Adjust the pvalue to reduce type 1 error.",
    "text": "Adjust the pvalue to reduce type 1 error.\nWe could do pairwise T-Tests but then we increase the Type 1 error rate.\n\nType 1 Error: Reject the null when it is true.\n\nSo we adjust the p-value (Bonferroni Correction )"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#bonferroni-correction-for-multiple-comparisons",
    "href": "lectures/22_ANOVA2.html#bonferroni-correction-for-multiple-comparisons",
    "title": "ANOVA 2",
    "section": "Bonferroni Correction for Multiple Comparisons",
    "text": "Bonferroni Correction for Multiple Comparisons\nConduct a t-test for the difference in means for all 𝐾 possible pairs and\ncollect the p-values (the pairwise p-values). The corrected the pairwise\np-value for multiple comparisons\n\\(\\text{p-value}^* = \\text{p-value} × 𝐾\\)\nwhich is equivalent to \\(\\alpha^* = \\frac{\\alpha}{K}\\)\nYou just do one or the other."
  },
  {
    "objectID": "lectures/22_ANOVA2.html#recall-anova-of-sepal.-length",
    "href": "lectures/22_ANOVA2.html#recall-anova-of-sepal.-length",
    "title": "ANOVA 2",
    "section": "Recall ANOVA of Sepal. Length",
    "text": "Recall ANOVA of Sepal. Length\n\nresults &lt;- aov( Sepal.Length ~ Species, data = iris )\nsummary(results)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nSpecies       2  63.21  31.606   119.3 &lt;2e-16 ***\nResiduals   147  38.96   0.265                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#post-hoc-on-sepal.length",
    "href": "lectures/22_ANOVA2.html#post-hoc-on-sepal.length",
    "title": "ANOVA 2",
    "section": "Post hoc on Sepal.Length",
    "text": "Post hoc on Sepal.Length\n\npairwise.t.test(\n  x= iris$Sepal.Length,\n  g = iris$Species,\n  pool.sd = F, \n  paired = F,\n  p.adjust.method = \"bonferroni\") \n\n\n    Pairwise comparisons using t tests with non-pooled SD \n\ndata:  iris$Sepal.Length and iris$Species \n\n           setosa  versicolor\nversicolor &lt; 2e-16 -         \nvirginica  &lt; 2e-16 5.6e-07   \n\nP value adjustment method: bonferroni"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#occasional-contradictions",
    "href": "lectures/22_ANOVA2.html#occasional-contradictions",
    "title": "ANOVA 2",
    "section": "Occasional contradictions",
    "text": "Occasional contradictions\nSometimes the post hoc doesn’t seem to indicate that any mean is different. That’s ok. Let’s stick with ANOVA"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#try-a-test-do-a-post-hoc-if-necessary.",
    "href": "lectures/22_ANOVA2.html#try-a-test-do-a-post-hoc-if-necessary.",
    "title": "ANOVA 2",
    "section": "Try a test, do a post hoc if necessary.",
    "text": "Try a test, do a post hoc if necessary.\n\nlibrary(palmerpenguins)\n\nFrom the palmerpenguins package consider the peguins data.\nIs there a difference in the avergae flipper length between species.\n\nCheck conditions (independence,sd, normalish)\n\nmake a graph?\n\nSet up test\nDo test\npost hoc\nconclusion"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#test-output",
    "href": "lectures/22_ANOVA2.html#test-output",
    "title": "ANOVA 2",
    "section": "Test output",
    "text": "Test output\n\nresults &lt;- aov(flipper_length_mm~species, data=penguins)\nsummary(results)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nspecies       2  52473   26237   594.8 &lt;2e-16 ***\nResiduals   339  14953      44                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\n\npairwise.t.test(\n  x= penguins$flipper_length_mm,\n  g = penguins$species,\n  pool.sd = F, \n  paired = F,\n  p.adjust.method = \"bonferroni\") \n\n\n    Pairwise comparisons using t tests with non-pooled SD \n\ndata:  penguins$flipper_length_mm and penguins$species \n\n          Adelie  Chinstrap\nChinstrap 1.8e-07 -        \nGentoo    &lt; 2e-16 &lt; 2e-16  \n\nP value adjustment method: bonferroni"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#example",
    "href": "lectures/22_ANOVA2.html#example",
    "title": "ANOVA 2",
    "section": "Example",
    "text": "Example\nConsider chickwts. Do a test to see if the average maximum weight of the chicks is dependent on the food type given.\n\ncheck conditions\ndo test\ndo post hoc\n\n\nchickwts\n\n   weight      feed\n1     179 horsebean\n2     160 horsebean\n3     136 horsebean\n4     227 horsebean\n5     217 horsebean\n6     168 horsebean\n7     108 horsebean\n8     124 horsebean\n9     143 horsebean\n10    140 horsebean\n11    309   linseed\n12    229   linseed\n13    181   linseed\n14    141   linseed\n15    260   linseed\n16    203   linseed\n17    148   linseed\n18    169   linseed\n19    213   linseed\n20    257   linseed\n21    244   linseed\n22    271   linseed\n23    243   soybean\n24    230   soybean\n25    248   soybean\n26    327   soybean\n27    329   soybean\n28    250   soybean\n29    193   soybean\n30    271   soybean\n31    316   soybean\n32    267   soybean\n33    199   soybean\n34    171   soybean\n35    158   soybean\n36    248   soybean\n37    423 sunflower\n38    340 sunflower\n39    392 sunflower\n40    339 sunflower\n41    341 sunflower\n42    226 sunflower\n43    320 sunflower\n44    295 sunflower\n45    334 sunflower\n46    322 sunflower\n47    297 sunflower\n48    318 sunflower\n49    325  meatmeal\n50    257  meatmeal\n51    303  meatmeal\n52    315  meatmeal\n53    380  meatmeal\n54    153  meatmeal\n55    263  meatmeal\n56    242  meatmeal\n57    206  meatmeal\n58    344  meatmeal\n59    258  meatmeal\n60    368    casein\n61    390    casein\n62    379    casein\n63    260    casein\n64    404    casein\n65    318    casein\n66    352    casein\n67    359    casein\n68    216    casein\n69    222    casein\n70    283    casein\n71    332    casein"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#anova-with-randomization",
    "href": "lectures/22_ANOVA2.html#anova-with-randomization",
    "title": "ANOVA 2",
    "section": "ANOVA with Randomization",
    "text": "ANOVA with Randomization\nYou’ll do this in lab 7.\n\nset.seed(11292023)\nlibrary(infer)\nsimulated_data &lt;- chickwts |&gt;\n  specify(weight ~ feed) |&gt;\n  hypothesize(null = \"independence\") |&gt; \n  generate(reps = 1000, type = \"permute\") |&gt; \n  calculate(stat = \"F\")"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#graph-of-simulated-data",
    "href": "lectures/22_ANOVA2.html#graph-of-simulated-data",
    "title": "ANOVA 2",
    "section": "Graph of simulated data",
    "text": "Graph of simulated data\n\nsimulated_data |&gt;\n  visualise() +\n  shade_p_value( obs_stat= 15.37, direction = \"greater\")"
  },
  {
    "objectID": "lectures/22_ANOVA2.html#consider-the-nba_player_19-data-from-open-intro",
    "href": "lectures/22_ANOVA2.html#consider-the-nba_player_19-data-from-open-intro",
    "title": "ANOVA 2",
    "section": "Consider the nba_player_19 data from open intro",
    "text": "Consider the nba_player_19 data from open intro\nDo a hypothesis to see if the average heights are different by team."
  },
  {
    "objectID": "lectures/day_26_difference_CI.html",
    "href": "lectures/day_26_difference_CI.html",
    "title": "Difference of Two Prop CI",
    "section": "",
    "text": "Is there a difference between the two proportions?\n\n\nThe following is from chapter 17 in the text:\nThe difference \\(\\hat{p}_1−\\hat{p}_2\\) can be modeled using a normal distribution when\nIndependence Extended: The data are independent within and between the two groups.\nSuccess-failure condition. The success-failure condition holds for both groups, where we check successes and failures in each group separately.\n\n\n\n\\(\\hat{p}_1−\\hat{p}_2 \\sim N(\\hat{p}_1−\\hat{p}_2,\\sqrt{\\frac{\\hat{p}_1(1−\\hat{p}_1)}{n_1} +\\frac{\\hat{p}_2(1−\\hat{p}_2)}{n_2}})\\)\nmean = \\(\\hat{p}_1−\\hat{p}_2\\)\nStandard Error = \\(\\sqrt{\\frac{\\hat{p}_1(1−\\hat{p}_1)}{n} +\\frac{\\hat{p}_2(1−\\hat{p}_2)}{n}}\\)\n\n\n\n ## Two groups\n\nggplot(cpr, aes(x = group, fill = outcome))+\ngeom_bar(position = \"fill\")"
  },
  {
    "objectID": "lectures/day_26_difference_CI.html#similar-to-ci-for-one-prop.",
    "href": "lectures/day_26_difference_CI.html#similar-to-ci-for-one-prop.",
    "title": "Difference of Two Prop CI",
    "section": "",
    "text": "The following is from chapter 17 in the text:\nThe difference \\(\\hat{p}_1−\\hat{p}_2\\) can be modeled using a normal distribution when\nIndependence Extended: The data are independent within and between the two groups.\nSuccess-failure condition. The success-failure condition holds for both groups, where we check successes and failures in each group separately."
  },
  {
    "objectID": "lectures/day_26_difference_CI.html#mean-and-se",
    "href": "lectures/day_26_difference_CI.html#mean-and-se",
    "title": "Difference of Two Prop CI",
    "section": "",
    "text": "\\(\\hat{p}_1−\\hat{p}_2 \\sim N(\\hat{p}_1−\\hat{p}_2,\\sqrt{\\frac{\\hat{p}_1(1−\\hat{p}_1)}{n_1} +\\frac{\\hat{p}_2(1−\\hat{p}_2)}{n_2}})\\)\nmean = \\(\\hat{p}_1−\\hat{p}_2\\)\nStandard Error = \\(\\sqrt{\\frac{\\hat{p}_1(1−\\hat{p}_1)}{n} +\\frac{\\hat{p}_2(1−\\hat{p}_2)}{n}}\\)"
  },
  {
    "objectID": "lectures/day_26_difference_CI.html#consider-the-cpr-data.",
    "href": "lectures/day_26_difference_CI.html#consider-the-cpr-data.",
    "title": "Difference of Two Prop CI",
    "section": "",
    "text": "## Two groups\n\nggplot(cpr, aes(x = group, fill = outcome))+\ngeom_bar(position = \"fill\")"
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "",
    "text": "Previously, we simulated how many cards we have to draw in a well shuffled deck of cards until we saw two cards that had the same suit. If we pooled the results from all three sections of 220. We would have something like the following:"
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#last-time",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#last-time",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "",
    "text": "Previously, we simulated how many cards we have to draw in a well shuffled deck of cards until we saw two cards that had the same suit. If we pooled the results from all three sections of 220. We would have something like the following:"
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#last-time-1",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#last-time-1",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Last Time",
    "text": "Last Time\n\nDescribe the two distributions: center, shape/skewness, spread.\nSuppose there where 60 groups in total across the three sections of STAT 220. Use the web-widget online and observe what happens when you change the “Number of simulations per mean estimated”. Try multiple values: very small, very very large, etc. Which distribution changes? How?"
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#recall-statistics-estimate-parameters",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#recall-statistics-estimate-parameters",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Recall: Statistics Estimate Parameters",
    "text": "Recall: Statistics Estimate Parameters\n\nA statistic, is an estimate for a parameter.\nCommon statistics are:\n\nsample proportion (\\(\\hat{p}\\))\nsample mean (\\(\\overline{x}\\) or \\(\\hat{\\mu}\\)).\n\nThese statistics estimate the\n\npopulation proportion (\\(p\\))\npopulation mean (\\(\\mu\\))."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#sampling-distributions",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#sampling-distributions",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions"
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#sampling-distributions-1",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#sampling-distributions-1",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\nSampling distributions help us answer the questions:\n\nHow much might a statistic vary from sample to sample?\nHow would we describe the shape, center, and variability of the possible values for our statistic?\nWhat is the effect of the sample size \\(n\\) on the shape of the sampling distribution.\nNote: The difference between Data Dist and Sample Dist.\nSampling distributions for means have a particular behavior that always happens."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#fund-theorm-of-statistics",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#fund-theorm-of-statistics",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Fund Theorm of Statistics",
    "text": "Fund Theorm of Statistics\nThe Fundamental Theorem of Statistics (also called the Central Limit Theorem)."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#fts-revisited",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#fts-revisited",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "FTS Revisited",
    "text": "FTS Revisited\nThe same is true for a single mean."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#normal-distribution",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#normal-distribution",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Normal Distribution",
    "text": "Normal Distribution\n\n\n\n\n\n\nThe normal distribution is a symmetric, unimodal, bell-shaped continuous probability distribution.\nSuper famous.\nNote, \\(\\overline{x}\\) and \\(\\hat{p}\\) will have a sampling distribution that is normally distributed centered around the parameter (true population mean/proportion)"
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#sampling-distributions-continued",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#sampling-distributions-continued",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Sampling Distributions Continued",
    "text": "Sampling Distributions Continued\n\nIts expensive to create sampling distributions.\nFor example, we may want the sampling distribution for:\n\nPolitical polls. How many people voted for a specific candidate?\nTaxi Cab Fares. How much would I spend on taxi cabs in NYC?\nHealth data. What percent of patients respond well to new treatment?\n\nOne sample is possible, many not so much."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#bootstrapping",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#bootstrapping",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Bootstrapping",
    "text": "Bootstrapping\nIn bootstrapping we simulate drawing a random sample from the observed data. That is, we resample by repeatedly taking samples from the original sample."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#bootstrap",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#bootstrap",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Bootstrap",
    "text": "Bootstrap\n\n\n\n\n\n\n\n\nWe can ‘pull ourselves up by our bootstraps’ to attack the problem by using computer simulations."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#bootstrap-resampling",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#bootstrap-resampling",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Bootstrap Resampling",
    "text": "Bootstrap Resampling\nTo use the bootstrap method with your original data set with \\(n\\) observations:\n\nYou resample, with replacement, \\(n\\) observations from the data distribution.\nFor the new bootstrap sample of size \\(n\\), construct the point estimate of the parameter of interest (the proportion).\nRepeat the process a very large number of times, \\(B\\) (e.g., selecting \\(B=\\) 10,000 separate samples of size \\(n\\) and calculating the 10,000 corresponding parameter estimates)."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#bootstrap-distribution",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#bootstrap-distribution",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Bootstrap Distribution",
    "text": "Bootstrap Distribution\nFor each bootstrap sample, we can compute a statistic of interest, such as a proportion.\nWe compute the sample proportion from thousands of bootstrap samples. The distribution of all these means, called the bootstrap distribution, will help us estimate the sampling distribution of the sample mean without having to take samples over and over again."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#features-of-the-bootstrap-distribution",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#features-of-the-bootstrap-distribution",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Features of the Bootstrap Distribution",
    "text": "Features of the Bootstrap Distribution\n\nCenter: the observed sample statistic\n\nThis differs from the sampling distribution, which is centered around the true population parameter.\n\nSpread: even though the means of the bootstrap distribution and the sampling distribution are not the same, their spreads are.\n\nThe bootstrapped statistic vary about original sample statistic in the same way that the original sample proportions vary about true parameter."
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#features-of-the-bootstrap-distribution-1",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#features-of-the-bootstrap-distribution-1",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Features of the Bootstrap Distribution",
    "text": "Features of the Bootstrap Distribution\nSuppose when we sampled cards last lecture one of our groups had a mean 5.27, but the true mean was 5.7 cards.\n\n\nLoading required package: airports\n\n\nLoading required package: cherryblossom\n\n\nLoading required package: usdata"
  },
  {
    "objectID": "lectures/day-16-the-bootstrap/SamplingDistr.html#limitations-of-the-bootstrap",
    "href": "lectures/day-16-the-bootstrap/SamplingDistr.html#limitations-of-the-bootstrap",
    "title": "IMS 12 (ish): Sampling Distributions and Bootstrapping",
    "section": "Limitations of the Bootstrap",
    "text": "Limitations of the Bootstrap\n\nIt is essential that the original sample is a random sample from the population, or at least representative of it.\nLarger samples (big \\(n\\)) are typically better for bootstraps.\nWhen the bootstrap distribution consists of only a few values and is highly discrete, it is of limited use and should not be used.\nWe typically need a large number of bootstrap resamples (\\(B \\geq 5000\\)) to obtain a bootstrap distribution that reasonably approximates the key features of the sampling distribution\n\nWhy are these things important?"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#find-the-confidence-interval-for",
    "href": "lectures/16__CI_prop_mathematically.html#find-the-confidence-interval-for",
    "title": "Confidence Intervals with a proportion",
    "section": "Find the confidence interval for:",
    "text": "Find the confidence interval for:\n\nThe true number of US women who were married before age 30.\n\n\n\nCode\nlibrary(openintro)\n\nage_at_mar &lt;- age_at_mar |&gt; \n  mutate(over_30 =\n           case_when(\n             age &gt; 30 ~ \"Over_30\",\n             TRUE ~ \"Under_30\"\n           ))\nhead(age_at_mar, 2)\n\n\n# A tibble: 2 × 2\n    age over_30 \n  &lt;int&gt; &lt;chr&gt;   \n1    32 Over_30 \n2    25 Under_30\n\n\n\nThe true proportion of women who smoke while pregnant in the US.\n\n\nhead(births14)\n\n# A tibble: 6 × 13\n   fage  mage mature      weeks premie visits gained weight lowbirthweight sex  \n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;\n1    34    34 younger mom    37 full …     14     28   6.96 not low        male \n2    36    31 younger mom    41 full …     12     41   8.86 not low        fema…\n3    37    36 mature mom     37 full …     10     28   7.51 not low        fema…\n4    NA    16 younger mom    38 full …     NA     29   6.19 not low        male \n5    32    31 younger mom    36 premie     12     48   6.75 not low        fema…\n6    32    26 younger mom    39 full …     14     45   6.69 not low        fema…\n# ℹ 3 more variables: habit &lt;chr&gt;, marital &lt;chr&gt;, whitemom &lt;chr&gt;"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#ci-mathematically",
    "href": "lectures/16__CI_prop_mathematically.html#ci-mathematically",
    "title": "Confidence Intervals with a proportion",
    "section": "CI mathematically",
    "text": "CI mathematically\nWe build the CI around the sample proportion.\nAssume\n\\[\n\\hat{p} \\sim N(p,se)\n\\]\n\nWe need \\(\\hat{p}\\) and \\(\\text{se}= \\sqrt{\\frac{p(1-p)}{n}}\\)\nWe also need the z score that goes with the confidence interval we are looking for.\n\\(\\hat{p} \\pm z_{score} \\times se\\)"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#remember-these-z-scores",
    "href": "lectures/16__CI_prop_mathematically.html#remember-these-z-scores",
    "title": "Confidence Intervals with a proportion",
    "section": "Remember these z-scores",
    "text": "Remember these z-scores\n\nz-scores you should know\n\n\nCI\nZ-score\n\n\n\n\n90%\n\\(z_{0.05}=1.645\\)\n\n\n95%\n\\(z_{0.025}=1.96\\)\n\n\n99.7%\n\\(z_{0.005}=2.968\\)"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#how-to-find-zscore-with-qnorm",
    "href": "lectures/16__CI_prop_mathematically.html#how-to-find-zscore-with-qnorm",
    "title": "Confidence Intervals with a proportion",
    "section": "How to find zscore with qnorm()",
    "text": "How to find zscore with qnorm()\nqnorm() finds the quantile that goes with a pvalue (probability)\n\nqnorm(p = 0.975, mean = 0, sd = 1 )\n\n[1] 1.959964\n\n\npnorm() finds a pvalue from a quantile.\n\npnorm(q=1.959964 , mean = 0, sd = 1 )\n\n[1] 0.975"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#the-distribution-of-sampling-proportions",
    "href": "lectures/16__CI_prop_mathematically.html#the-distribution-of-sampling-proportions",
    "title": "Confidence Intervals with a proportion",
    "section": "The distribution of sampling proportions",
    "text": "The distribution of sampling proportions\nCompare vs. bootstrap distributions."
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#lets-make-a-95-ci",
    "href": "lectures/16__CI_prop_mathematically.html#lets-make-a-95-ci",
    "title": "Confidence Intervals with a proportion",
    "section": "Let’s make a 95% CI",
    "text": "Let’s make a 95% CI\nFind these: \\(\\hat{p}\\) and \\(\\text{se}= \\sqrt{\\frac{p(1-p)}{n}}\\)\n\\(\\hat{p} \\pm z_{score} \\times se\\)"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#assumptions-for-a-single-parameter",
    "href": "lectures/16__CI_prop_mathematically.html#assumptions-for-a-single-parameter",
    "title": "Confidence Intervals with a proportion",
    "section": "Assumptions for a single parameter",
    "text": "Assumptions for a single parameter\nIndependent and “large” sample.\nSuccess-Failure Condition\nWhy do we need to assume this:\n\\[\n\\hat{p} \\sim N(p,se)\n\\]"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#board-practice",
    "href": "lectures/16__CI_prop_mathematically.html#board-practice",
    "title": "Confidence Intervals with a proportion",
    "section": "Board Practice",
    "text": "Board Practice\nWe found these with simulation, find them now with a mathematical model. Use a 88% CI.\n\nThe true number of US women who were married before age 30.\nThe true proportion of women who smoke while pregnant in the US."
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#quarantine",
    "href": "lectures/16__CI_prop_mathematically.html#quarantine",
    "title": "Confidence Intervals with a proportion",
    "section": "Quarantine",
    "text": "Quarantine\nWe ask 1042 New Yorkers if they are for quarantining peope who have been exposed to ebola. The results are below.\n\ncount(ebola_survey,quarantine)\n\n# A tibble: 2 × 2\n  quarantine     n\n  &lt;fct&gt;      &lt;int&gt;\n1 against      188\n2 favor        854\n\n\n\nWrite the notation for the theoretical sampling distribution.\nMake a 90, 95 and 99.7% CI for those against and interpret."
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#exclusive-relationships",
    "href": "lectures/16__CI_prop_mathematically.html#exclusive-relationships",
    "title": "Confidence Intervals with a proportion",
    "section": "Exclusive relationships",
    "text": "Exclusive relationships\nWhat is the proportion of college students that have had more than 1 exclusive_relationships?\n\nexclusive_relationship |&gt;\n  count(num &gt; 1)\n\n# A tibble: 3 × 2\n  `num &gt; 1`     n\n  &lt;lgl&gt;     &lt;int&gt;\n1 FALSE        51\n2 TRUE        152\n3 NA           15\n\n\n\nCheck Conditions.\nWrite the notation for the theoretical sampling distribution.\nMake a 90, 95 and 99.7% CI for those against and interpret."
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#iphones",
    "href": "lectures/16__CI_prop_mathematically.html#iphones",
    "title": "Confidence Intervals with a proportion",
    "section": "iphones",
    "text": "iphones\n\nIn a sample of 300 students, 68% said they own an iPod and a smart phone. Compute a 97% confidence interval for the true percent of students who own an iPod and a smartphone.1"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#worse-off",
    "href": "lectures/16__CI_prop_mathematically.html#worse-off",
    "title": "Confidence Intervals with a proportion",
    "section": "Worse off?",
    "text": "Worse off?\nEvery week the Yougov/The Economist do a survey from a representative sample of about 1500 adults. methodology On March 4, 2024 people were asked about their personal finances. See the results here.\nFind a CI for the true proportion of Americans who feel they are worse off financially than a year ago.\n\nnumber_worse_off &lt;- round(0.42*1556)\nnot_worse_off &lt;- 1556 -number_worse_off\n\n# This makes a data frame that mirrors the number of people who were worse off or not from the poll. \npoll &lt;- tibble(\n  worse_off = c(rep(\"Yes\", number_worse_off), rep(\"No\", not_worse_off))\n)"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#problems-from-the-text",
    "href": "lectures/16__CI_prop_mathematically.html#problems-from-the-text",
    "title": "Confidence Intervals with a proportion",
    "section": "Problems from the text",
    "text": "Problems from the text\nDo these with simulation and then with math. Chapter 6: 20, 21, 22"
  },
  {
    "objectID": "lectures/16__CI_prop_mathematically.html#footnotes",
    "href": "lectures/16__CI_prop_mathematically.html#footnotes",
    "title": "Confidence Intervals with a proportion",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis and the previous problem were from a text called Introductory Statistics↩︎"
  },
  {
    "objectID": "lectures/20_diff-of-means.html",
    "href": "lectures/20_diff-of-means.html",
    "title": "Difference of Means",
    "section": "",
    "text": "Find a partner (or two) and grab some chalkboard\nDo this hypothesis test.\nThe average height of Smith students is thought to be 64 inches. Our class has an average height of 65 inches with a standard deviation of 3.2. There were 34 students in our sample.\nTest the hypothesis that the true mean is 64 twice\n\nonce using the observed statistic to find a p-value.\nonce with the test statistic to find the same p-value."
  },
  {
    "objectID": "lectures/20_diff-of-means.html#warm-up",
    "href": "lectures/20_diff-of-means.html#warm-up",
    "title": "Difference of Means",
    "section": "",
    "text": "Find a partner (or two) and grab some chalkboard\nDo this hypothesis test.\nThe average height of Smith students is thought to be 64 inches. Our class has an average height of 65 inches with a standard deviation of 3.2. There were 34 students in our sample.\nTest the hypothesis that the true mean is 64 twice\n\nonce using the observed statistic to find a p-value.\nonce with the test statistic to find the same p-value."
  },
  {
    "objectID": "lectures/20_diff-of-means.html#warm-up-again-with-r",
    "href": "lectures/20_diff-of-means.html#warm-up-again-with-r",
    "title": "Difference of Means",
    "section": "warm up again with R",
    "text": "warm up again with R\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(googlesheets4)\n\n# Making CI from some sample proportions.\n\nclass_heights &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1x9srZXDoYzKGew1f-y4brMbN8dl4QM66pc-dmCBWHQY/edit?usp=sharing\",\n                            sheet = \"220-01\",\n                            range = \"1:35\")|&gt;\n  select(height)\n\n! Using an auto-discovered, cached token.\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n  See gargle's \"Non-interactive auth\" vignette for more details:\n  &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt;\nℹ The googlesheets4 package is using a cached token for 'nschwab@smith.edu'.\nAuto-refreshing stale OAuth token.\n✔ Reading from \"Schwab SDS 220 Fall 23 Pre-Course Questionnaire (Responses)\".\n✔ Range ''220-01'!1:35'.\n\n\n\nt.test(class_heights$height, mu=64)\n\n\n    One Sample t-test\n\ndata:  class_heights$height\nt = 1.8954, df = 33, p-value = 0.06683\nalternative hypothesis: true mean is not equal to 64\n95 percent confidence interval:\n 63.92442 66.13440\nsample estimates:\nmean of x \n 65.02941"
  },
  {
    "objectID": "lectures/20_diff-of-means.html#side-note-prop.test",
    "href": "lectures/20_diff-of-means.html#side-note-prop.test",
    "title": "Difference of Means",
    "section": "Side note: prop.test()",
    "text": "Side note: prop.test()\nThere is also a prop.test() function that will test a proportion hypothesis from data based on mathematical formula (as opposed to bootstrapping)."
  },
  {
    "objectID": "lectures/20_diff-of-means.html#new-test-difference-of-two-means",
    "href": "lectures/20_diff-of-means.html#new-test-difference-of-two-means",
    "title": "Difference of Means",
    "section": "New test: Difference of two means",
    "text": "New test: Difference of two means\nAnother hypothesis test.\n\nConditions\nDistributions\nNew Standard Error\nNew df"
  },
  {
    "objectID": "4_Numeric_Data.html",
    "href": "4_Numeric_Data.html",
    "title": "Numeric Data",
    "section": "",
    "text": "Chapter 5 Numeric Data"
  },
  {
    "objectID": "4_Numeric_Data.html#read-before-lecture",
    "href": "4_Numeric_Data.html#read-before-lecture",
    "title": "Numeric Data",
    "section": "",
    "text": "Chapter 5 Numeric Data"
  },
  {
    "objectID": "4_Numeric_Data.html#summarizing-distributions",
    "href": "4_Numeric_Data.html#summarizing-distributions",
    "title": "Numeric Data",
    "section": "Summarizing distributions",
    "text": "Summarizing distributions\nNumeric Data\n\n\nShape, Center, and Spread"
  },
  {
    "objectID": "4_Numeric_Data.html#load-the-libraries",
    "href": "4_Numeric_Data.html#load-the-libraries",
    "title": "Numeric Data",
    "section": "Load the libraries",
    "text": "Load the libraries\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "4_Numeric_Data.html#histogram",
    "href": "4_Numeric_Data.html#histogram",
    "title": "Numeric Data",
    "section": "Histogram",
    "text": "Histogram\nSummarize the shape of the distribution of one variable\n\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`)."
  },
  {
    "objectID": "4_Numeric_Data.html#density-plot",
    "href": "4_Numeric_Data.html#density-plot",
    "title": "Numeric Data",
    "section": "Density plot",
    "text": "Density plot\nSummarize the shape of the distribution of one variable\n\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_density()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density()`)."
  },
  {
    "objectID": "4_Numeric_Data.html#box-plot",
    "href": "4_Numeric_Data.html#box-plot",
    "title": "Numeric Data",
    "section": "Box plot",
    "text": "Box plot\nSummarize the shape of the distribution of one variable\n\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "4_Numeric_Data.html#your-turn",
    "href": "4_Numeric_Data.html#your-turn",
    "title": "Numeric Data",
    "section": "Your turn",
    "text": "Your turn\n\nUse a data graphic to summarize the distribution of the height variable in the starwars data frame."
  },
  {
    "objectID": "4_Numeric_Data.html#histogram-two-variables",
    "href": "4_Numeric_Data.html#histogram-two-variables",
    "title": "Numeric Data",
    "section": "Histogram: two variables",
    "text": "Histogram: two variables\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, fill = species)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`)."
  },
  {
    "objectID": "4_Numeric_Data.html#density-plot-two-variables",
    "href": "4_Numeric_Data.html#density-plot-two-variables",
    "title": "Numeric Data",
    "section": "Density plot: two variables",
    "text": "Density plot: two variables\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, fill = species)) +\n  geom_density(alpha = 0.4)\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density()`)."
  },
  {
    "objectID": "4_Numeric_Data.html#boxplot-two-variables",
    "href": "4_Numeric_Data.html#boxplot-two-variables",
    "title": "Numeric Data",
    "section": "Boxplot: two variables",
    "text": "Boxplot: two variables\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, fill = species)) +\n  geom_boxplot()\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`)."
  },
  {
    "objectID": "4_Numeric_Data.html#measures-of-center",
    "href": "4_Numeric_Data.html#measures-of-center",
    "title": "Numeric Data",
    "section": "Measures of center",
    "text": "Measures of center\n\n\nmean: mean()\nmedian: median()\n\n\n\n# When using summarize functions like n() and mean() the words to the left of the = are the column headers.\n\n  summarize(\n    .data = penguins,\n    number_of_penguins = n(),\n    mean_mass = mean(body_mass_g, na.rm = TRUE),\n    median_mass = median(body_mass_g, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 3\n  number_of_penguins mean_mass median_mass\n               &lt;int&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1                344     4202.        4050"
  },
  {
    "objectID": "4_Numeric_Data.html#measures-of-spread",
    "href": "4_Numeric_Data.html#measures-of-spread",
    "title": "Numeric Data",
    "section": "Measures of spread",
    "text": "Measures of spread\n\n\nstandard deviation: sd()\nvariance: var()\nrange: range()\nIQR: IQR()\n\n\n\n  summarize(\n    .data = penguins,\n    number_of_penguins = n(),\n    sd_mass = sd(body_mass_g, na.rm = TRUE),\n    var_mass = var(body_mass_g, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 3\n  number_of_penguins sd_mass var_mass\n               &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1                344    802.  643131."
  },
  {
    "objectID": "4_Numeric_Data.html#quantiles",
    "href": "4_Numeric_Data.html#quantiles",
    "title": "Numeric Data",
    "section": "Quantiles",
    "text": "Quantiles\nMost summary information can be found with the fivnum() or summary() function.\n\n# This is just the five number summary\nfive_number_pengiuns &lt;-fivenum(penguins$body_mass_g)\nfive_number_pengiuns\n\n[1] 2700 3550 4050 4750 6300\n\n#This is the five number plus summary\nsummary(penguins$body_mass_g)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2 \n\n\n\n# This is how you can get the exact quantile. \nquantile(x= penguins$body_mass_g, probs = c(0.25,0.5), na.rm=TRUE)\n\n 25%  50% \n3550 4050"
  },
  {
    "objectID": "4_Numeric_Data.html#graphed-quantiles",
    "href": "4_Numeric_Data.html#graphed-quantiles",
    "title": "Numeric Data",
    "section": "Graphed Quantiles",
    "text": "Graphed Quantiles\n\n# Note the vertical line showing the 25th percentile. \nggplot(data = penguins, aes(x = body_mass_g)) +\n  geom_density()+\n  geom_vline(xintercept = 3550, color = \"purple\") \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_density()`)."
  },
  {
    "objectID": "4_Numeric_Data.html#your-turn-1",
    "href": "4_Numeric_Data.html#your-turn-1",
    "title": "Numeric Data",
    "section": "Your turn",
    "text": "Your turn\n\nSummarize the distribution of the height variable in the starwars data frame by computing:\n\nthe number of observations\nthe mean\nthe standard deviation\n\nFind the 80th quantile for the height variable in the starwars data."
  },
  {
    "objectID": "4_Numeric_Data.html#answer-here.",
    "href": "4_Numeric_Data.html#answer-here.",
    "title": "Numeric Data",
    "section": "Answer here.",
    "text": "Answer here."
  },
  {
    "objectID": "4_Numeric_Data.html#outliers",
    "href": "4_Numeric_Data.html#outliers",
    "title": "Numeric Data",
    "section": "Outliers",
    "text": "Outliers\nAlong a number line to locate outliers we first calculate the two bounds\n\n\\[\nL = Q1 - 1.5 \\times IQR \\\\\nU = Q3 + 1.5 \\times IQR\n\\]\nAny values outside that range are considered outliers.\nLet’s do this with penguins mass."
  },
  {
    "objectID": "4_Numeric_Data.html#calculate-outlier-bounds-in-r",
    "href": "4_Numeric_Data.html#calculate-outlier-bounds-in-r",
    "title": "Numeric Data",
    "section": "Calculate outlier bounds in R",
    "text": "Calculate outlier bounds in R\n\n# This is the IQR of the penguin's mass\niqr_mass &lt;- IQR(x= penguins$body_mass_g, na.rm = TRUE)\n\nq1 &lt;- five_number_pengiuns[2]\nq3 &lt;- five_number_pengiuns[4]\n\n# This is the lower bound\nq1 - 1.5*iqr_mass \n\n[1] 1750\n\n# This is the upper bound\nq3 + 1.5*iqr_mass\n\n[1] 6550\n\nmin(penguins$body_mass_g, na.rm = TRUE)\n\n[1] 2700\n\nmax(penguins$body_mass_g, na.rm = TRUE)\n\n[1] 6300"
  },
  {
    "objectID": "4_Numeric_Data.html#your-turn-2",
    "href": "4_Numeric_Data.html#your-turn-2",
    "title": "Numeric Data",
    "section": "Your turn",
    "text": "Your turn\n\nMake a boxplot of mass of the starwars characters\nCalculate the outlier range (by hand or in the computer).\nWho are the outliers?"
  },
  {
    "objectID": "4_Numeric_Data.html#answer-here",
    "href": "4_Numeric_Data.html#answer-here",
    "title": "Numeric Data",
    "section": "Answer here",
    "text": "Answer here"
  },
  {
    "objectID": "lectures/3_categorical_data.html#read-before-lecture",
    "href": "lectures/3_categorical_data.html#read-before-lecture",
    "title": "Exploring Categorical Data",
    "section": "Read before Lecture",
    "text": "Read before Lecture\nChapter 4 Exploring Categorical Data"
  },
  {
    "objectID": "lectures/3_categorical_data.html#confounding-variables",
    "href": "lectures/3_categorical_data.html#confounding-variables",
    "title": "Exploring Categorical Data",
    "section": "Confounding Variables",
    "text": "Confounding Variables\nFor each of the following pairs of variables, a statistically significant positive relationship has been observed. Identify confounding that might cause the spurious correlation.\n\n\nThe amount of ice cream sold in New England and the number of deaths by drowning\nThe number of doctors in a region and the number of crimes committed in that region"
  },
  {
    "objectID": "lectures/3_categorical_data.html#explore-categorical-data",
    "href": "lectures/3_categorical_data.html#explore-categorical-data",
    "title": "Exploring Categorical Data",
    "section": "Explore Categorical Data",
    "text": "Explore Categorical Data\nWe’ll be exploring categorical data using R"
  },
  {
    "objectID": "lectures/3_categorical_data.html#chapter-4",
    "href": "lectures/3_categorical_data.html#chapter-4",
    "title": "Exploring Categorical Data",
    "section": "Chapter 4",
    "text": "Chapter 4\nExploring Categorical Data:\n\nlibrary(tidyverse)\nlibrary(openintro)\n\n# You should read and view the documentation of the data as a first step to exploring it. \n?assortive_mating\nassortive_mating\n\n# A tibble: 204 × 2\n   self_male partner_female\n   &lt;fct&gt;     &lt;fct&gt;         \n 1 blue      blue          \n 2 blue      blue          \n 3 blue      blue          \n 4 blue      blue          \n 5 blue      blue          \n 6 blue      blue          \n 7 blue      blue          \n 8 blue      blue          \n 9 blue      blue          \n10 blue      blue          \n# ℹ 194 more rows"
  },
  {
    "objectID": "lectures/3_categorical_data.html#sec-explore-categorical",
    "href": "lectures/3_categorical_data.html#sec-explore-categorical",
    "title": "Exploring Categorical Data",
    "section": "Exploring categorical data",
    "text": "Exploring categorical data\nLet’s explore categorical data using summary statistics and visualizations."
  },
  {
    "objectID": "lectures/3_categorical_data.html#tables",
    "href": "lectures/3_categorical_data.html#tables",
    "title": "Exploring Categorical Data",
    "section": "Tables",
    "text": "Tables\nTables are also helpful in understanding categorical data\n\ntable(data = assortive_mating)\n\n         partner_female\nself_male blue brown green\n    blue    78    23    13\n    brown   19    23    12\n    green   11     9    16"
  },
  {
    "objectID": "lectures/3_categorical_data.html#prop-tables",
    "href": "lectures/3_categorical_data.html#prop-tables",
    "title": "Exploring Categorical Data",
    "section": "Prop tables",
    "text": "Prop tables\n\n# Here I am saving the table as the variable my_table\n# I am telling table I specifically want to look at the male and female variables.\n\nmy_table &lt;- table(assortive_mating$self_male, assortive_mating$partner_female)\n\nprop.table(my_table)\n\n       \n              blue      brown      green\n  blue  0.38235294 0.11274510 0.06372549\n  brown 0.09313725 0.11274510 0.05882353\n  green 0.05392157 0.04411765 0.07843137"
  },
  {
    "objectID": "lectures/3_categorical_data.html#margins",
    "href": "lectures/3_categorical_data.html#margins",
    "title": "Exploring Categorical Data",
    "section": "Margins",
    "text": "Margins\n\naddmargins(A = my_table)\n\n       \n        blue brown green Sum\n  blue    78    23    13 114\n  brown   19    23    12  54\n  green   11     9    16  36\n  Sum    108    55    41 204"
  },
  {
    "objectID": "lectures/3_categorical_data.html#bar-graphs",
    "href": "lectures/3_categorical_data.html#bar-graphs",
    "title": "Exploring Categorical Data",
    "section": "Bar graphs",
    "text": "Bar graphs\nBar graphs can be helpful for exploring tables\n\n\n\nggplot(data = assortive_mating, mapping = aes(x=self_male)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nggplot(data = assortive_mating, mapping = aes(x=partner_female)) +\n  geom_bar()"
  },
  {
    "objectID": "lectures/3_categorical_data.html#mosaic-plots",
    "href": "lectures/3_categorical_data.html#mosaic-plots",
    "title": "Exploring Categorical Data",
    "section": "Mosaic plots",
    "text": "Mosaic plots\nIn the case of two categorical variables the mosaic plot is nice.\n\n# Here I am showing that I want to see a relationship between the two variables. \nmosaicplot(self_male ~ partner_female, data=assortive_mating)"
  },
  {
    "objectID": "lectures/3_categorical_data.html#variables-with-bar",
    "href": "lectures/3_categorical_data.html#variables-with-bar",
    "title": "Exploring Categorical Data",
    "section": "2 variables with bar",
    "text": "2 variables with bar\nWe can map aes to multiple variables\n\nggplot(data = assortive_mating, mapping = aes(x=self_male, fill=partner_female)) +\n  geom_bar()"
  },
  {
    "objectID": "lectures/3_categorical_data.html#fill",
    "href": "lectures/3_categorical_data.html#fill",
    "title": "Exploring Categorical Data",
    "section": "fill",
    "text": "fill\n\nggplot(data = assortive_mating, mapping = aes(x=self_male,fill=partner_female)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "lectures/3_categorical_data.html#dodge",
    "href": "lectures/3_categorical_data.html#dodge",
    "title": "Exploring Categorical Data",
    "section": "dodge",
    "text": "dodge\n\nggplot(data = assortive_mating, mapping = aes(x=self_male,fill=partner_female)) +\n  geom_bar(position = \"dodge\")"
  },
  {
    "objectID": "lectures/3_categorical_data.html#problem-4.5",
    "href": "lectures/3_categorical_data.html#problem-4.5",
    "title": "Exploring Categorical Data",
    "section": "Problem 4.5",
    "text": "Problem 4.5"
  },
  {
    "objectID": "lectures/3_categorical_data.html#additional-practice-exploring-categorical-data",
    "href": "lectures/3_categorical_data.html#additional-practice-exploring-categorical-data",
    "title": "Exploring Categorical Data",
    "section": "Additional Practice exploring Categorical Data",
    "text": "Additional Practice exploring Categorical Data\nOnce you’ve loaded the openintro and tidyverse libraries there are many dataset to practice with.\navandia is the name of the dataset explore it using the methods above.\nI’ll explore it myself in the next video."
  },
  {
    "objectID": "lectures/2_sampling.html#overview",
    "href": "lectures/2_sampling.html#overview",
    "title": "Intro to Study Vocabulary",
    "section": "Overview",
    "text": "Overview\nIn this lecture I’ll go over the vocabulary from the text and present some examples."
  },
  {
    "objectID": "lectures/2_sampling.html#read-before-hand",
    "href": "lectures/2_sampling.html#read-before-hand",
    "title": "Intro to Study Vocabulary",
    "section": "",
    "text": "Chapter 2 on Study Design"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#read-before-lecture",
    "href": "lectures/4_Numeric_Data.html#read-before-lecture",
    "title": "Numeric Data",
    "section": "Read before lecture",
    "text": "Read before lecture\nChapter 5 Numeric Data"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#summarizing-distributions",
    "href": "lectures/4_Numeric_Data.html#summarizing-distributions",
    "title": "Numeric Data",
    "section": "Summarizing distributions",
    "text": "Summarizing distributions\nNumeric Data\n\n\nShape, Center, and Spread"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#load-the-libraries",
    "href": "lectures/4_Numeric_Data.html#load-the-libraries",
    "title": "Numeric Data",
    "section": "Load the libraries",
    "text": "Load the libraries\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#histogram",
    "href": "lectures/4_Numeric_Data.html#histogram",
    "title": "Numeric Data",
    "section": "Histogram",
    "text": "Histogram\nSummarize the shape of the distribution of one variable\n\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_histogram()"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#density-plot",
    "href": "lectures/4_Numeric_Data.html#density-plot",
    "title": "Numeric Data",
    "section": "Density plot",
    "text": "Density plot\nSummarize the shape of the distribution of one variable\n\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_density()"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#box-plot",
    "href": "lectures/4_Numeric_Data.html#box-plot",
    "title": "Numeric Data",
    "section": "Box plot",
    "text": "Box plot\nSummarize the shape of the distribution of one variable\n\nggplot(data = penguins, mapping = aes(x = body_mass_g)) +\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#your-turn",
    "href": "lectures/4_Numeric_Data.html#your-turn",
    "title": "Numeric Data",
    "section": "Your turn",
    "text": "Your turn\n\nUse a data graphic to summarize the distribution of the height variable in the starwars data frame."
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#histogram-two-variables",
    "href": "lectures/4_Numeric_Data.html#histogram-two-variables",
    "title": "Numeric Data",
    "section": "Histogram: two variables",
    "text": "Histogram: two variables\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, fill = species)) +\n  geom_histogram()"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#density-plot-two-variables",
    "href": "lectures/4_Numeric_Data.html#density-plot-two-variables",
    "title": "Numeric Data",
    "section": "Density plot: two variables",
    "text": "Density plot: two variables\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, fill = species)) +\n  geom_density(alpha = 0.4)"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#boxplot-two-variables",
    "href": "lectures/4_Numeric_Data.html#boxplot-two-variables",
    "title": "Numeric Data",
    "section": "Boxplot: two variables",
    "text": "Boxplot: two variables\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, fill = species)) +\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#measures-of-center",
    "href": "lectures/4_Numeric_Data.html#measures-of-center",
    "title": "Numeric Data",
    "section": "Measures of center",
    "text": "Measures of center\n\n\nmean: mean()\nmedian: median()\n\n\n\n# When using summarize functions like n() and mean() the words to the left of the = are the column headers.\n\n  summarize(\n    .data = penguins,\n    number_of_penguins = n(),\n    mean_mass = mean(body_mass_g, na.rm = TRUE),\n    median_mass = median(body_mass_g, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 3\n  number_of_penguins mean_mass median_mass\n               &lt;int&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1                344     4202.        4050"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#measures-of-spread",
    "href": "lectures/4_Numeric_Data.html#measures-of-spread",
    "title": "Numeric Data",
    "section": "Measures of spread",
    "text": "Measures of spread\n\n\nstandard deviation: sd()\nvariance: var()\nrange: range()\nIQR: IQR()\n\n\n\n  summarize(\n    .data = penguins,\n    number_of_penguins = n(),\n    sd_mass = sd(body_mass_g, na.rm = TRUE),\n    var_mass = var(body_mass_g, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 3\n  number_of_penguins sd_mass var_mass\n               &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1                344    802.  643131."
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#quantiles",
    "href": "lectures/4_Numeric_Data.html#quantiles",
    "title": "Numeric Data",
    "section": "Quantiles",
    "text": "Quantiles\nMost summary information can be found with the fivnum() or summary() function.\n\n# This is just the five number summary\nfive_number_pengiuns &lt;-fivenum(penguins$body_mass_g)\nfive_number_pengiuns\n\n[1] 2700 3550 4050 4750 6300\n\n#This is the five number plus summary\nsummary(penguins$body_mass_g)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2 \n\n\n\n# This is how you can get the exact quantile. \nquantile(x= penguins$body_mass_g, probs = c(0.25,0.5), na.rm=TRUE)\n\n 25%  50% \n3550 4050"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#graphed-quantiles",
    "href": "lectures/4_Numeric_Data.html#graphed-quantiles",
    "title": "Numeric Data",
    "section": "Graphed Quantiles",
    "text": "Graphed Quantiles\n\n# Note the vertical line showing the 25th percentile. \nggplot(data = penguins, aes(x = body_mass_g)) +\n  geom_density()+\n  geom_vline(xintercept = 3550, color = \"purple\")"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#your-turn-1",
    "href": "lectures/4_Numeric_Data.html#your-turn-1",
    "title": "Numeric Data",
    "section": "Your turn",
    "text": "Your turn\n\nSummarize the distribution of the height variable in the starwars data frame by computing:\n\nthe number of observations\nthe mean\nthe standard deviation\n\nFind the 80th quantile for the height variable in the starwars data."
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#answer-here.",
    "href": "lectures/4_Numeric_Data.html#answer-here.",
    "title": "Numeric Data",
    "section": "Answer here.",
    "text": "Answer here."
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#outliers",
    "href": "lectures/4_Numeric_Data.html#outliers",
    "title": "Numeric Data",
    "section": "Outliers",
    "text": "Outliers\nAlong a number line to locate outliers we first calculate the two bounds\n\n\\[\nL = Q1 - 1.5 \\times IQR \\\\\nU = Q3 + 1.5 \\times IQR\n\\]\nAny values outside that range are considered outliers.\nLet’s do this with penguins mass."
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#calculate-outlier-bounds-in-r",
    "href": "lectures/4_Numeric_Data.html#calculate-outlier-bounds-in-r",
    "title": "Numeric Data",
    "section": "Calculate outlier bounds in R",
    "text": "Calculate outlier bounds in R\n\n# This is the IQR of the penguin's mass\niqr_mass &lt;- IQR(x= penguins$body_mass_g, na.rm = TRUE)\n\nq1 &lt;- five_number_pengiuns[2]\nq3 &lt;- five_number_pengiuns[4]\n\n# This is the lower bound\nq1 - 1.5*iqr_mass \n\n[1] 1750\n\n# This is the upper bound\nq3 + 1.5*iqr_mass\n\n[1] 6550\n\nmin(penguins$body_mass_g, na.rm = TRUE)\n\n[1] 2700\n\nmax(penguins$body_mass_g, na.rm = TRUE)\n\n[1] 6300"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#your-turn-2",
    "href": "lectures/4_Numeric_Data.html#your-turn-2",
    "title": "Numeric Data",
    "section": "Your turn",
    "text": "Your turn\n\nMake a boxplot of mass of the starwars characters\nCalculate the outlier range (by hand or in the computer).\nWho are the outliers?"
  },
  {
    "objectID": "lectures/4_Numeric_Data.html#answer-here",
    "href": "lectures/4_Numeric_Data.html#answer-here",
    "title": "Numeric Data",
    "section": "Answer here",
    "text": "Answer here"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#cats",
    "href": "lectures/6_Linear_regression_part_2.html#cats",
    "title": "Linear Regression part 2",
    "section": "Cats",
    "text": "Cats\n\nCat’s hearts"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#you-try",
    "href": "lectures/6_Linear_regression_part_2.html#you-try",
    "title": "Linear Regression part 2",
    "section": "You try:",
    "text": "You try:\n\n\nIf a cat weighs 3.5 kg how large a heart would we expect?\nCan we estimate the heart size for a 5kg cat?\n\nCaution against extrapolation."
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#solution",
    "href": "lectures/6_Linear_regression_part_2.html#solution",
    "title": "Linear Regression part 2",
    "section": "Solution:",
    "text": "Solution:\nThe equation for the line is\n$ = -0.36 + 4.03 Bwt $\nPlug in 3.5 we get\n\\(\\widehat{Hwt} = -0.36 + 4.03 \\times 3.5 \\\\\n\\widehat{Hwt} = 13.745 \\approx 13.7\\)"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#you-try-calculate-a-residual",
    "href": "lectures/6_Linear_regression_part_2.html#you-try-calculate-a-residual",
    "title": "Linear Regression part 2",
    "section": "You try: calculate a residual",
    "text": "You try: calculate a residual\nThere is a cat in this data that has a heart weight of 11.7 grams and a body weight of 3.5 kilograms. Calculate the residual for this cat."
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#solution-1",
    "href": "lectures/6_Linear_regression_part_2.html#solution-1",
    "title": "Linear Regression part 2",
    "section": "Solution:",
    "text": "Solution:\nThe residual is calculated \\[e = y - \\hat{y}\\]\nWe previously found the value of \\(\\hat{y} = 13.7\\) and we are told \\(y=11.7\\) So we need to subtract those two values to get\n\\[e = y - \\hat{y}\\\\\ne = 11.7-13.7\\\\\ne = -2\\]"
  },
  {
    "objectID": "lectures/6_Linear_regression_part_2.html#solution-with-r-functions",
    "href": "lectures/6_Linear_regression_part_2.html#solution-with-r-functions",
    "title": "Linear Regression part 2",
    "section": "Solution with R functions",
    "text": "Solution with R functions\n\npredict(object =  cat_model, \n        newdata = data.frame(Bwt = 3.5)\n        )\n\n       1 \n13.76256"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html",
    "href": "lectures/5_linear_regression_1_predictor.html",
    "title": "Intro to Linear Regression",
    "section": "",
    "text": "Chapter 7 Linear Regression with a single predictor"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#graph-from-present",
    "href": "lectures/5_linear_regression_1_predictor.html#graph-from-present",
    "title": "Intro to Linear Regression",
    "section": "Graph from Present",
    "text": "Graph from Present\n\nggplot(data = present, aes(x = year, y = boy_ratio)) +\n  geom_point() +\n  labs(title = \"Ratio of boys to girls born US\",\n       subtitle =\"The data comes from `present` in the openintro package\",\n       caption = \"This graph shows the ratio of boys to girls born in the US from the 1940s to the early 2000s\")"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#bivariate-relationships",
    "href": "lectures/5_linear_regression_1_predictor.html#bivariate-relationships",
    "title": "Intro to Linear Regression",
    "section": "Bivariate Relationships",
    "text": "Bivariate Relationships\n\nTwo variables\nResponse variable\nExplanatory variable"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#response",
    "href": "lectures/5_linear_regression_1_predictor.html#response",
    "title": "Intro to Linear Regression",
    "section": "Response",
    "text": "Response\nResponse variable (aka dependent variable): the variable that you are trying to understand/model"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#explanatory",
    "href": "lectures/5_linear_regression_1_predictor.html#explanatory",
    "title": "Intro to Linear Regression",
    "section": "Explanatory",
    "text": "Explanatory\nExplanatory variable (aka independent variable, aka predictor): the variable that you can measure that you think might be related to the response variable"
  },
  {
    "objectID": "lectures/2_sampling.html",
    "href": "lectures/2_sampling.html",
    "title": "Intro to Study Vocabulary",
    "section": "",
    "text": "Chapter 2 on Study Design"
  },
  {
    "objectID": "lectures/2_sampling.html#footnotes",
    "href": "lectures/2_sampling.html#footnotes",
    "title": "Intro to Study Vocabulary",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://en.wikipedia.org/wiki/Blue_whale↩︎"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#examine-the-babies-data",
    "href": "lectures/5_linear_regression_1_predictor.html#examine-the-babies-data",
    "title": "Intro to Linear Regression",
    "section": "Examine the babies data",
    "text": "Examine the babies data\nFrom the babies dataset, let’s make a scatter plot of gestation (explanatory) vs bwt (response).\n\nCharacterize the distribution\n\nForm\nDirection\nStrength\nOutliers"
  },
  {
    "objectID": "lectures/5_linear_regression_1_predictor.html#birthweight-of-babies",
    "href": "lectures/5_linear_regression_1_predictor.html#birthweight-of-babies",
    "title": "Intro to Linear Regression",
    "section": "Birthweight of babies",
    "text": "Birthweight of babies\n\nggplot(data = babies, aes(x = gestation, y = bwt)) +\n  geom_point()\n\n\n\nhelp(babies)"
  },
  {
    "objectID": "lectures/9_Probability_2.html#some-formula.",
    "href": "lectures/9_Probability_2.html#some-formula.",
    "title": "Random Variables",
    "section": "Some formula.",
    "text": "Some formula.\nGeneral Multiplication Rule:\n\\(P(A \\text{ and } B) = P(A|B)P(B)\\)\nLaw of Total Probability:\n\\(P(A) = P(A|B_1)P(B_1)+P(A|B_2)P(B_2)+…+P(A|B_k)P(B_k)\\)\nWhere each \\(B_i\\) is disjoint.\nConditional Probability\n\\(P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\\)"
  },
  {
    "objectID": "lectures/9_Probability_2.html#practice-problems",
    "href": "lectures/9_Probability_2.html#practice-problems",
    "title": "Random Variables",
    "section": "Practice Problems",
    "text": "Practice Problems\n3.14, 3.15"
  },
  {
    "objectID": "lectures/11_continuous_rv.html#reading",
    "href": "lectures/11_continuous_rv.html#reading",
    "title": "Continuous RV",
    "section": "Reading",
    "text": "Reading\nRead chapter 3.5 from Openintro statistics."
  },
  {
    "objectID": "lectures/11_continuous_rv.html#tangent-precision-matters",
    "href": "lectures/11_continuous_rv.html#tangent-precision-matters",
    "title": "Continuous RV",
    "section": "Tangent: Precision matters",
    "text": "Tangent: Precision matters\nWho is 65 inches tall?\nNone of us really know how tall we are exactly."
  },
  {
    "objectID": "lectures/11_continuous_rv.html#cont.-height-density-plot",
    "href": "lectures/11_continuous_rv.html#cont.-height-density-plot",
    "title": "Continuous RV",
    "section": "Cont. Height Density Plot",
    "text": "Cont. Height Density Plot\nWe get slightly different answers if we think about the data as continuous.\nLet X - A Student’s Height"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#read-before-lecture",
    "href": "lectures/12_Normal_Dist.html#read-before-lecture",
    "title": "Normal Distribution",
    "section": "Read before lecture",
    "text": "Read before lecture\nOpen Intro Statistics 4.1 Normal Distribution"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#normal-distribution",
    "href": "lectures/12_Normal_Dist.html#normal-distribution",
    "title": "Normal Distribution",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nThe normal distribution has a symmetric bell shaped curve\n\nlibrary(openintro)\nnormTail()\n\n\nThe picture above is for the so called standard normal distribution."
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#the-standard-normal",
    "href": "lectures/12_Normal_Dist.html#the-standard-normal",
    "title": "Normal Distribution",
    "section": "The Standard Normal",
    "text": "The Standard Normal\nHas a mean \\(\\mu = 0\\) and standard deviation \\(\\sigma = 1\\)\n\nNotation \\(X\\sim N(\\mu,\\sigma)\\) means the random variable X has a normal distribution.\n\nIt is what z-scores are based on. (There are other distributions)."
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#very-short-history-lesson.",
    "href": "lectures/12_Normal_Dist.html#very-short-history-lesson.",
    "title": "Normal Distribution",
    "section": "Very Short history lesson.",
    "text": "Very Short history lesson.\n\n\nLong long ago before computers existed people wanted to calculate probabilities from z-scores.\nThe table was first made by Christian Kramp in 1799.\nIt was improved upon ( for more read this).\nWe will not use the ancient table"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#brushtail-possum",
    "href": "lectures/12_Normal_Dist.html#brushtail-possum",
    "title": "Normal Distribution",
    "section": "Brushtail possum",
    "text": "Brushtail possum"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#problem-from-text",
    "href": "lectures/12_Normal_Dist.html#problem-from-text",
    "title": "Normal Distribution",
    "section": "Problem from text:",
    "text": "Problem from text:\n\nHead lengths of brushtail possums follow a nearly normal distribution (it is also a continuous random variable) with mean 92.6 mm and standard deviation 3.6 mm. Compute the [percentiles] for possums with head lengths of 95.4 mm and 85.8 mm.\nWhich of the two brushtail possum observations in the previous guided practice is more unusual?"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#picture-the-distribution",
    "href": "lectures/12_Normal_Dist.html#picture-the-distribution",
    "title": "Normal Distribution",
    "section": "Picture the distribution",
    "text": "Picture the distribution\n\\(X \\sim N(\\mu = 92.6 , \\sigma = 3.6)\\)\n\nnormTail(m=92.6,s=3.6)"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#z-scores-with-r",
    "href": "lectures/12_Normal_Dist.html#z-scores-with-r",
    "title": "Normal Distribution",
    "section": "Z-scores with R",
    "text": "Z-scores with R\nWe don’t need to find a z-score any more, but we still talk about them.\n\npnorm(q=85.8 ,m = 92.6, s = 3.6 )\n\n[1] 0.02945336\n\n\nThis finds the probability to the left of q.\n\npnorm(q=85.8 ,m = 92.6, s = 3.6, lower.tail = FALSE)\n\n[1] 0.9705466"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#visualize-with-openintro-package",
    "href": "lectures/12_Normal_Dist.html#visualize-with-openintro-package",
    "title": "Normal Distribution",
    "section": "Visualize with openintro package",
    "text": "Visualize with openintro package\n\nlibrary(tidyverse)\nlibrary(openintro)\n\npnorm(q=85.8 ,m = 92.6, s = 3.6, lower.tail = FALSE )\n\n[1] 0.9705466\n\nnormTail(m = 92.6, s= 3.6, U = 85.8)"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#calculus",
    "href": "lectures/12_Normal_Dist.html#calculus",
    "title": "Normal Distribution",
    "section": "Calculus",
    "text": "Calculus\nThe function f(x) below defines the pdf of the bell curve.\n\\[ f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}  e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2 } \\]"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#what-we-really-care-about",
    "href": "lectures/12_Normal_Dist.html#what-we-really-care-about",
    "title": "Normal Distribution",
    "section": "What we really care about:",
    "text": "What we really care about:\nThe probability is the area under the curve and can be represented as:\n\\[ \\int_a^b \\frac{1}{\\sigma \\sqrt{2 \\pi}}  e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2 } dx \\]\nWe will not be computing these values by hand."
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#reminder",
    "href": "lectures/12_Normal_Dist.html#reminder",
    "title": "Normal Distribution",
    "section": "Reminder:",
    "text": "Reminder:\nDraw the curve and the integral that goes with the possum area under the normal distribution."
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#the-empirical-rule.",
    "href": "lectures/12_Normal_Dist.html#the-empirical-rule.",
    "title": "Normal Distribution",
    "section": "The Empirical rule.",
    "text": "The Empirical rule.\nDraw a picture of the standard normal bell curve. Mark -1 and 1 \\(\\sigma\\) away from the mean.\nUsing R find the probability we get values between -1 and 1. shade your picture.\nRepeat this process for [-2,2] and [-3,3]."
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#practice",
    "href": "lectures/12_Normal_Dist.html#practice",
    "title": "Normal Distribution",
    "section": "Practice",
    "text": "Practice\nFrom the text:\n\nSAT scores closely follow the normal model with mean μ=1500 and standard deviation σ=300. About what percent of test takers score 900 to 2100? What percent score between 1500 and 2100"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#practice-2",
    "href": "lectures/12_Normal_Dist.html#practice-2",
    "title": "Normal Distribution",
    "section": "Practice 2",
    "text": "Practice 2\n\nShannon is a randomly selected SAT taker, and nothing is known about Shannon’s SAT aptitude. What is the probability that Shannon scores at least 1630 on their SATs?"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#practice-3",
    "href": "lectures/12_Normal_Dist.html#practice-3",
    "title": "Normal Distribution",
    "section": "Practice 3",
    "text": "Practice 3\n\nEdward earned a 1400 on their SAT. What is their percentile?\n\n\nWhat percent did better than Edward?"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#qnorm-outputs-quantiles-from-percents.",
    "href": "lectures/12_Normal_Dist.html#qnorm-outputs-quantiles-from-percents.",
    "title": "Normal Distribution",
    "section": "qnorm outputs quantiles from percents.",
    "text": "qnorm outputs quantiles from percents.\n\n#|echo: TRUE\n\npnorm(q = 85.8 ,m = 92.6, s = 3.6 )\n\n[1] 0.02945336\n\nqnorm(p = 0.02945336, m = 92.6, s = 3.6)\n\n[1] 85.8\n\n\nqnorm() is for finding quantiles pnorm() is for finding percentiles."
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#practice-4",
    "href": "lectures/12_Normal_Dist.html#practice-4",
    "title": "Normal Distribution",
    "section": "Practice 4",
    "text": "Practice 4\nOI 4.2 d"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#compute-the-mean-and-sd",
    "href": "lectures/12_Normal_Dist.html#compute-the-mean-and-sd",
    "title": "Normal Distribution",
    "section": "Compute the mean and sd",
    "text": "Compute the mean and sd\nNote on notation.\n\\(X \\sim N(\\mu = 92.6 , \\sigma = 3.6)\\)\nor\n\\(X \\sim N(\\bar{x} = 92.6 , s= 3.6)\\)\nWe estimate \\(\\sigma\\) with s - The sample proportion.\n\n# Sample standard deviation\n\nsd(possum$head_l)\n\n[1] 3.573349\n\n# Sample mean\nmean(possum$head_l, na.rm = TRUE)\n\n[1] 92.60288"
  },
  {
    "objectID": "lectures/9_Probability_2.html#reading",
    "href": "lectures/9_Probability_2.html#reading",
    "title": "Random Variables",
    "section": "Reading",
    "text": "Reading\nOpen Intro Statistics 3.2 and 3.4"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#the-graph-for-the-first-possum",
    "href": "lectures/12_Normal_Dist.html#the-graph-for-the-first-possum",
    "title": "Normal Distribution",
    "section": "The graph for the first possum",
    "text": "The graph for the first possum\n\nnormTail(m=92.6,s=3.6, L = 95.4)"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#the-graph-for-the-second-possum",
    "href": "lectures/12_Normal_Dist.html#the-graph-for-the-second-possum",
    "title": "Normal Distribution",
    "section": "The graph for the second possum",
    "text": "The graph for the second possum\n\nnormTail(m=92.6,s=3.6, L = 85.8)"
  },
  {
    "objectID": "lectures/12_Normal_Dist.html#calculate-percentiles-with-r",
    "href": "lectures/12_Normal_Dist.html#calculate-percentiles-with-r",
    "title": "Normal Distribution",
    "section": "Calculate percentiles with R",
    "text": "Calculate percentiles with R\nWe use pnorm() to find percentiles.\n\npnorm(q=85.8 ,m = 92.6, s = 3.6 )\n\n[1] 0.02945336\n\n\nThis finds the probability to the left of q.\n\npnorm(q=85.8 ,m = 92.6, s = 3.6, lower.tail = FALSE)\n\n[1] 0.9705466"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#load-libraries",
    "href": "lectures/13_parametric_boot.html#load-libraries",
    "title": "Bootstrap Hypothesis Test",
    "section": "Load Libraries",
    "text": "Load Libraries\n\n# install.packages(\"infer\")\n\nlibrary(tidyverse)\nlibrary(infer)"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#the-infer-package",
    "href": "lectures/13_parametric_boot.html#the-infer-package",
    "title": "Bootstrap Hypothesis Test",
    "section": "The infer package",
    "text": "The infer package\nGetting to know infer\n\nvignette(\"infer\")"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#parametric-bootstrap-distribution",
    "href": "lectures/13_parametric_boot.html#parametric-bootstrap-distribution",
    "title": "Bootstrap Hypothesis Test",
    "section": "Parametric Bootstrap Distribution",
    "text": "Parametric Bootstrap Distribution\n\n\nThe Parametric Bootstrap simulation assumes the null hypothesis is true then uses the data to construct a bootstrap distribution.\nToday this means for each value in our sample R will choose a success or failure with probability p for each value of n."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#problem-statement",
    "href": "lectures/13_parametric_boot.html#problem-statement",
    "title": "Bootstrap Hypothesis Test",
    "section": "Problem Statement",
    "text": "Problem Statement\nSuppose it is known that nationally out of 100 people struggling with drug addiction, 40 of them will have some blood born disease.\nA doctor at a clinic decides to test this hypothesis for her locality and samples 20 of her own patients. Of the 20 patients she finds 13 of them have a blood born disease.\nIs this evidence enough to say that the locality is different than the proportion nationally?"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#write-out-hypotheses",
    "href": "lectures/13_parametric_boot.html#write-out-hypotheses",
    "title": "Bootstrap Hypothesis Test",
    "section": "Write out hypotheses",
    "text": "Write out hypotheses\n\\[\nH_0: p = 0.40 \\\\\nH_a: p \\ne 0.40\n\\]\n\\[\n\\alpha = 0.05\n\\]"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#make-some-sample-data",
    "href": "lectures/13_parametric_boot.html#make-some-sample-data",
    "title": "Bootstrap Hypothesis Test",
    "section": "Make some sample data",
    "text": "Make some sample data\n\n# This makes a 40% success sample. The rep() function repeats \"disease\" 13 times\n\nclinic_sample &lt;-  c(rep(\"disease\", 13), rep(\"no-disease\", 7))\n\n# This saves the sample as a dataframe\nclinic_sample &lt;- as.data.frame(clinic_sample)\n\n# This changes the name of the variable to \"has_disease\"\nnames(clinic_sample) &lt;-\"has_disease\"\n\nhead(clinic_sample)\n\n  has_disease\n1     disease\n2     disease\n3     disease\n4     disease\n5     disease\n6     disease"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#calculate-p-hat",
    "href": "lectures/13_parametric_boot.html#calculate-p-hat",
    "title": "Bootstrap Hypothesis Test",
    "section": "Calculate p-hat",
    "text": "Calculate p-hat\nWe can calculate \\(\\hat{p} = \\frac{13}{20} = 0.65\\). But could do this:\n\np_hat &lt;- clinic_sample  |&gt;\n  # Telling R what we care about with specify \n  specify(response = has_disease, success = \"disease\") |&gt;\n  \n  # Calculating the proportion\n  calculate(stat = \"prop\")\n\n#Notice how we saved p_hat for later use. \np_hat\n\nResponse: has_disease (factor)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1  0.65"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#create-bootstrap-distribution-w-infer",
    "href": "lectures/13_parametric_boot.html#create-bootstrap-distribution-w-infer",
    "title": "Bootstrap Hypothesis Test",
    "section": "Create bootstrap distribution w/ infer()",
    "text": "Create bootstrap distribution w/ infer()\n\n# setting a seed\nset.seed(2024)\n\n# Saving the df\nclinic_sample  |&gt;\n  \n  # Here we specify() what is a success\n  specify(response = has_disease, success = \"disease\") |&gt;\n  \n  # This is where we set the null hypothesis\n  hypothesize(null = \"point\", p = 0.40) |&gt;\n  \n  # This is how many times R will sample from the clinic sample\n  # We are using draw to sample 1 value from a theoretical distribution with p = 0.40. \n  generate(reps = 1, type = \"draw\") |&gt;\n  \n  # This groups the reps together to find a proportion. \n  calculate(stat = \"prop\")\n\nResponse: has_disease (factor)\nNull Hypothesis: point\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1   0.5"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#more-replications",
    "href": "lectures/13_parametric_boot.html#more-replications",
    "title": "Bootstrap Hypothesis Test",
    "section": "More replications",
    "text": "More replications\nWe want to do this process a lot to create the bootstrap distribution.\n\n# setting a seed\nset.seed(2024)\n\n# Saving the df\nnull_distn_one_prop &lt;- clinic_sample  |&gt;\n  \n  # Here we tell specify what is a success\n  specify(response = has_disease, success = \"disease\") |&gt;\n  \n  # This is where we set the null hypothesis\n  hypothesize(null = \"point\", p = 0.4) |&gt;\n  \n  # Choosing 10000 replications\n  generate(reps = 10000, type = \"draw\") |&gt;\n  \n  # This is calculating a proportion for each sample\n  calculate(stat = \"prop\")"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#visualize-the-bootstrap-distribution.",
    "href": "lectures/13_parametric_boot.html#visualize-the-bootstrap-distribution.",
    "title": "Bootstrap Hypothesis Test",
    "section": "visualize() the bootstrap distribution.",
    "text": "visualize() the bootstrap distribution.\n\n# cheater function to graph, works like ggplot(), but we don't need aes()\nvisualize(data = null_distn_one_prop)"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#shade_p_value",
    "href": "lectures/13_parametric_boot.html#shade_p_value",
    "title": "Bootstrap Hypothesis Test",
    "section": "shade_p_value()",
    "text": "shade_p_value()\n\n# shade the p value\nvisualize(data = null_distn_one_prop)+\n  shade_p_value(obs_stat = p_hat, direction = \"both\")"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#we-can-use-get_pvalue",
    "href": "lectures/13_parametric_boot.html#we-can-use-get_pvalue",
    "title": "Bootstrap Hypothesis Test",
    "section": "We can use get_pvalue()",
    "text": "We can use get_pvalue()\n\n# get the pvalue to use. \nget_pvalue(x = null_distn_one_prop,\n             obs_stat = p_hat, \n             direction = \"both\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1  0.0392"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#make-a-parametric-bootstrap-distribution",
    "href": "lectures/13_parametric_boot.html#make-a-parametric-bootstrap-distribution",
    "title": "Bootstrap Hypothesis Test",
    "section": "Make a parametric bootstrap distribution",
    "text": "Make a parametric bootstrap distribution\nYou have a bag of marbles\n\nTake one out, note its color, and replace it.\nDo this 20 times. (Don’t look at the marbles).\nFind the proportion of reds in those 20 times. (This is one full repetition).\nEach person should do this once.\nAdd your proportions to the chalkboard graph."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#should-we-do-this-problem-again-with-a-mathematical-model.",
    "href": "lectures/13_parametric_boot.html#should-we-do-this-problem-again-with-a-mathematical-model.",
    "title": "Bootstrap Hypothesis Test",
    "section": "Should we do this problem again with a mathematical model.",
    "text": "Should we do this problem again with a mathematical model.\nWe should be hesitant, it does not meet the success-failure criterion and the sample is small."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#problem-11-twice",
    "href": "lectures/13_parametric_boot.html#problem-11-twice",
    "title": "Bootstrap Hypothesis Test",
    "section": "Problem 11 twice",
    "text": "Problem 11 twice\nWe’ll do it once with the parametric bootstrap and once with a mathematical model."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#problem-11-ch-16",
    "href": "lectures/13_parametric_boot.html#problem-11-ch-16",
    "title": "Bootstrap Hypothesis Test",
    "section": "Problem 11, Ch 16",
    "text": "Problem 11, Ch 16\nStatistics and employment In a large university where 70% of the full-time students are employed at least 5 hours per week, the members of the Statistics Department wonder if a smaller proportion of their students work at least 5 hours per week. They randomly sample 25 majors and find that 15 of the students work 5 or more hours each week."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#make-sample",
    "href": "lectures/13_parametric_boot.html#make-sample",
    "title": "Bootstrap Hypothesis Test",
    "section": "Make sample",
    "text": "Make sample\n\n# This creates a vector of 152 \"Trues\" and 51 \"Falses\"\nmore_than_1_relationship &lt;- c(\n  rep(TRUE, 152),\n  rep(FALSE, 51)\n) \n\n#This takes the vector and saves it as a data frame so we can us it. \nmore_than_1_relationship &lt;- as.data.frame(more_than_1_relationship)"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#make-hypotheses",
    "href": "lectures/13_parametric_boot.html#make-hypotheses",
    "title": "Bootstrap Hypothesis Test",
    "section": "Make Hypotheses",
    "text": "Make Hypotheses\n\\[\nH_0: p = 0.7 \\\\\nH_a: p &lt; 0.7\n\\]\n\\[\n\\alpha = 0.05\n\\]"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#make-p-hat",
    "href": "lectures/13_parametric_boot.html#make-p-hat",
    "title": "Bootstrap Hypothesis Test",
    "section": "Make p-hat",
    "text": "Make p-hat\np-hat:\n\n# There is no simulation happening here. Notice the pipes.\n# We are saving p_hat for later... It might be easier to type\n# p_hat &lt;- 15/25\np_hat &lt;- major_sample  |&gt;\n  \n  # specify which variable you are interested in, and which level is a success (our level is \"yes\")\n  specify(response = work, success = \"yes\") |&gt;\n  \n  # What is the statsitic we want calculated?\n  calculate(stat = \"prop\")"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#create-parametric-distribution-w-infer",
    "href": "lectures/13_parametric_boot.html#create-parametric-distribution-w-infer",
    "title": "Bootstrap Hypothesis Test",
    "section": "Create parametric distribution w/ infer()",
    "text": "Create parametric distribution w/ infer()\n\nset.seed(2018)\n\n\nnull_distn_one_prop &lt;- major_sample |&gt;\n  \n  specify(response = work, success = \"yes\") |&gt;\n  \n  hypothesize(null = \"point\", p = 0.70) |&gt;\n  \n  generate(reps = 10000) |&gt;\n  \n  calculate(stat = \"prop\")"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#visualize",
    "href": "lectures/13_parametric_boot.html#visualize",
    "title": "Bootstrap Hypothesis Test",
    "section": "visualize()",
    "text": "visualize()\n\n#|echo: true\n\n# I'm leaving off the data argument here. \nvisualise(null_distn_one_prop)"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#add-the-p-value-to-graph",
    "href": "lectures/13_parametric_boot.html#add-the-p-value-to-graph",
    "title": "Bootstrap Hypothesis Test",
    "section": "Add the p-value to graph",
    "text": "Add the p-value to graph\n\nvisualize(null_distn_one_prop) +\n  shade_p_value(obs_stat = p_hat, direction = \"less\")"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#get_pvalue",
    "href": "lectures/13_parametric_boot.html#get_pvalue",
    "title": "Bootstrap Hypothesis Test",
    "section": "get_pvalue()",
    "text": "get_pvalue()\n\npvalue &lt;- null_distn_one_prop %&gt;%\n  get_pvalue(obs_stat = p_hat, direction = \"less\")\npvalue\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1   0.188"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#make-conclusion",
    "href": "lectures/13_parametric_boot.html#make-conclusion",
    "title": "Bootstrap Hypothesis Test",
    "section": "Make conclusion",
    "text": "Make conclusion\nFail to reject the null hypothesis. It seems that stats majors work the same amount as other students based on our sample.\nCould have made a type two error. We failed to reject the null hypothesis when it was incorrect."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#again-with-math.",
    "href": "lectures/13_parametric_boot.html#again-with-math.",
    "title": "Bootstrap Hypothesis Test",
    "section": "Again with math.",
    "text": "Again with math.\nConditions are met.\nHypothesis notation is the same.\nThe assumed proportion is 0.7, the standard error is\n\\[\nSE = \\sqrt{\\frac{(0.7)(0.3)}{25}} = 0.09165151\n\\]\nThe distribution of the null is.\n\\[\nX \\sim N(p = 0.7, SE = 0.092)\n\\]"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#calculate-the-p-value-for-p_hat",
    "href": "lectures/13_parametric_boot.html#calculate-the-p-value-for-p_hat",
    "title": "Bootstrap Hypothesis Test",
    "section": "Calculate the p-value for p_hat",
    "text": "Calculate the p-value for p_hat\nWe saved p_hat earlier, it should still be in your environment.\n\npnorm(q = 0.6, mean = 0.7, sd = 0.09165151)\n\n[1] 0.1376168"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#conclusion",
    "href": "lectures/13_parametric_boot.html#conclusion",
    "title": "Bootstrap Hypothesis Test",
    "section": "Conclusion",
    "text": "Conclusion\nThe conclusion is the same as the first lecture from homework 6. The pvalue is much smaller than 0.05 so it is likely that a majority of students have had more than 1 exclusive relationship."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#example-ebola",
    "href": "lectures/12_hypothesis_test_prop.html#example-ebola",
    "title": "Hypothesis Testing",
    "section": "Example: Ebola",
    "text": "Example: Ebola\n\n\nPretend: We are studying how New Yorkers feel about a mandatory 14 day quarantine for Ebola exposure.\nWe ask: do you favor a “mandatory 14-day quarantine for anyone who has come in contact with an Ebola patient?”\n\n\nEbola in New York City"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#survey-data",
    "href": "lectures/12_hypothesis_test_prop.html#survey-data",
    "title": "Hypothesis Testing",
    "section": "Survey Data",
    "text": "Survey Data\nOur question: We want to know how New Yorkers feel on quarantine of Ebola after the COVID-19 pandemic."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#the-2014-data",
    "href": "lectures/12_hypothesis_test_prop.html#the-2014-data",
    "title": "Hypothesis Testing",
    "section": "The 2014 data",
    "text": "The 2014 data\nWe have past data to compare to from 2014. Its called ebola_survey and is our best guess as how New Yorkers felt about mandatory quarantine pre pandemic. This will be our assumed \\(p\\).\n\n\n# A tibble: 2 × 2\n  quarantine     n\n  &lt;fct&gt;      &lt;int&gt;\n1 against      188\n2 favor        854\n\n\n\\(p= 854/1042 \\approx 0.82\\) This is a reasonable estimate for p because we have not other data to the contrary."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#lets-now-assume-we-did-a-follow-up",
    "href": "lectures/12_hypothesis_test_prop.html#lets-now-assume-we-did-a-follow-up",
    "title": "Hypothesis Testing",
    "section": "Let’s now assume we did a follow up:",
    "text": "Let’s now assume we did a follow up:\nWe ask 1000 people if they favor a mandatory 14 day quarantine for individuals that have been in contact with Ebola.\nHere are the results.\n\n\n# A tibble: 1 × 2\n  against favor\n    &lt;dbl&gt; &lt;dbl&gt;\n1     486   514\n\n\nAnd so \\(\\hat{p} = 514/1000 = 0.514\\) Which seems very different from \\(p=0.82\\)"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#p-vs-hatp",
    "href": "lectures/12_hypothesis_test_prop.html#p-vs-hatp",
    "title": "Hypothesis Testing",
    "section": "p vs \\(\\hat{p}\\)",
    "text": "p vs \\(\\hat{p}\\)\n\n\n\\(\\hat{p}\\) - the sample statistic. It is a proportion in this case.\n\nThis is how the current sample of New Yorkers feel about a mandatory quarantine.\n\np - The assumed population parameter, also a proportion.\n\nWe assume this is how all New Yorkers feel about a mandatory quarantine."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#the-question.",
    "href": "lectures/12_hypothesis_test_prop.html#the-question.",
    "title": "Hypothesis Testing",
    "section": "The question.",
    "text": "The question.\n\nIf the sentiment from 2014 New Yorkers is unchanged today, what is the probability we would have gotten \\(\\hat{p} = 0.514\\) based on the 2014 sample?\n\n\n\nIs it likely or unlikely\n\nLikely will be anything more than \\(\\alpha = 0.05\\)\nIf less than 0.05, we reject \\(H_0\\)"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#notation",
    "href": "lectures/12_hypothesis_test_prop.html#notation",
    "title": "Hypothesis Testing",
    "section": "Notation",
    "text": "Notation\nHypothesis testing with Proportions\n\\[\nH_0: p = 0.82 \\\\\nH_A: p \\ne 0.82\n\\]\nNull and Alternative hypotheses.\nWe assume the null hypothesis is true and build a theoretical sampling distribution from that."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#the-central-limit-theorem",
    "href": "lectures/12_hypothesis_test_prop.html#the-central-limit-theorem",
    "title": "Hypothesis Testing",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\nThis is what allows us to build the sampling distribution.\n\nIf we look at a proportion and the scenario satisfies certain conditions, then the distribution of sample proportions will appear to follow a bell-shaped curve called the normal distribution.\n\nThis is the point of the recent R Assignment. If we could sample repeatedly from a population, the shape from the statistics in those samples would be normal."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#condition-on-h_0",
    "href": "lectures/12_hypothesis_test_prop.html#condition-on-h_0",
    "title": "Hypothesis Testing",
    "section": "Condition on \\(H_0\\)",
    "text": "Condition on \\(H_0\\)\nProportions:\n\nSuccess Failure condition\n\n10 successes or \\(n(p_0) &gt; 10\\)\n10 failures or \\(n(1-p_0) &gt; 10\\)\n\nLarge Independent Samples (n&gt;30)"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#draw-the-sampling-distribution",
    "href": "lectures/12_hypothesis_test_prop.html#draw-the-sampling-distribution",
    "title": "Hypothesis Testing",
    "section": "Draw the Sampling Distribution",
    "text": "Draw the Sampling Distribution\n\\[ p \\sim N(p_0,SE)\\]\nWith \\[SE= \\sqrt{\\frac{p_0(1-p_0)}{n}}\\]\nnote that n is the sample size from our current study."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#conclusion",
    "href": "lectures/12_hypothesis_test_prop.html#conclusion",
    "title": "Hypothesis Testing",
    "section": "Conclusion",
    "text": "Conclusion\nWith a p-value of zero it is extremely unlikely that we would have gotten 0.514 if the true distribution was centered at 0.82. So the distribution is likely not really centered around 0.82 and so we reject the null hypothesis that p=0.82.\nSo the true proportion of New Yorkers that believe there should be a mandatory 14 day quarantine is not 0.82, but some other number."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#practice-1.-exclusive-relationships",
    "href": "lectures/12_hypothesis_test_prop.html#practice-1.-exclusive-relationships",
    "title": "Hypothesis Testing",
    "section": "Practice 1. Exclusive relationships",
    "text": "Practice 1. Exclusive relationships\nHave a majority of college students had more than 1 exclusive_relationship?\n\n\n# A tibble: 3 × 2\n  `num &gt; 1`     n\n  &lt;lgl&gt;     &lt;int&gt;\n1 FALSE        51\n2 TRUE        152\n3 NA           15\n\n\n\nCheck Conditions.\nDo the test with math.\nDo the test with simulation."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#with-math.",
    "href": "lectures/12_hypothesis_test_prop.html#with-math.",
    "title": "Hypothesis Testing",
    "section": "With math.",
    "text": "With math.\nWe are testing against 50%. We’ve already checked the conditions for the mathematical test. Now we:\n\nCheck conditions\nWrite hypothesis notation.\nWrite the notation for the distribution of sample proportions.\n\nfind the theoretical proportion\nfind the standard error\n\nFind the probability we would get \\(\\hat{p} = 152/203 = 0.749\\) based on the null hypothesis.\nMake the conclusion."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#hypothesis-notation",
    "href": "lectures/12_hypothesis_test_prop.html#hypothesis-notation",
    "title": "Hypothesis Testing",
    "section": "Hypothesis notation",
    "text": "Hypothesis notation\n\\[\nH_0: p = 0.5 \\\\\nH_A: p &gt; 0.5\n\\]\n\\[\n\\alpha = 0.05\n\\]"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#notation-for-the-sampling-distribution",
    "href": "lectures/12_hypothesis_test_prop.html#notation-for-the-sampling-distribution",
    "title": "Hypothesis Testing",
    "section": "Notation for the sampling distribution",
    "text": "Notation for the sampling distribution\nWe have \\(p =0.5\\) We need to find the standard error.\n\\[\nSE = \\sqrt{\\frac{(p)(1-p)}{n}}=\\sqrt{\\frac{(0.5)(0.5)}{203}} = 0.03509312\n\\]\n\\[\np \\sim N(p = 0.5, SE = 0.035)\n\\]"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#probability-of-hatp",
    "href": "lectures/12_hypothesis_test_prop.html#probability-of-hatp",
    "title": "Hypothesis Testing",
    "section": "Probability of \\(\\hat{p}\\)",
    "text": "Probability of \\(\\hat{p}\\)\nIf the distribution from the last slide is correct what is the probability we would find \\(\\hat{p}=0.749\\) from our sample.\n\nnormTail(m = 0.5, s = 0.03509312, U = 0.7487685)\n\npnorm(q = 0.7487685 , mean=0.5,sd = 0.03509312, lower.tail = FALSE)\n\n[1] 6.763449e-13"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#conclusion-1",
    "href": "lectures/12_hypothesis_test_prop.html#conclusion-1",
    "title": "Hypothesis Testing",
    "section": "Conclusion",
    "text": "Conclusion\nWe get 6.763449e-13 (0.0000000000006), which is much smaller than 0.05. We reject the null hypothesis and state that its very likely that a majority of students have been in more than one exclusive relationship."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#decision-error",
    "href": "lectures/12_hypothesis_test_prop.html#decision-error",
    "title": "Hypothesis Testing",
    "section": "Decision Error",
    "text": "Decision Error\nWe could have made a type 1 error, and rejected the null hypothesis if it were actually true.\nMore on decision errors later."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#same-problem-with-simulation.",
    "href": "lectures/12_hypothesis_test_prop.html#same-problem-with-simulation.",
    "title": "Hypothesis Testing",
    "section": "Same problem with simulation.",
    "text": "Same problem with simulation.\n\nMake sample\nWrite hypothesis notation.\nCreate the simulated distribution.\nFind the probability we would get \\(\\hat{p} = 152/203 = 0.749\\) based on the null hypothesis.\nMake the conclusion."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#make-sample",
    "href": "lectures/12_hypothesis_test_prop.html#make-sample",
    "title": "Hypothesis Testing",
    "section": "Make sample",
    "text": "Make sample\n\n# This creates a vector of 152 \"Trues\" and 51 \"Falses\"\nmore_than_1_relationship &lt;- c(\n  rep(TRUE, 152),\n  rep(FALSE, 51)\n) \n\n#This takes the vector and saves it as a data frame so we can us it. \nmore_than_1_relationship &lt;- as.data.frame(more_than_1_relationship)"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#hypothesis-notation-1",
    "href": "lectures/12_hypothesis_test_prop.html#hypothesis-notation-1",
    "title": "Hypothesis Testing",
    "section": "Hypothesis notation",
    "text": "Hypothesis notation\nThis part is the same.\n\\[\nH_0: p = 0.5 \\\\\nH_A: p &gt; 0.5\n\\]\n\\[\n\\alpha = 0.05\n\\]"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#side-note-the-pipe",
    "href": "lectures/12_hypothesis_test_prop.html#side-note-the-pipe",
    "title": "Hypothesis Testing",
    "section": "Side note the pipe |>",
    "text": "Side note the pipe |&gt;\nYou may have noticed the occasional symbols |&gt; or %&gt;%.\nThis is called a pipe and it is an R operator that takes the output of the previous line of code and puts it into the first argument of the next line of code.\nIt often makes code easier to read, but can be confusing for first time programmers.\nFor this reason I have been avoiding it, until now."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#create-simulated-distribution",
    "href": "lectures/12_hypothesis_test_prop.html#create-simulated-distribution",
    "title": "Hypothesis Testing",
    "section": "Create simulated distribution",
    "text": "Create simulated distribution\n\nlibrary(infer)\n\n# Saving all the proportions we'll make\nnull_distn_one_prop &lt;- more_than_1_relationship  |&gt;\n  \n  # Here we tell specify what is a success\n  specify(response = more_than_1_relationship, success = \"TRUE\") |&gt;\n  \n  # This is where we set the null hypothesis\n  hypothesize(null = \"point\", p = 0.5) |&gt;\n  \n  # Choosing 10000 replications\n  generate(reps = 5000, type = \"draw\") |&gt;\n  \n  # This is \n  calculate(stat = \"prop\")"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#examine-the-samples.",
    "href": "lectures/12_hypothesis_test_prop.html#examine-the-samples.",
    "title": "Hypothesis Testing",
    "section": "Examine the samples.",
    "text": "Examine the samples.\n\n#visualize is a graphing function, based on ggplot, for the infer package. \n\nvisualise(data = null_distn_one_prop)"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#calculate-the-p-value-based-on-simulation",
    "href": "lectures/12_hypothesis_test_prop.html#calculate-the-p-value-based-on-simulation",
    "title": "Hypothesis Testing",
    "section": "Calculate the p-value based on simulation",
    "text": "Calculate the p-value based on simulation\nVisualize the pvalue\n\nvisualise(data = null_distn_one_prop) +\n  shade_p_value(obs_stat = 0.749, direction = \"greater\")"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#conclusion-2",
    "href": "lectures/12_hypothesis_test_prop.html#conclusion-2",
    "title": "Hypothesis Testing",
    "section": "Conclusion",
    "text": "Conclusion\nThe conclusion is the same. The pvalue is much smaller than 0.05 so it is likely that a majority of students have had more than 1 exclusive relationship."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#mathematical-vs.-simulation",
    "href": "lectures/12_hypothesis_test_prop.html#mathematical-vs.-simulation",
    "title": "Hypothesis Testing",
    "section": "Mathematical vs. simulation",
    "text": "Mathematical vs. simulation\nBoth methods are valid and often end at the same conclusion\nMath uses formula based on conditions which must be checked. A theoretical distribution is built and probabilities calculates.\nAlternatively a simulated distribution is built, which makes a simulated sampling distribution which is very similar to the theoretical distribution, conditions can be relaxed because we can visibly verify that the distribution is normal."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#homework",
    "href": "lectures/12_hypothesis_test_prop.html#homework",
    "title": "Hypothesis Testing",
    "section": "Homework",
    "text": "Homework\nOn your homework you will use the math formula to make a theoretical distribution and calculate probabilities."
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#r-assignment",
    "href": "lectures/12_hypothesis_test_prop.html#r-assignment",
    "title": "Hypothesis Testing",
    "section": "R Assignment",
    "text": "R Assignment\nYou will make a simulated distribution of your own and find pvalues in a future R Assignment.\nWe’ll look at another example in the next video."
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#read-before-lecture",
    "href": "lectures/11_Normal_Dist.html#read-before-lecture",
    "title": "Normal Distribution",
    "section": "Read before lecture",
    "text": "Read before lecture\nOpen Intro Statistics 4.1 Normal Distribution"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#normal-distribution",
    "href": "lectures/11_Normal_Dist.html#normal-distribution",
    "title": "Normal Distribution",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nThe normal distribution has a symmetric bell shaped curve\n\nlibrary(openintro)\nnormTail()\n\n\nThe picture above is for the so called standard normal distribution."
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#the-standard-normal",
    "href": "lectures/11_Normal_Dist.html#the-standard-normal",
    "title": "Normal Distribution",
    "section": "The Standard Normal",
    "text": "The Standard Normal\nHas a mean \\(\\mu = 0\\) and standard deviation \\(\\sigma = 1\\)\n\nNotation \\(X\\sim N(\\mu,\\sigma)\\) means the random variable X has a normal distribution.\n\nIt is what z-scores are based on. (There are other distributions)."
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#very-short-history-lesson.",
    "href": "lectures/11_Normal_Dist.html#very-short-history-lesson.",
    "title": "Normal Distribution",
    "section": "Very Short history lesson.",
    "text": "Very Short history lesson.\n\n\nLong long ago before computers existed people wanted to calculate probabilities from z-scores.\nThe table was first made by Christian Kramp in 1799.\nIt was improved upon ( for more read this).\nWe will not use the ancient table"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#brushtail-possum",
    "href": "lectures/11_Normal_Dist.html#brushtail-possum",
    "title": "Normal Distribution",
    "section": "Brushtail possum",
    "text": "Brushtail possum"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#problem-from-text",
    "href": "lectures/11_Normal_Dist.html#problem-from-text",
    "title": "Normal Distribution",
    "section": "Problem from text:",
    "text": "Problem from text:\n\nHead lengths of brushtail possums follow a nearly normal distribution (it is also a continuous random variable) with mean 92.6 mm and standard deviation 3.6 mm. Compute the [percentiles] for possums with head lengths of 95.4 mm and 85.8 mm.\nWhich of the two brushtail possum observations in the previous guided practice is more unusual?"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#picture-the-distribution",
    "href": "lectures/11_Normal_Dist.html#picture-the-distribution",
    "title": "Normal Distribution",
    "section": "Picture the distribution",
    "text": "Picture the distribution\n\\(X \\sim N(\\mu = 92.6 , \\sigma = 3.6)\\)\n\nnormTail(m=92.6,s=3.6)"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#the-graph-for-the-first-possum",
    "href": "lectures/11_Normal_Dist.html#the-graph-for-the-first-possum",
    "title": "Normal Distribution",
    "section": "The graph for the first possum",
    "text": "The graph for the first possum\n\nnormTail(m=92.6,s=3.6, L = 95.4)"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#the-graph-for-the-second-possum",
    "href": "lectures/11_Normal_Dist.html#the-graph-for-the-second-possum",
    "title": "Normal Distribution",
    "section": "The graph for the second possum",
    "text": "The graph for the second possum\n\nnormTail(m=92.6,s=3.6, L = 85.8)"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#calculate-percentiles-with-r",
    "href": "lectures/11_Normal_Dist.html#calculate-percentiles-with-r",
    "title": "Normal Distribution",
    "section": "Calculate percentiles with R",
    "text": "Calculate percentiles with R\nWe use pnorm() to find percentiles.\n\npnorm(q=85.8 ,m = 92.6, s = 3.6 )\n\n[1] 0.02945336\n\n\nThis finds the probability to the left of q.\n\npnorm(q=85.8 ,m = 92.6, s = 3.6, lower.tail = FALSE)\n\n[1] 0.9705466"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#visualize-with-openintro-package",
    "href": "lectures/11_Normal_Dist.html#visualize-with-openintro-package",
    "title": "Normal Distribution",
    "section": "Visualize with openintro package",
    "text": "Visualize with openintro package\n\nlibrary(tidyverse)\nlibrary(openintro)\n\npnorm(q=85.8 ,m = 92.6, s = 3.6, lower.tail = FALSE )\n\n[1] 0.9705466\n\nnormTail(m = 92.6, s= 3.6, U = 85.8)"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#calculus",
    "href": "lectures/11_Normal_Dist.html#calculus",
    "title": "Normal Distribution",
    "section": "Calculus",
    "text": "Calculus\nThe function f(x) below defines the pdf of the bell curve.\n\\[ f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}  e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2 } \\]"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#what-we-really-care-about",
    "href": "lectures/11_Normal_Dist.html#what-we-really-care-about",
    "title": "Normal Distribution",
    "section": "What we really care about:",
    "text": "What we really care about:\nThe probability is the area under the curve and can be represented as:\n\\[ \\int_a^b \\frac{1}{\\sigma \\sqrt{2 \\pi}}  e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2 } dx \\]\nWe will not be computing these values by hand."
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#reminder",
    "href": "lectures/11_Normal_Dist.html#reminder",
    "title": "Normal Distribution",
    "section": "Reminder:",
    "text": "Reminder:\nDraw the curve and the integral that goes with the possum area under the normal distribution."
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#the-empirical-rule.",
    "href": "lectures/11_Normal_Dist.html#the-empirical-rule.",
    "title": "Normal Distribution",
    "section": "The Empirical rule.",
    "text": "The Empirical rule.\nDraw a picture of the standard normal bell curve. Mark -1 and 1 \\(\\sigma\\) away from the mean.\nUsing R find the probability we get values between -1 and 1. shade your picture.\nRepeat this process for [-2,2] and [-3,3]."
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#practice",
    "href": "lectures/11_Normal_Dist.html#practice",
    "title": "Normal Distribution",
    "section": "Practice",
    "text": "Practice\nFrom the text:\n\nSAT scores closely follow the normal model with mean μ=1500 and standard deviation σ=300. About what percent of test takers score 900 to 2100? What percent score between 1500 and 2100"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#practice-2",
    "href": "lectures/11_Normal_Dist.html#practice-2",
    "title": "Normal Distribution",
    "section": "Practice 2",
    "text": "Practice 2\n\nShannon is a randomly selected SAT taker, and nothing is known about Shannon’s SAT aptitude. What is the probability that Shannon scores at least 1630 on their SATs?"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#practice-3",
    "href": "lectures/11_Normal_Dist.html#practice-3",
    "title": "Normal Distribution",
    "section": "Practice 3",
    "text": "Practice 3\n\nEdward earned a 1400 on their SAT. What is their percentile?\n\n\nWhat percent did better than Edward?"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#qnorm-outputs-quantiles-from-percents.",
    "href": "lectures/11_Normal_Dist.html#qnorm-outputs-quantiles-from-percents.",
    "title": "Normal Distribution",
    "section": "qnorm outputs quantiles from percents.",
    "text": "qnorm outputs quantiles from percents.\n\n#|echo: TRUE\n\npnorm(q = 85.8 ,m = 92.6, s = 3.6 )\n\n[1] 0.02945336\n\nqnorm(p = 0.02945336, m = 92.6, s = 3.6)\n\n[1] 85.8\n\n\nqnorm() is for finding quantiles pnorm() is for finding percentiles."
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#practice-4",
    "href": "lectures/11_Normal_Dist.html#practice-4",
    "title": "Normal Distribution",
    "section": "Practice 4",
    "text": "Practice 4\nOI 4.2 d"
  },
  {
    "objectID": "lectures/11_Normal_Dist.html#compute-the-mean-and-sd",
    "href": "lectures/11_Normal_Dist.html#compute-the-mean-and-sd",
    "title": "Normal Distribution",
    "section": "Compute the mean and sd",
    "text": "Compute the mean and sd\nNote on notation.\n\\(X \\sim N(\\mu = 92.6 , \\sigma = 3.6)\\)\nor\n\\(X \\sim N(\\bar{x} = 92.6 , s= 3.6)\\)\nWe estimate \\(\\sigma\\) with s - The sample proportion.\n\n# Sample standard deviation\n\nsd(possum$head_l)\n\n[1] 3.573349\n\n# Sample mean\nmean(possum$head_l, na.rm = TRUE)\n\n[1] 92.60288"
  },
  {
    "objectID": "lectures/10_continuous_rv.html#reading",
    "href": "lectures/10_continuous_rv.html#reading",
    "title": "Continuous RV",
    "section": "Reading",
    "text": "Reading\nRead chapter 3.5 from Openintro statistics."
  },
  {
    "objectID": "lectures/10_continuous_rv.html#continuous-rv",
    "href": "lectures/10_continuous_rv.html#continuous-rv",
    "title": "Continuous RV",
    "section": "Continuous RV",
    "text": "Continuous RV\n\n\nA continuous random variable can take any numeric value.\n(Discrete can only take integers.)\nX- Face value of a die\nY- Sum of two die.\nX and Y are discrete r.v. because their outcomes are whole numbers."
  },
  {
    "objectID": "lectures/10_continuous_rv.html#height",
    "href": "lectures/10_continuous_rv.html#height",
    "title": "Continuous RV",
    "section": "Height",
    "text": "Height\nX- height (inches)\nX is a continuous random variable.\n(people usually report is as a discrete RV.)"
  },
  {
    "objectID": "lectures/10_continuous_rv.html#tangent-precision-matters",
    "href": "lectures/10_continuous_rv.html#tangent-precision-matters",
    "title": "Continuous RV",
    "section": "Tangent: Precision matters",
    "text": "Tangent: Precision matters\nWho is 65 inches tall?\nNone of us really know how tall we are exactly."
  },
  {
    "objectID": "lectures/10_continuous_rv.html#convenience-sample-on-heights",
    "href": "lectures/10_continuous_rv.html#convenience-sample-on-heights",
    "title": "Continuous RV",
    "section": "Convenience Sample on heights",
    "text": "Convenience Sample on heights\nLast semester my in person class told me how tall they are. I made a histogram of their heights."
  },
  {
    "objectID": "lectures/10_continuous_rv.html#probabilities-from-our-sample",
    "href": "lectures/10_continuous_rv.html#probabilities-from-our-sample",
    "title": "Continuous RV",
    "section": "Probabilities from our sample",
    "text": "Probabilities from our sample\nThere are 34 students in my sample (n = 34).\nTreat the data as discrete.\n\nEstimate the following probabilities.\n\nP( X &lt; 65 )\nP( 60 &lt; X &lt; 63 )\nP( X = 65 )\n\n\n\n\nheights\n59 61 62 63 64 65 66 67 68 69 70 71 \n 1  4  3  4  6  2  2  3  2  4  2  1"
  },
  {
    "objectID": "lectures/10_continuous_rv.html#cont.-height-density-plot",
    "href": "lectures/10_continuous_rv.html#cont.-height-density-plot",
    "title": "Continuous RV",
    "section": "Cont. Height Density Plot",
    "text": "Cont. Height Density Plot\nWe get slightly different answers if we think about the data as continuous.\nLet X - A Student’s Height"
  },
  {
    "objectID": "lectures/10_continuous_rv.html#probability-height-questions",
    "href": "lectures/10_continuous_rv.html#probability-height-questions",
    "title": "Continuous RV",
    "section": "Probability Height Questions",
    "text": "Probability Height Questions\nLet’s pretend our sample is representative of all students\n\n\nP( X &lt; 65 )\nP( 60 &lt; X &lt; 63 )\nP( X = 65 )\n\nCannot be equal to exactly 1 number with continuous distributions. There is an \\(\\infty\\) number of values."
  },
  {
    "objectID": "lectures/10_continuous_rv.html#you-try.",
    "href": "lectures/10_continuous_rv.html#you-try.",
    "title": "Continuous RV",
    "section": "You try.",
    "text": "You try.\n3.37"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#calculate-the-p-value",
    "href": "lectures/12_hypothesis_test_prop.html#calculate-the-p-value",
    "title": "Hypothesis Testing",
    "section": "Calculate the p-value",
    "text": "Calculate the p-value\n\nget_p_value(x = null_distn_one_prop, \n            obs_stat = 0.749,\n            direction = 'greater')\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#create-one-sample-from-a-bootstrap-distribution",
    "href": "lectures/13_parametric_boot.html#create-one-sample-from-a-bootstrap-distribution",
    "title": "Bootstrap Hypothesis Test",
    "section": "Create one sample from a bootstrap distribution",
    "text": "Create one sample from a bootstrap distribution\n\n# setting a seed\nset.seed(2024)\n\n# Saving the df\nclinic_sample  |&gt;\n  \n  # Here we specify() what is a success\n  specify(response = has_disease, success = \"disease\") |&gt;\n  \n  # This is where we set the null hypothesis\n  hypothesize(null = \"point\", p = 0.40) |&gt;\n  \n  # This is how many times R will sample from the clinic sample\n  # We are using draw to sample 1 value from a theoretical distribution with p = 0.40. \n  generate(reps = 1, type = \"draw\") |&gt;\n  \n  # This groups the reps together to find a proportion. \n  calculate(stat = \"prop\")\n\nResponse: has_disease (factor)\nNull Hypothesis: point\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1   0.5"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#visualize-the-bootstrap-distribution",
    "href": "lectures/13_parametric_boot.html#visualize-the-bootstrap-distribution",
    "title": "Bootstrap Hypothesis Test",
    "section": "visualize() the bootstrap distribution",
    "text": "visualize() the bootstrap distribution\n\n# cheater function to graph, works like ggplot(), but we don't need aes()\nvisualize(data = null_distn_one_prop)"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#conclusion-1",
    "href": "lectures/13_parametric_boot.html#conclusion-1",
    "title": "Bootstrap Hypothesis Test",
    "section": "Conclusion",
    "text": "Conclusion\nWe fail to reject the null hypothesis at the 5% significance level. 0.13 &gt; 0.05"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#reading",
    "href": "lectures/12_hypothesis_test_prop.html#reading",
    "title": "Hypothesis Testing",
    "section": "Reading",
    "text": "Reading\nRead chapter 16 on hypothesis testing"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#more-than-1-relationship-with-simulation",
    "href": "lectures/13_parametric_boot.html#more-than-1-relationship-with-simulation",
    "title": "Bootstrap Hypothesis Test",
    "section": "More than 1 relationship with simulation",
    "text": "More than 1 relationship with simulation\n\nMake sample\nWrite hypothesis notation.\nCreate the simulated distribution.\nFind the probability we would get \\(\\hat{p} = 152/203 = 0.749\\) based on the null hypothesis.\nMake the conclusion."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#hypothesis-notation",
    "href": "lectures/13_parametric_boot.html#hypothesis-notation",
    "title": "Bootstrap Hypothesis Test",
    "section": "Hypothesis notation",
    "text": "Hypothesis notation\nThis part is the same.\n\\[\nH_0: p = 0.5 \\\\\nH_A: p &gt; 0.5\n\\]\n\\[\n\\alpha = 0.05\n\\]"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#side-note-the-pipe",
    "href": "lectures/13_parametric_boot.html#side-note-the-pipe",
    "title": "Bootstrap Hypothesis Test",
    "section": "Side note the pipe |>",
    "text": "Side note the pipe |&gt;\nYou may have noticed the occasional symbols |&gt; or %&gt;%.\nThis is called a pipe and it is an R operator that takes the output of the previous line of code and puts it into the first argument of the next line of code.\nIt often makes code easier to read, but can be confusing for first time programmers.\nFor this reason I have been avoiding it, until now."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#create-simulated-distribution",
    "href": "lectures/13_parametric_boot.html#create-simulated-distribution",
    "title": "Bootstrap Hypothesis Test",
    "section": "Create simulated distribution",
    "text": "Create simulated distribution\n\nlibrary(infer)\n\n# Saving all the proportions we'll make\nnull_distn_one_prop &lt;- more_than_1_relationship  |&gt;\n  \n  # Here we tell specify what is a success\n  specify(response = more_than_1_relationship, success = \"TRUE\") |&gt;\n  \n  # This is where we set the null hypothesis\n  hypothesize(null = \"point\", p = 0.5) |&gt;\n  \n  # Choosing 10000 replications\n  generate(reps = 5000, type = \"draw\") |&gt;\n  \n  # This is \n  calculate(stat = \"prop\")"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#examine-the-samples.",
    "href": "lectures/13_parametric_boot.html#examine-the-samples.",
    "title": "Bootstrap Hypothesis Test",
    "section": "Examine the samples.",
    "text": "Examine the samples.\n\n#visualize is a graphing function, based on ggplot, for the infer package. \n\nvisualise(data = null_distn_one_prop)"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#calculate-the-p-value-based-on-simulation",
    "href": "lectures/13_parametric_boot.html#calculate-the-p-value-based-on-simulation",
    "title": "Bootstrap Hypothesis Test",
    "section": "Calculate the p-value based on simulation",
    "text": "Calculate the p-value based on simulation\nVisualize the pvalue\n\nvisualise(data = null_distn_one_prop) +\n  shade_p_value(obs_stat = 0.749, direction = \"greater\")"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#calculate-the-p-value",
    "href": "lectures/13_parametric_boot.html#calculate-the-p-value",
    "title": "Bootstrap Hypothesis Test",
    "section": "Calculate the p-value",
    "text": "Calculate the p-value\n\nget_p_value(x = null_distn_one_prop, \n            obs_stat = 0.749,\n            direction = 'greater')\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#mathematical-vs.-simulation",
    "href": "lectures/13_parametric_boot.html#mathematical-vs.-simulation",
    "title": "Bootstrap Hypothesis Test",
    "section": "Mathematical vs. Simulation",
    "text": "Mathematical vs. Simulation\nBoth methods are valid and often end at the same conclusion\nMath uses formula based on conditions which must be checked. A theoretical distribution is built and probabilities calculated.\nA simulated distribution is built from resampling the sample. Conditions can be relaxed as we can visibly verify that the distribution is normal."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#homework",
    "href": "lectures/13_parametric_boot.html#homework",
    "title": "Bootstrap Hypothesis Test",
    "section": "Homework",
    "text": "Homework\nOn your homework you will use the math formula to make a theoretical distribution and calculate probabilities."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#r-assignment",
    "href": "lectures/13_parametric_boot.html#r-assignment",
    "title": "Bootstrap Hypothesis Test",
    "section": "R Assignment",
    "text": "R Assignment\nYou will make a simulated distribution of your own and find pvalues in a future R Assignment.\nWe’ll look at another example in the next video."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#another-example",
    "href": "lectures/13_parametric_boot.html#another-example",
    "title": "Bootstrap Hypothesis Test",
    "section": "Another example",
    "text": "Another example\nSuppose it is known that nationally out of 100 people struggling with drug addiction, 40 of them will have some blood born disease.\nA doctor at a clinic decides to test this hypothesis for her locality and samples 20 of her own patients. Of the 20 patients she finds 13 of them have a blood born disease.\nIs this evidence enough to say that the locality is different than the proportion nationally?"
  },
  {
    "objectID": "lectures/13_parametric_boot.html#last-example",
    "href": "lectures/13_parametric_boot.html#last-example",
    "title": "Bootstrap Hypothesis Test",
    "section": "Last example",
    "text": "Last example\nProblem 11, Ch 16\nStatistics and employment In a large university where 70% of the full-time students are employed at least 5 hours per week, the members of the Statistics Department wonder if a smaller proportion of their students work at least 5 hours per week. They randomly sample 25 majors and find that 15 of the students work 5 or more hours each week."
  },
  {
    "objectID": "lectures/13_parametric_boot.html#make-sample-1",
    "href": "lectures/13_parametric_boot.html#make-sample-1",
    "title": "Bootstrap Hypothesis Test",
    "section": "Make sample",
    "text": "Make sample\nNothing wrong with copying and editing code from above.\n\n# This makes a 60% success sample. \n\nmajor_sample &lt;-   c(rep(\"yes\", 15), rep(\"no\", 10))\n\n# This saves the sample as a dataframe\nmajor_sample &lt;- as.data.frame(major_sample)\n\n# This changed the name of the variable to \"has_disease\"\nnames(major_sample) &lt;-\"work\""
  },
  {
    "objectID": "lectures/13_parametric_boot.html#conclusion-2",
    "href": "lectures/13_parametric_boot.html#conclusion-2",
    "title": "Bootstrap Hypothesis Test",
    "section": "Conclusion",
    "text": "Conclusion\nWe fail to reject the null hypothesis at the 5% significance level. 0.13 &gt; 0.05"
  },
  {
    "objectID": "lectures/12_hypothesis_test_prop.html#calculate-pvalue",
    "href": "lectures/12_hypothesis_test_prop.html#calculate-pvalue",
    "title": "Hypothesis Testing",
    "section": "Calculate pvalue",
    "text": "Calculate pvalue\nWhat is the probability of getting the \\(\\hat{p}\\) from our sample?\n\nSE = sqrt(0.82*(1-0.82)/1000)\n\npnorm(q = 0.514, mean = 0.82, sd = SE )\n\n[1] 2.773057e-140"
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#practice-making-ci-with-proportions",
    "href": "lectures/14__CI_prop_mathematically.html#practice-making-ci-with-proportions",
    "title": "Confidence Intervals with a proportion",
    "section": "Practice Making CI with proportions",
    "text": "Practice Making CI with proportions"
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#find-the-confidence-interval-for",
    "href": "lectures/14__CI_prop_mathematically.html#find-the-confidence-interval-for",
    "title": "Confidence Intervals with a proportion",
    "section": "Find the confidence interval for:",
    "text": "Find the confidence interval for:\n\nThe true number of US women who were married before age 30.\n\n\n\n# A tibble: 2 × 2\n    age over_30 \n  &lt;int&gt; &lt;chr&gt;   \n1    32 Over_30 \n2    25 Under_30\n\n\n\nThe true proportion of women who smoke while pregnant in the US.\n\n\n\n# A tibble: 6 × 13\n   fage  mage mature      weeks premie visits gained weight lowbirthweight sex  \n  &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;\n1    34    34 younger mom    37 full …     14     28   6.96 not low        male \n2    36    31 younger mom    41 full …     12     41   8.86 not low        fema…\n3    37    36 mature mom     37 full …     10     28   7.51 not low        fema…\n4    NA    16 younger mom    38 full …     NA     29   6.19 not low        male \n5    32    31 younger mom    36 premie     12     48   6.75 not low        fema…\n6    32    26 younger mom    39 full …     14     45   6.69 not low        fema…\n# ℹ 3 more variables: habit &lt;chr&gt;, marital &lt;chr&gt;, whitemom &lt;chr&gt;"
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#ci-mathematically",
    "href": "lectures/14__CI_prop_mathematically.html#ci-mathematically",
    "title": "Confidence Intervals with a proportion",
    "section": "CI mathematically",
    "text": "CI mathematically\nWe build the CI around the sample proportion.\nAssume\n\\[\n\\hat{p} \\sim N(p,se)\n\\]\n\nWe’ll need \\(\\hat{p}\\) and \\(\\text{se}= \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\)\nWe also need the z score that goes with the confidence interval we are looking for.\n\\(\\hat{p} \\pm z_{score} \\times se\\)"
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#remember-these-z-scores",
    "href": "lectures/14__CI_prop_mathematically.html#remember-these-z-scores",
    "title": "Confidence Intervals with a proportion",
    "section": "Remember these z-scores",
    "text": "Remember these z-scores\n\nz-scores you should know\n\n\nCI\nZ-score\n\n\n\n\n90%\n\\(z_{0.05}=1.645\\)\n\n\n95%\n\\(z_{0.025}=1.96\\)\n\n\n99.7%\n\\(z_{0.005}=2.968\\)"
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#how-to-find-zscore-with-qnorm",
    "href": "lectures/14__CI_prop_mathematically.html#how-to-find-zscore-with-qnorm",
    "title": "Confidence Intervals with a proportion",
    "section": "How to find zscore with qnorm()",
    "text": "How to find zscore with qnorm()\nqnorm() finds the quantile that goes with a pvalue (probability)\n\n\n[1] 1.644854\n\n\npnorm() finds a pvalue from a quantile.\n\n\n[1] 0.975"
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#the-distribution-of-sampling-proportions",
    "href": "lectures/14__CI_prop_mathematically.html#the-distribution-of-sampling-proportions",
    "title": "Confidence Intervals with a proportion",
    "section": "The distribution of sampling proportions",
    "text": "The distribution of sampling proportions\nCompare vs. bootstrap distributions."
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#lets-make-a-95-ci",
    "href": "lectures/14__CI_prop_mathematically.html#lets-make-a-95-ci",
    "title": "Confidence Intervals with a proportion",
    "section": "Let’s make a 95% CI",
    "text": "Let’s make a 95% CI\nCalculate these: \\(\\hat{p}\\) and \\(\\text{se}= \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\)\n\\(\\hat{p} \\pm z_{score} \\times se\\)"
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#assumptions-for-a-single-parameter",
    "href": "lectures/14__CI_prop_mathematically.html#assumptions-for-a-single-parameter",
    "title": "Confidence Intervals with a proportion",
    "section": "Assumptions for a single parameter",
    "text": "Assumptions for a single parameter\nIndependent and “large” sample.\nSuccess-Failure Condition\nWhy do we need to assume this:\n\\[\n\\hat{p} \\sim N(p,se)\n\\]"
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#quarantine-again",
    "href": "lectures/14__CI_prop_mathematically.html#quarantine-again",
    "title": "Confidence Intervals with a proportion",
    "section": "Quarantine again",
    "text": "Quarantine again\nWe ask 1042 New Yorkers if they are for quarantining people who have been exposed to ebola. The results are below.\n\n\n# A tibble: 2 × 2\n  quarantine     n\n  &lt;fct&gt;      &lt;int&gt;\n1 against      188\n2 favor        854\n\n\n\nWrite the notation for the theoretical sampling distribution.\nMake a 90, 95 and 99.7% CI for those against and interpret."
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#exclusive-relationships",
    "href": "lectures/14__CI_prop_mathematically.html#exclusive-relationships",
    "title": "Confidence Intervals with a proportion",
    "section": "Exclusive relationships",
    "text": "Exclusive relationships\nWhat is the proportion of college students that have had more than 1 exclusive_relationships?\n\n\n# A tibble: 3 × 2\n  `num &gt; 1`     n\n  &lt;lgl&gt;     &lt;int&gt;\n1 FALSE        51\n2 TRUE        152\n3 NA           15\n\n\n\nCheck Conditions.\nWrite the notation for the theoretical sampling distribution.\nMake a 90, 95 and 99.7% CI for those against and interpret."
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#iphones",
    "href": "lectures/14__CI_prop_mathematically.html#iphones",
    "title": "Confidence Intervals with a proportion",
    "section": "iphones",
    "text": "iphones\n\nIn a sample of 300 students, 68% said they own an iPod and a smart phone. Compute a 97% confidence interval for the true percent of students who own an iPod and a smartphone.1\n\nThis and the previous problem were from a text called Introductory Statistics"
  },
  {
    "objectID": "lectures/14__CI_prop_mathematically.html#worse-off",
    "href": "lectures/14__CI_prop_mathematically.html#worse-off",
    "title": "Confidence Intervals with a proportion",
    "section": "Worse off?",
    "text": "Worse off?\nEvery week the Yougov/The Economist do a survey from a representative sample of about 1500 adults. methodology On March 4, 2024 people were asked about their personal finances. See the results here.\n42% of respondants said they were worse off than a year ago. Find a CI for the true proportion of Americans who feel they are worse off financially than a year ago."
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#explore-the-clt",
    "href": "lectures/16_Two_Proportions.html#explore-the-clt",
    "title": "Two proportions",
    "section": "Explore the CLT",
    "text": "Explore the CLT\n1 Distributions\n2 Confidence Intervals\n3 Confidence Interval (activity)\n4 Then on to two proportions"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#distributions",
    "href": "lectures/16_Two_Proportions.html#distributions",
    "title": "Two proportions",
    "section": "Distributions",
    "text": "Distributions\n\nData Distribution\n\nHow does the sample data look?\n\nSampling distribution\n\nA theoretical distribution (math model) of proportions from many samples\ncentered around the true propotion p.\n\nBootstrapped Distribution\n\nIf parametric its the same as the Null Distribution, center at p.\nIf non-parametric it is centered around \\(\\widehat{p}.\\)\n\n\nhttps://seeing-theory.brown.edu/frequentist-inference/index.html#section2"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#central-limit-theorem-for-a-proportion.",
    "href": "lectures/16_Two_Proportions.html#central-limit-theorem-for-a-proportion.",
    "title": "Two proportions",
    "section": "Central Limit Theorem for a proportion.",
    "text": "Central Limit Theorem for a proportion.\nThis is how we build the sampling distribution.\nIf we consider many proportions from many samples and the conditions are satisfied, then the distribution of the sample proportions will be Normal.\nhttps://xlasercut.github.io/central-limit-theorem-animation/#/"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#confidence-intervals.",
    "href": "lectures/16_Two_Proportions.html#confidence-intervals.",
    "title": "Two proportions",
    "section": "Confidence intervals.",
    "text": "Confidence intervals.\nIf we make a 95% CI from 100 point estimates of \\(\\widehat{p}\\) from 100 samples we expect 95 of those to contain the true proportion."
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#demonstration",
    "href": "lectures/16_Two_Proportions.html#demonstration",
    "title": "Two proportions",
    "section": "Demonstration",
    "text": "Demonstration\nhttps://seeing-theory.brown.edu/frequentist-inference/index.html#section2"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#two-proportions",
    "href": "lectures/16_Two_Proportions.html#two-proportions",
    "title": "Two proportions",
    "section": "Two proportions",
    "text": "Two proportions\nMaybe we want to directly compare two proportions.\nConsider a difference of proportions.\n\nConfidence Interval\nHypothesis Test"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#compare-two-proportions",
    "href": "lectures/16_Two_Proportions.html#compare-two-proportions",
    "title": "Two proportions",
    "section": "Compare two proportions",
    "text": "Compare two proportions\nIs there a difference between the two proportions?"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#similar-to-ci-for-one-prop.",
    "href": "lectures/16_Two_Proportions.html#similar-to-ci-for-one-prop.",
    "title": "Two proportions",
    "section": "Similar to CI for one prop.",
    "text": "Similar to CI for one prop.\nThe following is from chapter 17 in the text:\nThe difference \\(\\hat{p}_1−\\hat{p}_2\\) can be modeled using a normal distribution when\n\nIndependence Extended: The data are independent within and between the two groups.\nSuccess-failure condition. The success-failure condition holds for both groups, where we check successes and failures in each group separately."
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#mean-and-se",
    "href": "lectures/16_Two_Proportions.html#mean-and-se",
    "title": "Two proportions",
    "section": "Mean and SE",
    "text": "Mean and SE\n\\(p_1−p_2 \\sim N(\\hat{p}_1−\\hat{p}_2,\\sqrt{\\frac{\\hat{p}_1(1−\\hat{p}_1)}{n_1} +\\frac{\\hat{p}_2(1−\\hat{p}_2)}{n_2}})\\)\nmean = \\(\\hat{p}_1−\\hat{p}_2\\)\nStandard Error = \\(\\sqrt{\\frac{\\hat{p}_1(1−\\hat{p}_1)}{n_1} +\\frac{\\hat{p}_2(1−\\hat{p}_2)}{n_2}}\\)"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#consider-the-cpr-data.",
    "href": "lectures/16_Two_Proportions.html#consider-the-cpr-data.",
    "title": "Two proportions",
    "section": "Consider the cpr data.",
    "text": "Consider the cpr data."
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#data-distribution",
    "href": "lectures/16_Two_Proportions.html#data-distribution",
    "title": "Two proportions",
    "section": "Data Distribution",
    "text": "Data Distribution\n\nggplot(cpr, aes(x = group, fill = outcome))+\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#make-a-95-confidence-interval",
    "href": "lectures/16_Two_Proportions.html#make-a-95-confidence-interval",
    "title": "Two proportions",
    "section": "Make a 95% Confidence Interval",
    "text": "Make a 95% Confidence Interval\nWe want to try to capture the true difference in proportions.\n\\[\n\\hat{p}_1−\\hat{p}_2  \\pm z_{\\frac{\\alpha}{2}} \\times SE\n\\]\nWe expect 95% of the CIs to capture the true difference.\nCheck conditions first:\n\nIndependence Extended\nSuccess-failure condition"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#find-hatp-and-se",
    "href": "lectures/16_Two_Proportions.html#find-hatp-and-se",
    "title": "Two proportions",
    "section": "Find \\(\\hat{p}\\) and SE",
    "text": "Find \\(\\hat{p}\\) and SE\n\\(\\hat{p}_1 = \\frac{11}{50} = 0.22\\)\n\\(\\hat{p}_2 = \\frac{14}{40} \\approx 0.35\\)\n\\(\\hat{p_2} - \\hat{p_1} = 0.13\\)\n\\(SE = \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1}+\\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}} \\approx 0.095\\)\n\np_1 = 0.22\np_2 = 0.35\np_2-p_1\n\n[1] 0.13\n\nSE = sqrt(p_1*(1-p_1)/50+p_2*(1-p_2)/40)\nSE\n\n[1] 0.09549607\n\n\n\\(Z = 1.96\\)"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#the-distribution-is",
    "href": "lectures/16_Two_Proportions.html#the-distribution-is",
    "title": "Two proportions",
    "section": "The distribution is",
    "text": "The distribution is\n\\({p}_1−{p}_2 \\sim N(0.13,0.095)\\)"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#the-95-ci",
    "href": "lectures/16_Two_Proportions.html#the-95-ci",
    "title": "Two proportions",
    "section": "The 95% CI",
    "text": "The 95% CI\n\nZ = 1.96\n\n# \"Lower Bound\"\np_2-p_1 - Z* SE\n\n[1] -0.0571723\n\n# \"Upper Bound\"\np_2-p_1 + Z* SE\n\n[1] 0.3171723"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#interpretation",
    "href": "lectures/16_Two_Proportions.html#interpretation",
    "title": "Two proportions",
    "section": "Interpretation",
    "text": "Interpretation\nWe are 95 % confident that the true difference in the proportion of people who survived using the two treatments is between -0.06 and 0.32. Note that zero is in this interval. It is possible that there is no difference in the survival rates."
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#you-try",
    "href": "lectures/16_Two_Proportions.html#you-try",
    "title": "Two proportions",
    "section": "You try:",
    "text": "You try:"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#chapter-17",
    "href": "lectures/16_Two_Proportions.html#chapter-17",
    "title": "Two proportions",
    "section": "10 chapter 17",
    "text": "10 chapter 17"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#lets-do-a-hypothesis-test",
    "href": "lectures/16_Two_Proportions.html#lets-do-a-hypothesis-test",
    "title": "Two proportions",
    "section": "Let’s do a Hypothesis Test",
    "text": "Let’s do a Hypothesis Test\nWe’ll use the same data above\n\\[\nH_0: p_1 = p_2 \\\\\nH_a:p_1 \\ne p_2\n\\]\n\\[\n\\alpha = 0.05\n\\]\nCheck conditions:\n\nIndependence Extended\nSuccess-failure condition"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#pooled-groups",
    "href": "lectures/16_Two_Proportions.html#pooled-groups",
    "title": "Two proportions",
    "section": "pooled groups",
    "text": "pooled groups\nThere is one difference when doing the hypothesis test. We use a pooled statistic when calculating the standard error.\nThe book uses \\(\\widehat{p}_{pool} = \\frac{\\text{total successes from both groups}}{\\text{total from both groups}}\\)\nIf conditions with the pooled group then\n\\(\\hat{p}_1−\\hat{p}_2 \\sim N({p}_1−{p}_2,\\sqrt{\\hat{p}_{pool}(1−\\hat{p}_{pool})(\\frac{1}{n_1} +\\frac{1}{n_2}}))\\)"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#calculate-the-pooled-groups",
    "href": "lectures/16_Two_Proportions.html#calculate-the-pooled-groups",
    "title": "Two proportions",
    "section": "Calculate the pooled groups",
    "text": "Calculate the pooled groups\n\\(\\widehat{p}_{pool} = \\frac{25}{90}\\)\n\\(SE = \\sqrt{\\widehat{p}_{pool}(1-\\widehat{p}_{pool})(1/n_1+1/n_2)}\\)\n\np_pool = 25/90\nSE = sqrt(p_pool*(1-p_pool)*(1/50+1/40))\nSE\n\n[1] 0.09501462"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#find-pvalue",
    "href": "lectures/16_Two_Proportions.html#find-pvalue",
    "title": "Two proportions",
    "section": "Find pvalue",
    "text": "Find pvalue\nNote that the distribution is different, because in a hypothesis test we assume the center is 0.\n\\({p}_1−{p}_2 \\sim N(0,0.095)\\)\nIf the distribution is centered around the null parameter (eg 0, because we assume there is no difference) how likely is it that we would get 0.13 for a difference?\n\n2*pnorm(q = 0.13, mean = 0, sd = SE, lower.tail = FALSE)\n\n[1] 0.1712462"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#conclusion",
    "href": "lectures/16_Two_Proportions.html#conclusion",
    "title": "Two proportions",
    "section": "Conclusion",
    "text": "Conclusion\nOur pvalue is greater than 0.05 so we fail to reject the null hypothesis and conclude that there is no difference in survival rates between the treatment and control groups.\nNote: It is possible we have made a Type 2 error in failing to reject the null even when the null was false."
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#you-try-1",
    "href": "lectures/16_Two_Proportions.html#you-try-1",
    "title": "Two proportions",
    "section": "You try",
    "text": "You try\nproblem 12 chapter 17"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#problem-12-chapter-17",
    "href": "lectures/16_Two_Proportions.html#problem-12-chapter-17",
    "title": "Two proportions",
    "section": "problem 12 chapter 17",
    "text": "problem 12 chapter 17"
  },
  {
    "objectID": "lectures/15_Reflection.html#explore-the-clt",
    "href": "lectures/15_Reflection.html#explore-the-clt",
    "title": "Reflect on the CLT",
    "section": "Explore the CLT",
    "text": "Explore the CLT\n1 Distributions\n2 Confidence Intervals\n3 Confidence Interval (activity)"
  },
  {
    "objectID": "lectures/15_Reflection.html#distributions",
    "href": "lectures/15_Reflection.html#distributions",
    "title": "Reflect on the CLT",
    "section": "Distributions",
    "text": "Distributions\n\nData Distribution\n\nHow does the sample data look?\n\nSampling distribution\n\nA theoretical distribution (math model) of proportions from many samples\ncentered around the true propotion p.\n\nBootstrapped Distribution\n\nIf parametric its center is the same as the Null Distribution, center at p.\nIf non-parametric it is centered around \\(\\widehat{p}.\\)"
  },
  {
    "objectID": "lectures/15_Reflection.html#central-limit-theorem-for-a-proportion.",
    "href": "lectures/15_Reflection.html#central-limit-theorem-for-a-proportion.",
    "title": "Reflect on the CLT",
    "section": "Central Limit Theorem for a proportion.",
    "text": "Central Limit Theorem for a proportion.\nThis is how we build the sampling distribution.\nIf we consider many proportions from many samples and the conditions are satisfied, then the distribution of the sample proportions will be Normal.\nAn visual for the CLT"
  },
  {
    "objectID": "lectures/15_Reflection.html#confidence-intervals.",
    "href": "lectures/15_Reflection.html#confidence-intervals.",
    "title": "Reflect on the CLT",
    "section": "Confidence intervals.",
    "text": "Confidence intervals.\nIf we make a 95% CI from 100 point estimates of \\(\\widehat{p}\\) from 100 samples we expect 95 of those to contain the true proportion."
  },
  {
    "objectID": "lectures/15_Reflection.html#demonstration",
    "href": "lectures/15_Reflection.html#demonstration",
    "title": "Reflect on the CLT",
    "section": "Demonstration",
    "text": "Demonstration\nA visual for Confidence Intervals"
  },
  {
    "objectID": "lectures/15_Reflection.html#the-bootstrap",
    "href": "lectures/15_Reflection.html#the-bootstrap",
    "title": "Reflect on the CLT",
    "section": "The bootstrap",
    "text": "The bootstrap\nThe bootstrap from Seeing Theory"
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html",
    "href": "lectures/17_decision_error_tidying_up.html",
    "title": "Decision Errors",
    "section": "",
    "text": "Write notation\nCheck Conditions\nBuild Theoretical Distributions with assumed parameter.\nFind the probability of such a sample statistic."
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#hypothesis-testing-with-p-values",
    "href": "lectures/17_decision_error_tidying_up.html#hypothesis-testing-with-p-values",
    "title": "Decision Errors",
    "section": "Hypothesis Testing with p-values",
    "text": "Hypothesis Testing with p-values\n\nWrite notation\nCheck Conditions\nBuild Theoretical Distributions with assumed parameter.\nFind the probability of a sample statistic."
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#the-question-we-are-trying-to-answer",
    "href": "lectures/17_decision_error_tidying_up.html#the-question-we-are-trying-to-answer",
    "title": "Decision Errors",
    "section": "The question we are trying to answer:",
    "text": "The question we are trying to answer:\nIf the null hypothesis is true, how likely is it that we would have gotten the statistic from our sample?"
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#example-from-lab-4",
    "href": "lectures/17_decision_error_tidying_up.html#example-from-lab-4",
    "title": "Decision Errors",
    "section": "Example from lab 4",
    "text": "Example from lab 4\nIf \\(H_0 : p = 0.08\\) how likely is it we would have gotten \\(\\widehat{p} = 0.0653\\)\nYou all found that to be very unlikely from your bootstrap distribution."
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#note-on-alpha-alpha",
    "href": "lectures/17_decision_error_tidying_up.html#note-on-alpha-alpha",
    "title": "Decision Errors",
    "section": "Note on alpha \\(\\alpha\\) :",
    "text": "Note on alpha \\(\\alpha\\) :\n\\(\\alpha\\) is a cut off value. If the p-value is larger than \\(\\alpha\\) we say \\(\\widehat{p}\\) is likely (Fail to reject \\(H_0\\)), smaller than alpha \\(\\widehat{p}\\) is unlikely (reject \\(H_0\\)).\n\n\\(\\alpha\\) shows the strength of our evidence.\nweak evidence \\(\\alpha = 0.1\\) or higher.\nmoderate evidence \\(\\alpha =0.05\\)\nstrong evidence \\(\\alpha = 0.01\\)\n\nChoosing alpha involves making trade offs that are beyond the scope of this class."
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#but-we-can-make-the-wrong-decision",
    "href": "lectures/17_decision_error_tidying_up.html#but-we-can-make-the-wrong-decision",
    "title": "Decision Errors",
    "section": "But we can make the wrong decision",
    "text": "But we can make the wrong decision\nThese are just probabilities. They could be wrong.\n\nWe could reject \\(H_0\\) if it is true. (Type 1)\n\nor\n\nWe could fail to reject \\(H_0\\) if it is false. (Type 2)"
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#decision-errors",
    "href": "lectures/17_decision_error_tidying_up.html#decision-errors",
    "title": "Decision Errors",
    "section": "Decision Errors",
    "text": "Decision Errors"
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#on-lab-4",
    "href": "lectures/17_decision_error_tidying_up.html#on-lab-4",
    "title": "Decision Errors",
    "section": "On Lab 4",
    "text": "On Lab 4\nCould we have made an error?"
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#board-work-problem",
    "href": "lectures/17_decision_error_tidying_up.html#board-work-problem",
    "title": "Decision Errors",
    "section": "Board work problem",
    "text": "Board work problem\n16.3\n\nignore d.\nMake your own bootstrapped null distribution. set.seed(2024)\nFind the pvalue.\nMake conclusion.\nAlso consider which error could have been reached."
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#example-from-difference-of-props",
    "href": "lectures/17_decision_error_tidying_up.html#example-from-difference-of-props",
    "title": "Decision Errors",
    "section": "Example from difference of props",
    "text": "Example from difference of props\nIf \\(H_0 : p_1 = p_2\\) how likely is it we would have gotten \\(\\widehat{p}_1- \\widehat{p}_2 = 0.13\\)\nWith a p-value of 0.086 found it to be likely that we would have gotten 0.13."
  },
  {
    "objectID": "lectures/17_decision_error_tidying_up.html#making-a-wrong-decision",
    "href": "lectures/17_decision_error_tidying_up.html#making-a-wrong-decision",
    "title": "Decision Errors",
    "section": "Making a wrong decision",
    "text": "Making a wrong decision\nThese are just probabilities. They could be wrong.\n\nWe could reject \\(H_0\\) if it is true. (Type 1)\n\nor\n\nWe could fail to reject \\(H_0\\) if it is false. (Type 2)"
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#read-before-hand",
    "href": "lectures/16_Two_Proportions.html#read-before-hand",
    "title": "Two proportions",
    "section": "Read before hand",
    "text": "Read before hand\nRead chapter 17 on inference with two proportions."
  },
  {
    "objectID": "lectures/16_Two_Proportions.html#libraries",
    "href": "lectures/16_Two_Proportions.html#libraries",
    "title": "Two proportions",
    "section": "Libraries",
    "text": "Libraries\n\nlibrary(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "lectures/19_single_mean.html#libraries",
    "href": "lectures/19_single_mean.html#libraries",
    "title": "hypothesis test for one mean",
    "section": "Libraries",
    "text": "Libraries\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "lectures/19_single_mean.html#test-statistics",
    "href": "lectures/19_single_mean.html#test-statistics",
    "title": "hypothesis test for one mean",
    "section": "Test Statistics",
    "text": "Test Statistics\nWhat is a test statistic?\nIt is the value from your data that you can compare to a sampling (or comparison) distribution primarily for finding a p-value."
  },
  {
    "objectID": "lectures/19_single_mean.html#single-proportion",
    "href": "lectures/19_single_mean.html#single-proportion",
    "title": "hypothesis test for one mean",
    "section": "Single proportion",
    "text": "Single proportion\nThe test statistic for a single proportion is a z-score for the standard normal N(0,1):\n\\[\nT=\\frac{\\widehat{p} - p_{null}}{SE}\n\\]\nWhere \\(p_{null}\\) is the proportion under the null hypothesis."
  },
  {
    "objectID": "lectures/19_single_mean.html#diff-of-proportions",
    "href": "lectures/19_single_mean.html#diff-of-proportions",
    "title": "hypothesis test for one mean",
    "section": "Diff of Proportions",
    "text": "Diff of Proportions\nThe test statistic for a difference of proportions is also a z-score for the standard normal N(0,1):\n\\[\nT = \\frac{\\widehat{p_1} - \\widehat{p_2} - 0}{SE}\n\\]\nWhere \\(\\widehat{p_1} - \\widehat{p_2}\\) is the point estimate and 0 is the difference under the null."
  },
  {
    "objectID": "lectures/19_single_mean.html#why-did-we-compute-these",
    "href": "lectures/19_single_mean.html#why-did-we-compute-these",
    "title": "hypothesis test for one mean",
    "section": "Why did we compute these?",
    "text": "Why did we compute these?\nWe find the test statistics on the standard normal table of z-scores to be able to find a p-value.\nWe don’t really need to know how to do this because we have pnorm().\nWhen reading stats papers the phrase test statistic is still often given along side the p-value."
  },
  {
    "objectID": "lectures/19_single_mean.html#a-single-mean",
    "href": "lectures/19_single_mean.html#a-single-mean",
    "title": "hypothesis test for one mean",
    "section": "A single mean",
    "text": "A single mean\nFictional:\nWe are concerned about over-fishing depleting the food for penguin’s diets.\nLast year the average weight of Adelie penguins on Togersen island was 3900 grams.\nWe went to Togersen Island this year and weighed some penguins.\nOur data is in penguins."
  },
  {
    "objectID": "lectures/19_single_mean.html#penguin-sample",
    "href": "lectures/19_single_mean.html#penguin-sample",
    "title": "hypothesis test for one mean",
    "section": "Penguin Sample",
    "text": "Penguin Sample\n\nTogersen_penguins &lt;- penguins |&gt;\n  filter(island == \"Torgersen\") \n\nmean(Togersen_penguins$body_mass_g, na.rm = TRUE)\n\n[1] 3706.373\n\n\nIs the difference from 3900 due to chance?"
  },
  {
    "objectID": "lectures/19_single_mean.html#hypothesis-test-for-a-single-mean",
    "href": "lectures/19_single_mean.html#hypothesis-test-for-a-single-mean",
    "title": "hypothesis test for one mean",
    "section": "Hypothesis test for a single mean",
    "text": "Hypothesis test for a single mean\nLet’s set up the test for the penguins\n\\[\nH_0: \\mu = 3900 \\\\\nH_a: \\mu \\ne 3900\n\\]"
  },
  {
    "objectID": "lectures/19_single_mean.html#conditions",
    "href": "lectures/19_single_mean.html#conditions",
    "title": "hypothesis test for one mean",
    "section": "Conditions",
    "text": "Conditions\nLarge Independent sample\n\nNo extreme outliers\nLarger than 30\n\nor\nSmall Independent sample\n\nThe data distribution is normal.\nNo clear outliers."
  },
  {
    "objectID": "lectures/19_single_mean.html#check-our-conditions",
    "href": "lectures/19_single_mean.html#check-our-conditions",
    "title": "hypothesis test for one mean",
    "section": "Check our conditions",
    "text": "Check our conditions\n\n#Sample size \nnrow(Togersen_penguins)\n\n[1] 52\n\n# Outliers? \nggplot(Togersen_penguins)+\n  geom_boxplot(aes(x=body_mass_g))"
  },
  {
    "objectID": "lectures/19_single_mean.html#what-is-the-sampling-distribution",
    "href": "lectures/19_single_mean.html#what-is-the-sampling-distribution",
    "title": "hypothesis test for one mean",
    "section": "What is the sampling distribution?",
    "text": "What is the sampling distribution?\nWe could use the sampling distribution… But its much better to use the Student t."
  },
  {
    "objectID": "lectures/19_single_mean.html#the-students-t-dist",
    "href": "lectures/19_single_mean.html#the-students-t-dist",
    "title": "hypothesis test for one mean",
    "section": "The Student’s t dist",
    "text": "The Student’s t dist\nThe student t distribution is similar to the normal distribution in shape. \nIt has wider tails. \nIt is used with confidence intervals and hypothesis testing of a single mean. \nUnlike the normal distribution it works well for small sample sizes if the population is normal distributed."
  },
  {
    "objectID": "lectures/19_single_mean.html#very-short-history",
    "href": "lectures/19_single_mean.html#very-short-history",
    "title": "hypothesis test for one mean",
    "section": "Very Short History",
    "text": "Very Short History\n\n\nWilliam Sealy Gosset\n\n\n\n\nWorked at Guiness and was interested in the chemical properties of barley. source"
  },
  {
    "objectID": "lectures/19_single_mean.html#the-parameters-of-a-student-t.",
    "href": "lectures/19_single_mean.html#the-parameters-of-a-student-t.",
    "title": "hypothesis test for one mean",
    "section": "The parameters of a student t.",
    "text": "The parameters of a student t.\nThe student t takes just one parameter\n\ndf = degree of freedom.\n\n\\(df= n-1\\)"
  },
  {
    "objectID": "lectures/19_single_mean.html#limit-of-t-dist-is-normal",
    "href": "lectures/19_single_mean.html#limit-of-t-dist-is-normal",
    "title": "hypothesis test for one mean",
    "section": "limit of t-dist is normal",
    "text": "limit of t-dist is normal\nAs \\(\\text{lim}_{df \\rightarrow \\infty} t_{dist} \\rightarrow N(\\mu=0,sigma=1)\\)\n\nhttps://en.wikipedia.org/wiki/Student%27s_t-distribution#/media/File:Student_t_pdf.svg"
  },
  {
    "objectID": "lectures/19_single_mean.html#t-dist-is-better-than-the-normal-for-sampling-distributions.",
    "href": "lectures/19_single_mean.html#t-dist-is-better-than-the-normal-for-sampling-distributions.",
    "title": "hypothesis test for one mean",
    "section": "t-dist is better than the normal for sampling distributions.",
    "text": "t-dist is better than the normal for sampling distributions.\nYou can use either if:\n\n\nIf the sample size is large or underlying distribution is normal\nPopulation standard deviation is known \\(\\sigma\\)\nBut if population sd \\(\\sigma\\) is unknown or n is small use student t.\nIn general the t distribution works, the normal less so."
  },
  {
    "objectID": "lectures/19_single_mean.html#the-sampling-distribution-for-sample-mean",
    "href": "lectures/19_single_mean.html#the-sampling-distribution-for-sample-mean",
    "title": "hypothesis test for one mean",
    "section": "The sampling distribution for sample mean:",
    "text": "The sampling distribution for sample mean:\n\\(\\mu \\sim \\text{t}_{df}\\)\n\nThe mean of the t-dist is 0.\n\nThe mean of your sample is \\(\\bar{x}\\) and the standard error is \\(SE = \\frac{s}{\\sqrt{n}}\\)"
  },
  {
    "objectID": "lectures/19_single_mean.html#what-is-df",
    "href": "lectures/19_single_mean.html#what-is-df",
    "title": "hypothesis test for one mean",
    "section": "What is df?",
    "text": "What is df?\n\n\nThe number of values that can vary when finding a mean.\nConsider that you find a mean of 3 numbers. x,y,and z.\nIf I tell you the mean is 10, you can guess any two numbers and the third is forced.\nThis mean would have 2 degrees of freedom."
  },
  {
    "objectID": "lectures/19_single_mean.html#test-statistic-for-a-mean",
    "href": "lectures/19_single_mean.html#test-statistic-for-a-mean",
    "title": "hypothesis test for one mean",
    "section": "test statistic for a mean",
    "text": "test statistic for a mean\nWe’ve skipped discussing test statistics until now, because of pnorm().\nIdeally\n\\[ T = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\]\nor more realistically:\n\\[ T = \\frac{\\bar{x} - \\mu}{\\frac{s_x}{\\sqrt{n}}}\\]"
  },
  {
    "objectID": "lectures/19_single_mean.html#lets-finish-our-hypothesis-test",
    "href": "lectures/19_single_mean.html#lets-finish-our-hypothesis-test",
    "title": "hypothesis test for one mean",
    "section": "Let’s finish our hypothesis test",
    "text": "Let’s finish our hypothesis test\nWe are considering the weight of penguins.\nLast year the weight was 3900, and this yeah its 3706.\nWe checked conditions.\nThe standard deviation is:\n\ns_x = sd(Togersen_penguins$body_mass_g, na.rm = TRUE)\ns_x\n\n[1] 445.1079\n\n\nSo the test statistic is:\n\nT = (3706.373 - 3900)/ (s_x/sqrt(51))\nT\n\n[1] -3.106602"
  },
  {
    "objectID": "lectures/19_single_mean.html#find-pvalue",
    "href": "lectures/19_single_mean.html#find-pvalue",
    "title": "hypothesis test for one mean",
    "section": "Find pvalue",
    "text": "Find pvalue\nWe need to calculate the probability of getting -3.11 for a test statistic.\nMultiply by 2 for a two tailed test.\n\n2 * pt(-3.11, df = 51-1)\n\n[1] 0.003086856"
  },
  {
    "objectID": "lectures/19_single_mean.html#conclusion",
    "href": "lectures/19_single_mean.html#conclusion",
    "title": "hypothesis test for one mean",
    "section": "conclusion",
    "text": "conclusion\nReject the null hypothesis. We have strong evidence to believe that the average weight this year is different from 3900 grams.\nIts possible we made a type 1 error and rejected the null even if it was true."
  },
  {
    "objectID": "lectures/19_single_mean.html#you-can-make-confidence-intervals-with-the-student-t.",
    "href": "lectures/19_single_mean.html#you-can-make-confidence-intervals-with-the-student-t.",
    "title": "hypothesis test for one mean",
    "section": "You can make confidence intervals with the student t.",
    "text": "You can make confidence intervals with the student t.\nIts the same as doing it with the normal distribution.\nExcept you use a t* score instead of z*score.\n\\[ \\bar{x} \\pm t^* SE\\]"
  },
  {
    "objectID": "lectures/19_single_mean.html#lets-make-a-90-ci-for-our-penguin-data.",
    "href": "lectures/19_single_mean.html#lets-make-a-90-ci-for-our-penguin-data.",
    "title": "hypothesis test for one mean",
    "section": "Lets make a 90% CI for our penguin data.",
    "text": "Lets make a 90% CI for our penguin data.\n\\(\\bar{x} = 3706.373\\)\n\\(SE = \\frac{s}{n}=\\frac{445.10}{51} = 8.73\\)\n\\(t^*=\\)\n\nt_star = qt(0.95 , df=50)\nt_star\n\n[1] 1.675905\n\n\n\nx_bar = 3706.373\nSE = s_x/sqrt(51)\n\n# Lower Bound\nx_bar - t_star*SE\n\n[1] 3601.918\n\n# Upper Bound\nx_bar + t_star*SE\n\n[1] 3810.828"
  },
  {
    "objectID": "lectures/19_single_mean.html#conclusion-1",
    "href": "lectures/19_single_mean.html#conclusion-1",
    "title": "hypothesis test for one mean",
    "section": "Conclusion",
    "text": "Conclusion\nWe are 90% confident that the true weight of penguins is between 3602 and 3811."
  },
  {
    "objectID": "lectures/19_single_mean.html#you-try-hypothesis-testing-on-a-single-mean",
    "href": "lectures/19_single_mean.html#you-try-hypothesis-testing-on-a-single-mean",
    "title": "hypothesis test for one mean",
    "section": "You try: Hypothesis testing on a single mean",
    "text": "You try: Hypothesis testing on a single mean\nAwesome Auto data set. 𝑛 = 5, \\(\\bar{x}\\)= 14600, and \\(s_x\\)= 7765.31. Suppose you hear that the Awesome Auto dealership typically sells cars for 18000. You decide to test this claim.\n\nWrite the hypotheses in symbols.\nCheck conditions, then calculate the test statistic, 𝑇 , and the associated degrees of freedom.\nFind and interpret the p-value in this context.\nWhat is the conclusion of the hypothesis test when using 𝛼 = 0.05?"
  },
  {
    "objectID": "lectures/19_single_mean.html#solution",
    "href": "lectures/19_single_mean.html#solution",
    "title": "hypothesis test for one mean",
    "section": "Solution",
    "text": "Solution\n\\[\nH_0: \\mu = 18000 \\\\\nH_a: \\mu \\ne 18000 \\\\\n\\alpha = 0.05\n\\]\nUnfortunately we cannot at present test the normal condition. The cars are independent."
  },
  {
    "objectID": "lectures/19_single_mean.html#test-statistic",
    "href": "lectures/19_single_mean.html#test-statistic",
    "title": "hypothesis test for one mean",
    "section": "Test Statistic",
    "text": "Test Statistic\n\\(T =   \\frac{14600 - 18000}{\\frac{7765.31}{\\sqrt{5}}}\\)\ndf = 4\np-value:\n\n# give info below\nx_bar = 14600\nmu = 18000\ns_x = 7765.31\nn = 5\n\n# test statistic\ntest_stat = (x_bar - mu)/(s_x/sqrt(n))\n\n# Find pvalue\n2*pt(q=test_stat, df=4)\n\n[1] 0.3829896"
  },
  {
    "objectID": "lectures/19_single_mean.html#conclusion-2",
    "href": "lectures/19_single_mean.html#conclusion-2",
    "title": "hypothesis test for one mean",
    "section": "Conclusion",
    "text": "Conclusion\nWith a large p value we find no evidence that the prices at Awesome Auto average 18000.\nWe could never verify that the underlying data was normal."
  },
  {
    "objectID": "lectures/19_single_mean.html#the-t.test",
    "href": "lectures/19_single_mean.html#the-t.test",
    "title": "hypothesis test for one mean",
    "section": "The t.test()",
    "text": "The t.test()\nR, of course, can make this test easy if you are working from a vector of values (x) (instead of sample statistics, like above). You will do this on occasion in your homework.\nYou can also take the time to have R calculate the mean and standard deviation, but t.test() is fine.\n\nt.test(x= , alternative= , mu=)"
  },
  {
    "objectID": "lectures/19_single_mean.html#awesome-auto-revisited",
    "href": "lectures/19_single_mean.html#awesome-auto-revisited",
    "title": "hypothesis test for one mean",
    "section": "Awesome auto revisited",
    "text": "Awesome auto revisited\nSuppose the awesome auto data was:\n\nawesome_auto &lt;- c(15000, 26000, 6000, 17000, 9000)\n\n\nt.test(x = awesome_auto,\n       alternative = \"two\",\n       mu = 18000)\n\n\n    One Sample t-test\n\ndata:  awesome_auto\nt = -0.97905, df = 4, p-value = 0.383\nalternative hypothesis: true mean is not equal to 18000\n95 percent confidence interval:\n  4958.097 24241.903\nsample estimates:\nmean of x \n    14600"
  },
  {
    "objectID": "lectures/19_single_mean.html#you-try-another-one-with-t.test",
    "href": "lectures/19_single_mean.html#you-try-another-one-with-t.test",
    "title": "hypothesis test for one mean",
    "section": "You try: Another one with t.test()",
    "text": "You try: Another one with t.test()\nThe 2017 Toyota Prius Prime has a MPG_e = 54. Consider the prius_mpg data set in the openintro package.\n\nTest the hypothesis that the actual MPG is greater than 54.\n\nConsider Conditions, but do the test either way and we’ll discuss conditions afterwards.\n\nHint: use prius_mpg$_____ to take just one column from the data."
  },
  {
    "objectID": "lectures/19_single_mean.html#my-output",
    "href": "lectures/19_single_mean.html#my-output",
    "title": "hypothesis test for one mean",
    "section": "My output",
    "text": "My output\n\nlibrary(tidyverse)\nlibrary(openintro)\n\nt.test(x=prius_mpg$average_mpg, alternative = \"greater\", mu = 54)\n\n\n    One Sample t-test\n\ndata:  prius_mpg$average_mpg\nt = 5.757, df = 18, p-value = 9.304e-06\nalternative hypothesis: true mean is greater than 54\n95 percent confidence interval:\n 117.4944      Inf\nsample estimates:\nmean of x \n 144.8632"
  },
  {
    "objectID": "lectures/19_single_mean.html#preview-bootstrapping",
    "href": "lectures/19_single_mean.html#preview-bootstrapping",
    "title": "hypothesis test for one mean",
    "section": "Preview: Bootstrapping",
    "text": "Preview: Bootstrapping\n\nlibrary(infer)\n\nx_bar &lt;- mean(prius_mpg$average_mpg)\n\nprius_randomization &lt;-prius_mpg |&gt;\n  specify(response = average_mpg)|&gt;\n  hypothesise(null= \"point\", mu = 54) |&gt;\n  generate(reps = 5000)|&gt;\n  calculate(stat = \"mean\")"
  },
  {
    "objectID": "lectures/19_single_mean.html#graph-and-pvalue",
    "href": "lectures/19_single_mean.html#graph-and-pvalue",
    "title": "hypothesis test for one mean",
    "section": "Graph and pvalue",
    "text": "Graph and pvalue\n\nprius_randomization |&gt;  visualise()+\n  shade_p_value(obs_stat = x_bar, direction = \"greater\")\n\nprius_randomization |&gt;\n  get_pvalue(obs_stat = x_bar, direction = \"greater\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0"
  },
  {
    "objectID": "lectures/19_single_mean.html#a-single-mean-example",
    "href": "lectures/19_single_mean.html#a-single-mean-example",
    "title": "hypothesis test for one mean",
    "section": "A single mean example",
    "text": "A single mean example\nFictional:\nWe are concerned about over-fishing depleting the food for penguin’s diets.\nLast year the average weight of Adelie penguins on Togersen island was 3900 grams.\nWe went to Togersen Island this year and weighed some penguins.\nOur data is in penguins."
  },
  {
    "objectID": "lectures/18_single_mean.html",
    "href": "lectures/18_single_mean.html",
    "title": "hypothesis test for one mean",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "lectures/18_single_mean.html#libraries",
    "href": "lectures/18_single_mean.html#libraries",
    "title": "hypothesis test for one mean",
    "section": "Libraries",
    "text": "Libraries\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "lectures/18_single_mean.html#test-statistics",
    "href": "lectures/18_single_mean.html#test-statistics",
    "title": "hypothesis test for one mean",
    "section": "Test Statistics",
    "text": "Test Statistics\nWhat is a test statistic?\nIt is the value from your data that you can compare to a sampling (or comparison) distribution primarily for finding a p-value."
  },
  {
    "objectID": "lectures/18_single_mean.html#single-proportion",
    "href": "lectures/18_single_mean.html#single-proportion",
    "title": "hypothesis test for one mean",
    "section": "Single proportion",
    "text": "Single proportion\nThe test statistic for a single proportion is a z-score for the standard normal N(0,1):\n\\[\nT=\\frac{\\widehat{p} - p_{null}}{SE}\n\\]\nWhere \\(p_{null}\\) is the proportion under the null hypothesis."
  },
  {
    "objectID": "lectures/18_single_mean.html#diff-of-proportions",
    "href": "lectures/18_single_mean.html#diff-of-proportions",
    "title": "hypothesis test for one mean",
    "section": "Diff of Proportions",
    "text": "Diff of Proportions\nThe test statistic for a difference of proportions is also a z-score for the standard normal N(0,1):\n\\[\nT = \\frac{\\widehat{p_1} - \\widehat{p_2} - 0}{SE}\n\\]\nWhere \\(\\widehat{p_1} - \\widehat{p_2}\\) is the point estimate and 0 is the difference under the null."
  },
  {
    "objectID": "lectures/18_single_mean.html#why-did-we-compute-these",
    "href": "lectures/18_single_mean.html#why-did-we-compute-these",
    "title": "hypothesis test for one mean",
    "section": "Why did we compute these?",
    "text": "Why did we compute these?\nWe find the test statistics on the standard normal table of z-scores to be able to find a p-value.\nWe don’t really need to know how to do this because we have pnorm().\nWhen reading stats papers the phrase test statistic is still often given along side the p-value."
  },
  {
    "objectID": "lectures/18_single_mean.html#a-single-mean-example",
    "href": "lectures/18_single_mean.html#a-single-mean-example",
    "title": "hypothesis test for one mean",
    "section": "A single mean example",
    "text": "A single mean example\nFictional:\nWe are concerned about over-fishing depleting the food for penguin’s diets.\nLast year the average weight of Adelie penguins on Togersen island was 3900 grams.\nWe went to Togersen Island this year and weighed some penguins.\nOur data is in penguins."
  },
  {
    "objectID": "lectures/18_single_mean.html#penguin-sample",
    "href": "lectures/18_single_mean.html#penguin-sample",
    "title": "hypothesis test for one mean",
    "section": "Penguin Sample",
    "text": "Penguin Sample\n\nTogersen_penguins &lt;- penguins |&gt;\n  filter(island == \"Torgersen\") \n\nmean(Togersen_penguins$body_mass_g, na.rm = TRUE)\n\n[1] 3706.373\n\n\nIs the difference from 3900 due to chance?"
  },
  {
    "objectID": "lectures/18_single_mean.html#hypothesis-test-for-a-single-mean",
    "href": "lectures/18_single_mean.html#hypothesis-test-for-a-single-mean",
    "title": "hypothesis test for one mean",
    "section": "Hypothesis test for a single mean",
    "text": "Hypothesis test for a single mean\nLet’s set up the test for the penguins\n\\[\nH_0: \\mu = 3900 \\\\\nH_a: \\mu \\ne 3900\n\\]"
  },
  {
    "objectID": "lectures/18_single_mean.html#conditions",
    "href": "lectures/18_single_mean.html#conditions",
    "title": "hypothesis test for one mean",
    "section": "Conditions",
    "text": "Conditions\nLarge Independent sample\n\nNo extreme outliers\nLarger than 30\n\nor\nSmall Independent sample\n\nThe data distribution is normal.\nNo clear outliers."
  },
  {
    "objectID": "lectures/18_single_mean.html#check-our-conditions",
    "href": "lectures/18_single_mean.html#check-our-conditions",
    "title": "hypothesis test for one mean",
    "section": "Check our conditions",
    "text": "Check our conditions\n\n#Sample size \nnrow(Togersen_penguins)\n\n[1] 52\n\n# Outliers? \nggplot(Togersen_penguins)+\n  geom_boxplot(aes(x=body_mass_g))"
  },
  {
    "objectID": "lectures/18_single_mean.html#what-is-the-sampling-distribution",
    "href": "lectures/18_single_mean.html#what-is-the-sampling-distribution",
    "title": "hypothesis test for one mean",
    "section": "What is the sampling distribution?",
    "text": "What is the sampling distribution?\nWe could use the sampling distribution… But its much better to use the Student t."
  },
  {
    "objectID": "lectures/18_single_mean.html#the-students-t-dist",
    "href": "lectures/18_single_mean.html#the-students-t-dist",
    "title": "hypothesis test for one mean",
    "section": "The Student’s t dist",
    "text": "The Student’s t dist\nThe student t distribution is similar to the normal distribution in shape. \nIt has wider tails. \nIt is used with confidence intervals and hypothesis testing of a single mean. \nUnlike the normal distribution it works well for small sample sizes if the population is normal distributed."
  },
  {
    "objectID": "lectures/18_single_mean.html#very-short-history",
    "href": "lectures/18_single_mean.html#very-short-history",
    "title": "hypothesis test for one mean",
    "section": "Very Short History",
    "text": "Very Short History\n\n\nWilliam Sealy Gosset\n\n\n\n\nWorked at Guiness and was interested in the chemical properties of barley. source"
  },
  {
    "objectID": "lectures/18_single_mean.html#the-parameters-of-a-student-t.",
    "href": "lectures/18_single_mean.html#the-parameters-of-a-student-t.",
    "title": "hypothesis test for one mean",
    "section": "The parameters of a student t.",
    "text": "The parameters of a student t.\nThe student t takes just one parameter\n\ndf = degree of freedom.\n\n\\(df= n-1\\)"
  },
  {
    "objectID": "lectures/18_single_mean.html#limit-of-t-dist-is-normal",
    "href": "lectures/18_single_mean.html#limit-of-t-dist-is-normal",
    "title": "hypothesis test for one mean",
    "section": "limit of t-dist is normal",
    "text": "limit of t-dist is normal\nAs \\(\\text{lim}_{df \\rightarrow \\infty} t_{dist} \\rightarrow N(\\mu=0,sigma=1)\\)\n\nhttps://en.wikipedia.org/wiki/Student%27s_t-distribution#/media/File:Student_t_pdf.svg"
  },
  {
    "objectID": "lectures/18_single_mean.html#t-dist-is-better-than-the-normal-for-sampling-distributions.",
    "href": "lectures/18_single_mean.html#t-dist-is-better-than-the-normal-for-sampling-distributions.",
    "title": "hypothesis test for one mean",
    "section": "t-dist is better than the normal for sampling distributions.",
    "text": "t-dist is better than the normal for sampling distributions.\nYou can use either if:\n\n\nIf the sample size is large or underlying distribution is normal\nPopulation standard deviation is known \\(\\sigma\\)\nBut if population sd \\(\\sigma\\) is unknown or n is small use student t.\nIn general the t distribution works, the normal less so."
  },
  {
    "objectID": "lectures/18_single_mean.html#the-sampling-distribution-for-sample-mean",
    "href": "lectures/18_single_mean.html#the-sampling-distribution-for-sample-mean",
    "title": "hypothesis test for one mean",
    "section": "The sampling distribution for sample mean:",
    "text": "The sampling distribution for sample mean:\n\\(\\mu \\sim \\text{t}_{df}\\)\n\nThe mean of the t-dist is 0.\n\nThe mean of your sample is \\(\\bar{x}\\) and the standard error is \\(SE = \\frac{s}{\\sqrt{n}}\\)"
  },
  {
    "objectID": "lectures/18_single_mean.html#what-is-df",
    "href": "lectures/18_single_mean.html#what-is-df",
    "title": "hypothesis test for one mean",
    "section": "What is df?",
    "text": "What is df?\n\n\nThe number of values that can vary when finding a mean.\nConsider that you find a mean of 3 numbers. x,y,and z.\nIf I tell you the mean is 10, you can guess any two numbers and the third is forced.\nThis mean would have 2 degrees of freedom."
  },
  {
    "objectID": "lectures/18_single_mean.html#test-statistic-for-a-mean",
    "href": "lectures/18_single_mean.html#test-statistic-for-a-mean",
    "title": "hypothesis test for one mean",
    "section": "test statistic for a mean",
    "text": "test statistic for a mean\nWe’ve skipped discussing test statistics until now, because of pnorm().\nIdeally\n\\[ T = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\]\nor more realistically:\n\\[ T = \\frac{\\bar{x} - \\mu}{\\frac{s_x}{\\sqrt{n}}}\\]"
  },
  {
    "objectID": "lectures/18_single_mean.html#lets-finish-our-hypothesis-test",
    "href": "lectures/18_single_mean.html#lets-finish-our-hypothesis-test",
    "title": "hypothesis test for one mean",
    "section": "Let’s finish our hypothesis test",
    "text": "Let’s finish our hypothesis test\nWe are considering the weight of penguins.\nLast year the weight was 3900, and this yeah its 3706.\nWe checked conditions.\nThe standard deviation is:\n\ns_x = sd(Togersen_penguins$body_mass_g, na.rm = TRUE)\ns_x\n\n[1] 445.1079\n\n\nSo the test statistic is:\n\nT = (3706.373 - 3900)/ (s_x/sqrt(51))\nT\n\n[1] -3.106602"
  },
  {
    "objectID": "lectures/18_single_mean.html#find-pvalue",
    "href": "lectures/18_single_mean.html#find-pvalue",
    "title": "hypothesis test for one mean",
    "section": "Find pvalue",
    "text": "Find pvalue\nWe need to calculate the probability of getting -3.11 for a test statistic.\nMultiply by 2 for a two tailed test.\n\n2 * pt(-3.11, df = 51-1)\n\n[1] 0.003086856"
  },
  {
    "objectID": "lectures/18_single_mean.html#conclusion",
    "href": "lectures/18_single_mean.html#conclusion",
    "title": "hypothesis test for one mean",
    "section": "conclusion",
    "text": "conclusion\nReject the null hypothesis. We have strong evidence to believe that the average weight this year is different from 3900 grams.\nIts possible we made a type 1 error and rejected the null even if it was true."
  },
  {
    "objectID": "lectures/18_single_mean.html#you-can-make-confidence-intervals-with-the-student-t.",
    "href": "lectures/18_single_mean.html#you-can-make-confidence-intervals-with-the-student-t.",
    "title": "hypothesis test for one mean",
    "section": "You can make confidence intervals with the student t.",
    "text": "You can make confidence intervals with the student t.\nIts the same as doing it with the normal distribution.\nExcept you use a t* score instead of z*score.\n\\[ \\bar{x} \\pm t^* SE\\]"
  },
  {
    "objectID": "lectures/18_single_mean.html#lets-make-a-90-ci-for-our-penguin-data.",
    "href": "lectures/18_single_mean.html#lets-make-a-90-ci-for-our-penguin-data.",
    "title": "hypothesis test for one mean",
    "section": "Lets make a 90% CI for our penguin data.",
    "text": "Lets make a 90% CI for our penguin data.\n\\(\\bar{x} = 3706.373\\)\n\\(SE = \\frac{s}{n}=\\frac{445.10}{51} = 8.73\\)\n\\(t^*=\\)\n\nt_star = qt(0.95 , df=50)\nt_star\n\n[1] 1.675905\n\n\n\nx_bar = 3706.373\nSE = s_x/sqrt(51)\n\n# Lower Bound\nx_bar - t_star*SE\n\n[1] 3601.918\n\n# Upper Bound\nx_bar + t_star*SE\n\n[1] 3810.828"
  },
  {
    "objectID": "lectures/18_single_mean.html#conclusion-1",
    "href": "lectures/18_single_mean.html#conclusion-1",
    "title": "hypothesis test for one mean",
    "section": "Conclusion",
    "text": "Conclusion\nWe are 90% confident that the true weight of penguins is between 3602 and 3811."
  },
  {
    "objectID": "lectures/18_single_mean.html#you-try-hypothesis-testing-on-a-single-mean",
    "href": "lectures/18_single_mean.html#you-try-hypothesis-testing-on-a-single-mean",
    "title": "hypothesis test for one mean",
    "section": "You try: Hypothesis testing on a single mean",
    "text": "You try: Hypothesis testing on a single mean\nAwesome Auto data set. 𝑛 = 5, \\(\\bar{x}\\)= 14600, and \\(s_x\\)= 7765.31. Suppose you hear that the Awesome Auto dealership typically sells cars for 18000. You decide to test this claim.\n\nWrite the hypotheses in symbols.\nCheck conditions, then calculate the test statistic, 𝑇 , and the associated degrees of freedom.\nFind and interpret the p-value in this context.\nWhat is the conclusion of the hypothesis test when using 𝛼 = 0.05?"
  },
  {
    "objectID": "lectures/18_single_mean.html#solution",
    "href": "lectures/18_single_mean.html#solution",
    "title": "hypothesis test for one mean",
    "section": "Solution",
    "text": "Solution\n\\[\nH_0: \\mu = 18000 \\\\\nH_a: \\mu \\ne 18000 \\\\\n\\alpha = 0.05\n\\]\nUnfortunately we cannot at present test the normal condition. The cars are independent."
  },
  {
    "objectID": "lectures/18_single_mean.html#test-statistic",
    "href": "lectures/18_single_mean.html#test-statistic",
    "title": "hypothesis test for one mean",
    "section": "Test Statistic",
    "text": "Test Statistic\n\\(T =   \\frac{14600 - 18000}{\\frac{7765.31}{\\sqrt{5}}}\\)\ndf = 4\np-value:\n\n# give info below\nx_bar = 14600\nmu = 18000\ns_x = 7765.31\nn = 5\n\n# test statistic\ntest_stat = (x_bar - mu)/(s_x/sqrt(n))\n\n# Find pvalue\n2*pt(q=test_stat, df=4)\n\n[1] 0.3829896"
  },
  {
    "objectID": "lectures/18_single_mean.html#conclusion-2",
    "href": "lectures/18_single_mean.html#conclusion-2",
    "title": "hypothesis test for one mean",
    "section": "Conclusion",
    "text": "Conclusion\nWith a large p value we find no evidence that the prices at Awesome Auto average 18000.\nWe could never verify that the underlying data was normal."
  },
  {
    "objectID": "lectures/18_single_mean.html#the-t.test",
    "href": "lectures/18_single_mean.html#the-t.test",
    "title": "hypothesis test for one mean",
    "section": "The t.test()",
    "text": "The t.test()\nR, of course, can make this test easy if you are working from a vector of values (x) (instead of sample statistics, like above). You will do this on occasion in your homework.\nYou can also take the time to have R calculate the mean and standard deviation, but t.test() is fine.\n\nt.test(x= , alternative= , mu=)"
  },
  {
    "objectID": "lectures/18_single_mean.html#awesome-auto-revisited",
    "href": "lectures/18_single_mean.html#awesome-auto-revisited",
    "title": "hypothesis test for one mean",
    "section": "Awesome auto revisited",
    "text": "Awesome auto revisited\nSuppose the awesome auto data was:\n\nawesome_auto &lt;- c(15000, 26000, 6000, 17000, 9000)\n\n\nt.test(x = awesome_auto,\n       alternative = \"two\",\n       mu = 18000)\n\n\n    One Sample t-test\n\ndata:  awesome_auto\nt = -0.97905, df = 4, p-value = 0.383\nalternative hypothesis: true mean is not equal to 18000\n95 percent confidence interval:\n  4958.097 24241.903\nsample estimates:\nmean of x \n    14600"
  },
  {
    "objectID": "lectures/18_single_mean.html#you-try-another-one-with-t.test",
    "href": "lectures/18_single_mean.html#you-try-another-one-with-t.test",
    "title": "hypothesis test for one mean",
    "section": "You try: Another one with t.test()",
    "text": "You try: Another one with t.test()\nThe 2017 Toyota Prius Prime has a MPG_e = 54. Consider the prius_mpg data set in the openintro package.\n\nTest the hypothesis that the actual MPG is greater than 54.\n\nConsider Conditions, but do the test either way and we’ll discuss conditions afterwards.\n\nHint: use prius_mpg$_____ to take just one column from the data."
  },
  {
    "objectID": "lectures/18_single_mean.html#my-output",
    "href": "lectures/18_single_mean.html#my-output",
    "title": "hypothesis test for one mean",
    "section": "My output",
    "text": "My output\n\nlibrary(tidyverse)\nlibrary(openintro)\n\nt.test(x=prius_mpg$average_mpg, alternative = \"greater\", mu = 54)\n\n\n    One Sample t-test\n\ndata:  prius_mpg$average_mpg\nt = 5.757, df = 18, p-value = 9.304e-06\nalternative hypothesis: true mean is greater than 54\n95 percent confidence interval:\n 117.4944      Inf\nsample estimates:\nmean of x \n 144.8632"
  },
  {
    "objectID": "lectures/18_single_mean.html#preview-bootstrapping",
    "href": "lectures/18_single_mean.html#preview-bootstrapping",
    "title": "hypothesis test for one mean",
    "section": "Preview: Bootstrapping",
    "text": "Preview: Bootstrapping\n\nlibrary(infer)\n\nx_bar &lt;- mean(prius_mpg$average_mpg)\n\nprius_randomization &lt;-prius_mpg |&gt;\n  specify(response = average_mpg)|&gt;\n  hypothesise(null= \"point\", mu = 54) |&gt;\n  generate(reps = 5000)|&gt;\n  calculate(stat = \"mean\")"
  },
  {
    "objectID": "lectures/18_single_mean.html#graph-and-pvalue",
    "href": "lectures/18_single_mean.html#graph-and-pvalue",
    "title": "hypothesis test for one mean",
    "section": "Graph and pvalue",
    "text": "Graph and pvalue\n\nprius_randomization |&gt;  visualise()+\n  shade_p_value(obs_stat = x_bar, direction = \"greater\")\n\nprius_randomization |&gt;\n  get_pvalue(obs_stat = x_bar, direction = \"greater\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0"
  },
  {
    "objectID": "lectures/19_diff-of-means.html",
    "href": "lectures/19_diff-of-means.html",
    "title": "Difference of Means",
    "section": "",
    "text": "Find a partner (or two) and grab some chalkboard\nDo this hypothesis test.\nThe average height of Smith students is thought to be 64 inches. Our class has an average height of 65 inches with a standard deviation of 3.2. There were 34 students in our sample.\nTest the hypothesis that the true mean is 64 twice\n\nonce using the observed statistic to find a p-value.\nonce with the test statistic to find the same p-value."
  },
  {
    "objectID": "lectures/19_diff-of-means.html#warm-up",
    "href": "lectures/19_diff-of-means.html#warm-up",
    "title": "Difference of Means",
    "section": "",
    "text": "Find a partner (or two) and grab some chalkboard\nDo this hypothesis test.\nThe average height of Smith students is thought to be 64 inches. Our class has an average height of 65 inches with a standard deviation of 3.2. There were 34 students in our sample.\nTest the hypothesis that the true mean is 64 twice\n\nonce using the observed statistic to find a p-value.\nonce with the test statistic to find the same p-value."
  },
  {
    "objectID": "lectures/19_diff-of-means.html#warm-up-again-with-r",
    "href": "lectures/19_diff-of-means.html#warm-up-again-with-r",
    "title": "Difference of Means",
    "section": "warm up again with R",
    "text": "warm up again with R\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(googlesheets4)\n\n# Making CI from some sample proportions.\n\nclass_heights &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/1x9srZXDoYzKGew1f-y4brMbN8dl4QM66pc-dmCBWHQY/edit?usp=sharing\",\n                            sheet = \"220-01\",\n                            range = \"1:35\")|&gt;\n  select(height)\n\n! Using an auto-discovered, cached token.\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n  See gargle's \"Non-interactive auth\" vignette for more details:\n  &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt;\nℹ The googlesheets4 package is using a cached token for 'nschwab@smith.edu'.\nAuto-refreshing stale OAuth token.\n✔ Reading from \"Schwab SDS 220 Fall 23 Pre-Course Questionnaire (Responses)\".\n✔ Range ''220-01'!1:35'.\n\n\n\nt.test(class_heights$height, mu=64)\n\n\n    One Sample t-test\n\ndata:  class_heights$height\nt = 1.8954, df = 33, p-value = 0.06683\nalternative hypothesis: true mean is not equal to 64\n95 percent confidence interval:\n 63.92442 66.13440\nsample estimates:\nmean of x \n 65.02941"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#side-note-prop.test",
    "href": "lectures/19_diff-of-means.html#side-note-prop.test",
    "title": "Difference of Means",
    "section": "Side note: prop.test()",
    "text": "Side note: prop.test()\nThere is also a prop.test() function that will test a proportion hypothesis from data based on mathematical formula (as opposed to bootstrapping)."
  },
  {
    "objectID": "lectures/19_diff-of-means.html#new-test-difference-of-two-means",
    "href": "lectures/19_diff-of-means.html#new-test-difference-of-two-means",
    "title": "Difference of Means",
    "section": "New test: Difference of two means",
    "text": "New test: Difference of two means\nAnother hypothesis test.\n\nConditions\nDistributions\nNew Standard Error\nNew df"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#reading",
    "href": "lectures/19_diff-of-means.html#reading",
    "title": "Difference of Means",
    "section": "Reading",
    "text": "Reading\nRead chapter 20 before these lectures."
  },
  {
    "objectID": "lectures/19_diff-of-means.html#confidence-interval-99",
    "href": "lectures/19_diff-of-means.html#confidence-interval-99",
    "title": "Difference of Means",
    "section": "Confidence interval 99%",
    "text": "Confidence interval 99%\nCheck independence extended.\nNo extreme outliers."
  },
  {
    "objectID": "lectures/19_diff-of-means.html#input-values-calculate-se",
    "href": "lectures/19_diff-of-means.html#input-values-calculate-se",
    "title": "Difference of Means",
    "section": "Input values & calculate SE",
    "text": "Input values & calculate SE\n\\(\\bar{x}_1 - \\bar{x}_2 \\pm t^* SE\\)\n\n# Automatic car stats\nx_1 = 23.7\ns_1 = 3.9\nn_1 = 25\n\n# Manual car stats\nx_2 = 30.9\ns_2 = 5.13\nn_2 = 25\n\n# Calculate the SE\nSE =  sqrt(s_1^2/n_1 +s_2^2/n_2)\n\n# Calculate the t_star\nt_star = qt(p = 0.005, df = 24, lower.tail = FALSE)"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#conclusion",
    "href": "lectures/19_diff-of-means.html#conclusion",
    "title": "Difference of Means",
    "section": "Conclusion",
    "text": "Conclusion\nWe are 99% sure that the true difference in mpg is between 3.6 and 10.8.\n\n#Lower bound\nx_1 - x_2 - t_star*SE\n\n[1] -10.80477\n\n# Upper Bound\nx_1 - x_2 + t_star*SE\n\n[1] -3.595228"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#hypothesis-test",
    "href": "lectures/19_diff-of-means.html#hypothesis-test",
    "title": "Difference of Means",
    "section": "Hypothesis test",
    "text": "Hypothesis test\nConditions are checked and values are input.\nNotation:\n\\[\nH_o: \\mu_1 = \\mu_2\\\\\nH_a: \\mu_1 \\ne \\mu_2\\\\\n\\alpha = 0.05\n\\]"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#calculate-pvalue",
    "href": "lectures/19_diff-of-means.html#calculate-pvalue",
    "title": "Difference of Means",
    "section": "Calculate pvalue",
    "text": "Calculate pvalue\nTest statistic:\n\\[\nT = \\frac{\\bar{x}_1-\\bar{x}_2 - 0 }{SE}\n\\]\n\nTest_stat = x_1 - x_2\n\n2*pt(q=Test_stat, df = 24)\n\n[1] 1.933053e-07"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#conclusion-1",
    "href": "lectures/19_diff-of-means.html#conclusion-1",
    "title": "Difference of Means",
    "section": "Conclusion:",
    "text": "Conclusion:\nWith a pvalue close to zero we have strong evidence to reject the null hypothesis in favor of the alternative. It seems that the average fuel economy of automatic vs manual cars is different.\nIt is possible we have made a type 1 error."
  },
  {
    "objectID": "lectures/19_diff-of-means.html#solution",
    "href": "lectures/19_diff-of-means.html#solution",
    "title": "Difference of Means",
    "section": "Solution:",
    "text": "Solution:\nWe should first check out absenteeism. ?absenteeism\nIndependence between and within groups.\ncheck for outliers:\n\nlibrary(tidyverse)\nlibrary(openintro)\n\nggplot(data= absenteeism, aes(x=days, color = sex))+\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#oh-no",
    "href": "lectures/19_diff-of-means.html#oh-no",
    "title": "Difference of Means",
    "section": "Oh no",
    "text": "Oh no\nThose outliers seem pretty extreme. We should probably not do this test with a math model, like t.test()"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#lets-do-it-anyway-for-practice",
    "href": "lectures/19_diff-of-means.html#lets-do-it-anyway-for-practice",
    "title": "Difference of Means",
    "section": "Let’s do it anyway for practice",
    "text": "Let’s do it anyway for practice\n\\[\nH_o: \\mu_1 = \\mu_2\\\\\nH_a: \\mu_1 \\ne \\mu_2\\\\\n\\alpha = 0.05\n\\]\n\nt.test(absenteeism$days ~ absenteeism$sex, alternative = \"t\")\n\n\n    Welch Two Sample t-test\n\ndata:  absenteeism$days by absenteeism$sex\nt = -1.0058, df = 136.35, p-value = 0.3163\nalternative hypothesis: true difference in means between group F and group M is not equal to 0\n95 percent confidence interval:\n -8.096135  2.637044\nsample estimates:\nmean in group F mean in group M \n       15.22500        17.95455"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#conditions-1",
    "href": "lectures/19_diff-of-means.html#conditions-1",
    "title": "Difference of Means",
    "section": "Conditions",
    "text": "Conditions\nIndependence\nOutliers seem to still be a problem\n\nggplot(data= absenteeism, aes(x=days, color = eth))+\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#doing-the-test-anyway",
    "href": "lectures/19_diff-of-means.html#doing-the-test-anyway",
    "title": "Difference of Means",
    "section": "Doing the test anyway",
    "text": "Doing the test anyway\n\\[\nH_o: \\mu_1 = \\mu_2\\\\\nH_a: \\mu_1 \\ne \\mu_2\\\\\n\\alpha = 0.05\n\\]\n\nt.test(absenteeism$days~absenteeism$eth, alternative = \"t\")\n\n\n    Welch Two Sample t-test\n\ndata:  absenteeism$days by absenteeism$eth\nt = 3.4358, df = 126.85, p-value = 0.0007991\nalternative hypothesis: true difference in means between group A and group N is not equal to 0\n95 percent confidence interval:\n  3.837747 14.262384\nsample estimates:\nmean in group A mean in group N \n       21.23188        12.18182"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#do-it-with-a-simulation",
    "href": "lectures/19_diff-of-means.html#do-it-with-a-simulation",
    "title": "Difference of Means",
    "section": "Do it with a simulation",
    "text": "Do it with a simulation\n\nlibrary(infer)\n\nset.seed(9)\n\nabsenteeism_randomization &lt;- absenteeism |&gt;\n  specify( days ~ eth )|&gt;\n  hypothesise(null= \"independence\") |&gt;\n  generate(reps = 5000, type = \"permute\")|&gt;\n  calculate(stat = \"diff in means\", order = c(\"A\",\"N\"))"
  },
  {
    "objectID": "lectures/19_diff-of-means.html#visualize-and-pvalue",
    "href": "lectures/19_diff-of-means.html#visualize-and-pvalue",
    "title": "Difference of Means",
    "section": "Visualize and pvalue",
    "text": "Visualize and pvalue\nThe observed difference is \\(21.2 - 12.2 \\approx 9\\)\n\nabsenteeism_randomization |&gt;\n  visualise()+\n  shade_p_value(obs_stat = 9, direction = \"right\")\n\nabsenteeism_randomization|&gt;\n  get_p_value(obs_stat = 9, direction = \"both\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1  0.0004"
  },
  {
    "objectID": "lectures/20_ANOVA.html",
    "href": "lectures/20_ANOVA.html",
    "title": "ANOVA part 1",
    "section": "",
    "text": "library(openintro)\n\nLoading required package: airports\n\n\nLoading required package: cherryblossom\n\n\nLoading required package: usdata\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "lectures/20_ANOVA.html#libraries",
    "href": "lectures/20_ANOVA.html#libraries",
    "title": "ANOVA part 1",
    "section": "",
    "text": "library(openintro)\n\nLoading required package: airports\n\n\nLoading required package: cherryblossom\n\n\nLoading required package: usdata\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "lectures/20_ANOVA.html#comparing-multiple-groups",
    "href": "lectures/20_ANOVA.html#comparing-multiple-groups",
    "title": "ANOVA part 1",
    "section": "Comparing multiple groups",
    "text": "Comparing multiple groups\nWe use Analysis of Variance for testing if there is a difference between many means."
  },
  {
    "objectID": "lectures/20_ANOVA.html#new-distribution-f",
    "href": "lectures/20_ANOVA.html#new-distribution-f",
    "title": "ANOVA part 1",
    "section": "New distribution: F",
    "text": "New distribution: F\nThe F distribution looks like:"
  },
  {
    "objectID": "lectures/20_ANOVA.html#p-value-and-ci",
    "href": "lectures/20_ANOVA.html#p-value-and-ci",
    "title": "ANOVA part 1",
    "section": "p-value and CI",
    "text": "p-value and CI\nWe find the p-value in the right tail.\nThere is no real confidence interval."
  },
  {
    "objectID": "lectures/20_ANOVA.html#conditions",
    "href": "lectures/20_ANOVA.html#conditions",
    "title": "ANOVA part 1",
    "section": "Conditions:",
    "text": "Conditions:\n\nthe observations are independent within and between groups,\n\n\n\nthe responses within each group are nearly normal, and*\n\n\n\nthe variability across the groups is about equal."
  },
  {
    "objectID": "lectures/20_ANOVA.html#rule-of-thumb",
    "href": "lectures/20_ANOVA.html#rule-of-thumb",
    "title": "ANOVA part 1",
    "section": "Rule of Thumb",
    "text": "Rule of Thumb\n\nThe variance are equal condition has a rule of thumb.\nIf the largest is not more than four times the smallest all is well.\n\\[\n\\frac{\\sigma^2_{max}}{\\sigma^2_{min}}\\le 4\n\\]\nor\nIf the largest SD/ smalest SD is between 0.5 and 2.\n\\[\n\\frac{\\sigma_{max}}{\\sigma_{min}}\\le 2\n\\]"
  },
  {
    "objectID": "lectures/20_ANOVA.html#a-test",
    "href": "lectures/20_ANOVA.html#a-test",
    "title": "ANOVA part 1",
    "section": "A test",
    "text": "A test\nThere are three classes that took a midterm. We want to know if the exam average for any of the classes is different.\n\nggplot(data=classdata) +\n  geom_boxplot(\n    aes(x= m1, color = lecture)    )"
  },
  {
    "objectID": "lectures/20_ANOVA.html#summary-stats",
    "href": "lectures/20_ANOVA.html#summary-stats",
    "title": "ANOVA part 1",
    "section": "Summary stats",
    "text": "Summary stats\nIs the variance about the same?\n\nclassdata |&gt;\n  group_by(lecture) |&gt;\n  summarise(mean = mean(m1), sd = sd(m1), count = n())|&gt;\n  kable(digits = 1, align = \"l\")\n\n\n\n\nlecture\nmean\nsd\ncount\n\n\n\n\na\n75.1\n13.9\n58\n\n\nb\n72.0\n13.8\n55\n\n\nc\n78.9\n13.1\n51"
  },
  {
    "objectID": "lectures/20_ANOVA.html#notation",
    "href": "lectures/20_ANOVA.html#notation",
    "title": "ANOVA part 1",
    "section": "Notation:",
    "text": "Notation:\n\n\\(H_0: \\mu_1 =\\mu_2 =\\mu_3\\)\n\\(H_a:\\) At least one mean is different.\n\\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "lectures/20_ANOVA.html#the-test-computation",
    "href": "lectures/20_ANOVA.html#the-test-computation",
    "title": "ANOVA part 1",
    "section": "The test computation",
    "text": "The test computation\nIs done by R with aov() . We will not be doing this test by hand.\n\nresults &lt;- aov( m1 ~ lecture, data = classdata )\nsummary(results)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)  \nlecture       2   1290   645.1   3.484  0.033 *\nResiduals   161  29810   185.2                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "lectures/20_ANOVA.html#conclusion",
    "href": "lectures/20_ANOVA.html#conclusion",
    "title": "ANOVA part 1",
    "section": "Conclusion:",
    "text": "Conclusion:\nReject the null, one of the exam averages is different than the other two."
  },
  {
    "objectID": "lectures/20_ANOVA.html#try-one",
    "href": "lectures/20_ANOVA.html#try-one",
    "title": "ANOVA part 1",
    "section": "Try one:",
    "text": "Try one:\nIn the iris data set, would it be appropriate to do ANOVA on petal.length? Why or why not?\nMake a summary table or boxplot to justifty."
  },
  {
    "objectID": "lectures/20_ANOVA.html#my-code-for-petal.length",
    "href": "lectures/20_ANOVA.html#my-code-for-petal.length",
    "title": "ANOVA part 1",
    "section": "My code for petal.length",
    "text": "My code for petal.length\nFor the table:\n\niris |&gt;\n   group_by(Species) |&gt;\n   summarise(mean = mean(Petal.Length), standard_dev = sd(Petal.Length), count =n())|&gt;\n   kable(digits = 1, align = \"c\")\n\nFor the graph\n\niris |&gt;\n  ggplot(aes(Petal.Length, color = Species))+\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/20_ANOVA.html#my-summary-table-and-graph",
    "href": "lectures/20_ANOVA.html#my-summary-table-and-graph",
    "title": "ANOVA part 1",
    "section": "My summary table and graph",
    "text": "My summary table and graph\n\niris |&gt;\n   group_by(Species) |&gt;\n   summarise(mean = mean(Petal.Length), sd = sd(Petal.Length), count =n())|&gt;\n   kable(digits = 1, align = \"c\")\n\n\n\n\nSpecies\nmean\nsd\ncount\n\n\n\n\nsetosa\n1.5\n0.2\n50\n\n\nversicolor\n4.3\n0.5\n50\n\n\nvirginica\n5.6\n0.6\n50\n\n\n\n\n\n\niris |&gt;\n  ggplot(aes(Petal.Length, color = Species))+\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/20_ANOVA.html#a-flowers-sepal",
    "href": "lectures/20_ANOVA.html#a-flowers-sepal",
    "title": "ANOVA part 1",
    "section": "A flower’s sepal",
    "text": "A flower’s sepal"
  },
  {
    "objectID": "lectures/20_ANOVA.html#try-sepal.length-from-iris.",
    "href": "lectures/20_ANOVA.html#try-sepal.length-from-iris.",
    "title": "ANOVA part 1",
    "section": "Try Sepal.Length from iris.",
    "text": "Try Sepal.Length from iris.\nIs it appropriate to do ANOVA on Sepal.Length?\n\n\n\n\n\nSpecies\nmean\nsd\n\n\n\n\nsetosa\n5.0\n0.4\n\n\nversicolor\n5.9\n0.5\n\n\nvirginica\n6.6\n0.6"
  },
  {
    "objectID": "lectures/20_ANOVA.html#look-at-the-graph",
    "href": "lectures/20_ANOVA.html#look-at-the-graph",
    "title": "ANOVA part 1",
    "section": "Look at the graph",
    "text": "Look at the graph\nIs there one mean that’s different?\n\niris |&gt;\n  ggplot(aes(Sepal.Length, color = Species))+\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/20_ANOVA.html#do-the-test",
    "href": "lectures/20_ANOVA.html#do-the-test",
    "title": "ANOVA part 1",
    "section": "Do the test",
    "text": "Do the test\n\nNotation\nTest\nConclusion\n\n\nresults &lt;- aov( Sepal.Length ~ Species, data = iris )\nsummary(results)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nSpecies       2  63.21  31.606   119.3 &lt;2e-16 ***\nResiduals   147  38.96   0.265                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "lectures/20_ANOVA.html#problem-5-7-or-9",
    "href": "lectures/20_ANOVA.html#problem-5-7-or-9",
    "title": "ANOVA part 1",
    "section": "Problem 5, 7, or 9",
    "text": "Problem 5, 7, or 9\nLink to exercises"
  },
  {
    "objectID": "lectures/21_linear_regression.html",
    "href": "lectures/21_linear_regression.html",
    "title": "Linear regression one predictor",
    "section": "",
    "text": "library(openintro)\n\nLoading required package: airports\n\n\nLoading required package: cherryblossom\n\n\nLoading required package: usdata\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(broom)\nlibrary(statsr)\n\nLoading required package: BayesFactor\nLoading required package: coda\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n************\nWelcome to BayesFactor 0.9.12-4.7. If you have questions, please contact Richard Morey (richarddmorey@gmail.com).\n\nType BFManual() to open the manual.\n************\n\nAttaching package: 'statsr'\n\nThe following objects are masked from 'package:openintro':\n\n    calc_streak, evals, nycflights, present\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "lectures/21_linear_regression.html#libraries",
    "href": "lectures/21_linear_regression.html#libraries",
    "title": "Linear regression one predictor",
    "section": "",
    "text": "library(openintro)\n\nLoading required package: airports\n\n\nLoading required package: cherryblossom\n\n\nLoading required package: usdata\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(broom)\nlibrary(statsr)\n\nLoading required package: BayesFactor\nLoading required package: coda\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n************\nWelcome to BayesFactor 0.9.12-4.7. If you have questions, please contact Richard Morey (richarddmorey@gmail.com).\n\nType BFManual() to open the manual.\n************\n\nAttaching package: 'statsr'\n\nThe following objects are masked from 'package:openintro':\n\n    calc_streak, evals, nycflights, present\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows"
  },
  {
    "objectID": "lectures/21_linear_regression.html#recall-linear-regression",
    "href": "lectures/21_linear_regression.html#recall-linear-regression",
    "title": "Linear regression one predictor",
    "section": "Recall Linear Regression",
    "text": "Recall Linear Regression\n\nstarbucks |&gt;\n  ggplot()+\n  geom_point(aes(x=fat, y= calories))"
  },
  {
    "objectID": "lectures/21_linear_regression.html#modeling-with-a-line.",
    "href": "lectures/21_linear_regression.html#modeling-with-a-line.",
    "title": "Linear regression one predictor",
    "section": "Modeling with a line.",
    "text": "Modeling with a line.\nFit the data with a model.\n\nstar_model &lt;- lm(calories ~ fat, data= starbucks) \nstar_model |&gt; tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    184.      17.3       10.6 1.25e-16\n2 fat             11.3      1.12      10.1 1.32e-15"
  },
  {
    "objectID": "lectures/21_linear_regression.html#add-the-model-to-the-points.",
    "href": "lectures/21_linear_regression.html#add-the-model-to-the-points.",
    "title": "Linear regression one predictor",
    "section": "Add the model to the points.",
    "text": "Add the model to the points.\n\nstarbucks |&gt;\n  ggplot(aes(x=fat, y= calories))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/21_linear_regression.html#model-outputs-tidy",
    "href": "lectures/21_linear_regression.html#model-outputs-tidy",
    "title": "Linear regression one predictor",
    "section": "Model outputs: tidy",
    "text": "Model outputs: tidy\n\n#tidy() give the regression output\ntidy(star_model) |&gt;\n  kable()\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n183.73375\n17.277012\n10.63458\n0\n\n\nfat\n11.26651\n1.117087\n10.08562\n0"
  },
  {
    "objectID": "lectures/21_linear_regression.html#summary",
    "href": "lectures/21_linear_regression.html#summary",
    "title": "Linear regression one predictor",
    "section": "summary()",
    "text": "summary()\n\nsummary(star_model)\n\n\nCall:\nlm(formula = calories ~ fat, data = starbucks)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-132.599  -44.130    3.469   54.868  126.134 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  183.734     17.277   10.63  &lt; 2e-16 ***\nfat           11.267      1.117   10.09 1.32e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 69.1 on 75 degrees of freedom\nMultiple R-squared:  0.5756,    Adjusted R-squared:  0.5699 \nF-statistic: 101.7 on 1 and 75 DF,  p-value: 1.32e-15"
  },
  {
    "objectID": "lectures/21_linear_regression.html#what-were-we-doing",
    "href": "lectures/21_linear_regression.html#what-were-we-doing",
    "title": "Linear regression one predictor",
    "section": "What were we doing?",
    "text": "What were we doing?\n\nMake a model\nTrying to figure out if the model is reasonable\n\nlooking at the correlation coefficent r."
  },
  {
    "objectID": "lectures/21_linear_regression.html#what-will-we-do-today",
    "href": "lectures/21_linear_regression.html#what-will-we-do-today",
    "title": "Linear regression one predictor",
    "section": "What will we do today?",
    "text": "What will we do today?\n\nA hypothesis test to see if the slope is a number other than zero.\nrecall: \\(y= \\beta_0 + \\beta_1 x\\)\n\\(\\beta_1\\) is the slope.\nIf the slope is zero there is no relationship between y and x."
  },
  {
    "objectID": "lectures/21_linear_regression.html#conditions",
    "href": "lectures/21_linear_regression.html#conditions",
    "title": "Linear regression one predictor",
    "section": "Conditions:",
    "text": "Conditions:\n\n\nLinearity* data has to be linear\n\nData has to be independent\n\nwatch out for time series.\n\nnearly normal residuals\n\nlook for random disbursment around the zero line of residual plot.\n\nconstant or equal variability\n\nthe points in the residual plot should not have a distinct/changing pattern.\n\n\nThe book gives the acronym of LINE."
  },
  {
    "objectID": "lectures/21_linear_regression.html#some-examples",
    "href": "lectures/21_linear_regression.html#some-examples",
    "title": "Linear regression one predictor",
    "section": "Some examples:",
    "text": "Some examples:\nIndependence problems\n\narbuthnot |&gt;\n  ggplot(aes(year,boys))+\n  geom_point() +\n  geom_smooth(method = \"lm\" , se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/21_linear_regression.html#linear-problems",
    "href": "lectures/21_linear_regression.html#linear-problems",
    "title": "Linear regression one predictor",
    "section": "Linear Problems",
    "text": "Linear Problems"
  },
  {
    "objectID": "lectures/21_linear_regression.html#normal-issues",
    "href": "lectures/21_linear_regression.html#normal-issues",
    "title": "Linear regression one predictor",
    "section": "Normal issues",
    "text": "Normal issues"
  },
  {
    "objectID": "lectures/21_linear_regression.html#normal-issues-again",
    "href": "lectures/21_linear_regression.html#normal-issues-again",
    "title": "Linear regression one predictor",
    "section": "Normal issues again",
    "text": "Normal issues again"
  },
  {
    "objectID": "lectures/21_linear_regression.html#starbucks-calories-vs-fat.",
    "href": "lectures/21_linear_regression.html#starbucks-calories-vs-fat.",
    "title": "Linear regression one predictor",
    "section": "Starbucks calories vs fat.",
    "text": "Starbucks calories vs fat.\n\nstarbucks |&gt;\n  ggplot(aes(x=fat, y= calories))+\n  geom_point()+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/21_linear_regression.html#what-about-this",
    "href": "lectures/21_linear_regression.html#what-about-this",
    "title": "Linear regression one predictor",
    "section": "What about this?",
    "text": "What about this?\n\narbuthnot |&gt;\n  ggplot(aes(x = girls, y = boys))+\n  geom_point()+\n  labs(title = \"Boys vs Girls\",\n       subtitle = \"Born in London in the 1600s\")+\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/21_linear_regression.html#residuals-girl-vs-boy-births",
    "href": "lectures/21_linear_regression.html#residuals-girl-vs-boy-births",
    "title": "Linear regression one predictor",
    "section": "Residuals girl vs boy births",
    "text": "Residuals girl vs boy births"
  },
  {
    "objectID": "lectures/21_linear_regression.html#recall",
    "href": "lectures/21_linear_regression.html#recall",
    "title": "Linear regression one predictor",
    "section": "Recall",
    "text": "Recall\n\\[\ny=\\beta_0+\\beta_1 x + e\n\\]\n\n\\(\\beta_0\\) = intercept\n\\(\\beta_1\\) = slope\nx is the predictor variable\ny is the response variable\ne is the error"
  },
  {
    "objectID": "lectures/21_linear_regression.html#relationship-between-variable-x-and-y",
    "href": "lectures/21_linear_regression.html#relationship-between-variable-x-and-y",
    "title": "Linear regression one predictor",
    "section": "Relationship between variable x and y?",
    "text": "Relationship between variable x and y?\nIf there is no relationship the slope is 0\nIf there is a relationship the slope is not zero.\nWe do\n\\[\nH_0: \\beta_1 = 0 \\\\\nH_1: \\beta_1 \\ne 0\n\\]\n(We could do other tests on r - the correlation coefficient or \\(\\beta_0\\) )"
  },
  {
    "objectID": "lectures/21_linear_regression.html#the-t-distribution",
    "href": "lectures/21_linear_regression.html#the-t-distribution",
    "title": "Linear regression one predictor",
    "section": "The t distribution",
    "text": "The t distribution\nThe distribution of the slopes of an infinite number of samples would be a student t.\nSo we are doing a t test with this test statistic:\n\\(T = \\frac{\\hat{\\beta}_1-0} {\\text{SE}}\\)\ndf= n-2\nWe’ll let R calculate \\(SE\\) and \\(\\hat{\\beta_1}\\)."
  },
  {
    "objectID": "lectures/21_linear_regression.html#the-test",
    "href": "lectures/21_linear_regression.html#the-test",
    "title": "Linear regression one predictor",
    "section": "The test",
    "text": "The test\n\\[\nH_0: \\beta_1 = 0 \\\\\nH_1: \\beta_1 \\ne 0\n\\]\n\nresults &lt;- lm(boys ~ girls, data= arbuthnot)\ntidy(results)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   185.     59.8         3.09 2.74e- 3\n2 girls           1.03    0.0104     99.6  1.21e-85"
  },
  {
    "objectID": "lectures/21_linear_regression.html#some-vocab",
    "href": "lectures/21_linear_regression.html#some-vocab",
    "title": "Linear regression one predictor",
    "section": "Some Vocab",
    "text": "Some Vocab\n\\(r\\) - correlation coefficient\n\\(r^2\\) - coefficient of determination\n\\(r^2\\) is the proportion of the variability that can be explained by the explanatory variable"
  },
  {
    "objectID": "lectures/21_linear_regression.html#practice-problem",
    "href": "lectures/21_linear_regression.html#practice-problem",
    "title": "Linear regression one predictor",
    "section": "Practice Problem",
    "text": "Practice Problem\nThe diamonds data set in R contains the prices and other attributes of almost 54,000 diamonds. We want to see if carat (weight of the diamond) is a good predictor for price (in US dollars).\n\nWrite the hypotheses.\nCheck the conditions and comment on any potential violations.\nWhat is the p-value and conclusion?"
  },
  {
    "objectID": "lectures/21_linear_regression.html#homework-time",
    "href": "lectures/21_linear_regression.html#homework-time",
    "title": "Linear regression one predictor",
    "section": "Homework Time",
    "text": "Homework Time\nProblem 3 and 6 in class."
  }
]