---
title: "Intro to Linear Regression"
subtitle: "IMS, Ch. 7.1"
author: "Ben Baumer edited by Nic Schwab "
format:
  revealjs: 
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    theme: beige
date: |
  2023-09-22
execute: 
  echo: true
---

## Read Before Lecture

[Chapter 7 Linear Regression with a single predictor](https://openintro-ims.netlify.app/model-slr)

## Graph of Arbuthonot

```{r calc-prop-boys-vars}
#| echo = FALSE

library(openintro)
library(tidyverse)
library(broom)
```

## Bivariate Relationships

- Two variables

- **Response** variable 
- **Explanatory** variable 

## Response

Response variable (aka dependent variable): the variable that you are trying to understand/model

## Explanatory

Explanatory variable (aka independent variable, aka predictor): the variable that you can measure that you think might be related to the response variable

## Scatterplot for two numerical variables

::: incremental

- response variable on $y$-axis and explanatory variable on $x$-axis
- `geom_point()`
- What are we looking for?
    - Overall patterns and deviations from those patterns
    - Form (e.g. linear, quadratic, etc.), direction (positive or negative), and strength (how much scatter?)
    - Outliers

:::

## Examine the babies data

From the babies dataset, let's make a scatter plot of gestation (explanatory) vs bwt (response). 

- Characterize the distribution
    - Form
    - Direction
    - Strength
    - Outliers

## Birthweight of babies

```{r}
ggplot(data = babies, aes(x = gestation, y = bwt)) +
  geom_point()
```

::: footer
`help(babies)`
:::

## Your turn

::: incremental

- Use a scatter plot to analyze the relationship between the `height` and `mass` of characters in the `starwars` data frame

- Characterize the distribution
    - Form
    - Direction
    - Strength
    - Outliers

:::

## Solution: starwars characters height vs. mass.

There is one outlier, it is Jaba the Hut. 

```{r}
ggplot(data = starwars, aes(x = height, y = mass)) +
  geom_point()
```

# Correlation

## (Pearson Product-Moment) correlation coefficient

::: incremental

- measure of the **strength** and **direction** of the **linear** relationship between two numerical variables 
- denoted $r$ 
- measured on the scale of $[-1, 1]$
- `cor(data1,data2,use = "complete.obs")`

:::

::: footer
<https://en.wikipedia.org/wiki/Correlation>
:::

## Find the correlation for babies

```{r}
summarise(.data = babies, r = cor(gestation,bwt,use="complete.obs"))
```


##  You try

Find the correlation coefficient for StarWars `height` vs `mass`. Hint: copy and edit the code from above. 

## Solution

```{r}
summarise(.data = starwars, r = cor(height, mass ,use="complete.obs"))
```

## Filtering out outliers   

We might want to remove Jaba The Hut from the data. This is not something you need to know how to do. But if I filter data you are expected to graph it. 

- `filter()` out the one massive character and create a new df
- find the new correlation coefficient

## Graph the new starwars scatter plot

```{r}
new_starwars <- filter(.data = starwars, mass < 500)
summarise(.data = new_starwars, r = cor(height, mass ,use="complete.obs"))
```

```{r}
#| echo: FALSE
ggplot(data = new_starwars, aes(x = height, y = mass)) +
  geom_point() 
```

## Add the regression line to babies.

```{r}
#Filter out the babies born before 259 days. They are premature
babies <- filter(.data = babies, gestation > 259)

ggplot(data=babies, aes(x = gestation, y = bwt)) +
  geom_point()+
  geom_smooth(method = "lm", se=FALSE)
```

## The equation of that regression. 

```{r}
# Save the linear regression object. 
baby_model <- lm(bwt~gestation,data=babies)

# Look at the summary output of that object. 
tidy(baby_model)
```

## Add the regression line to new_starwars

::: incremental
- Do you think it is fair to remove the outlier from starwars? 

- Can we remove outliers from babies? 
:::

## [Anscombe](http://en.wikipedia.org/wiki/Anscombe%27s_quartet)

```{r}
#| echo: false
ds <- anscombe %>%
  mutate(id = row_number()) %>%
  pivot_longer(-id, names_to = "key", values_to = "val") %>%
  separate(key, into = c("variable", "set"), sep = 1) %>%
  pivot_wider(names_from = variable, values_from = val)
ds %>%
  group_by(set) %>%
  summarize(N = n(), mean(x), mean(y), cor(x,y))
```

::: incremental

- same mean
- same standard deviation
- same correlation coefficient is the same (up to three digits)!

:::

## Anscombe plots

```{r}
ggplot(data = ds, aes(x = x, y = y)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = 0) + 
  facet_wrap(~set)
```


## Datasaurus

<iframe width="1024" height="576" src="https://www.youtube.com/embed/It4UA75z_KQ" title="Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical ..." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## More examples

![](http://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/1000px-Correlation_examples2.svg.png)

## Beware

::: incremental

- Note that correlation only measures the strength of a **linear** relationship 

- **Always** graph your data!

:::

# [Spurious Correlations](http://www.tylervigen.com/)

## Reading for next lecture 

No additional reading
