---
title: "Hypothesis Testing"
author: "Schwab"
format: 
  revealjs:
    theme: beige
editor: visual
---

## Example: Ebola

::: incremental
-   Pretend: We are studying how New Yorkers feel about a mandatory 14 day quarantine for Ebola exposure.

-   We ask: do you favor a "mandatory 14-day quarantine for anyone who has come in contact with an Ebola patient?"
:::

[Ebola in New York City](https://en.wikipedia.org/wiki/Ebola_virus_cases_in_the_United_States)

## Survey Data

Our question: We want to know how New Yorkers feel on quarantine of Ebola after the COVID-19 pandemic.

## The 2014 data

We have past data to compare to from 2014. Its called `ebola_survey` and is our best guess as how New Yorkers felt about mandatory quarantine pre pandemic. This will be our assumed $p$.

```{r}
library(tidyverse)
library(openintro)
count(ebola_survey,quarantine)
```

$p= 854/1042 \approx 0.82$ This is a reasonable estimate for *p* because we have not other data to the contrary.

## Let's now assume we did a follow up:

We ask 1000 people if they favor a mandatory 14 day quarantine for individuals that have been in contact with Ebola.

Here are the results.

```{r}
tribble(
  ~against, ~favor,
  486, 514
)
```

And so $\hat{p} = 514/1000 = 0.514$ Which seems very different from $p=0.82$

## p vs $\hat{p}$

::: incremental
-   $\hat{p}$ - the sample statistic. It is a proportion in this case.

    -   This is how the current sample of New Yorkers feel about a mandatory quarantine.

-   p - The assumed population parameter, also a proportion.

    -   We assume this is how all New Yorkers feel about a mandatory quarantine.
:::

## The question.

> If the sentiment from 2014 New Yorkers is unchanged today, what is the probability we would have gotten $\hat{p} = 0.514$ based on the 2014 sample?

::: incremental
-   Is it likely or unlikely

    -   Likely will be anything more than $\alpha = 0.05$

    -   If less than 0.05, we reject $H_0$
:::

## Notation

Hypothesis testing with Proportions

$$
H_1: p = 0.82 \\
H_A: p \ne 0.82
$$

Null and Alternative hypotheses.

We assume the null hypothesis is true and build a theoretical sampling distribution from that.

## The Central Limit Theorem

This is what allows us to build the sampling distribution.

> If we look at a proportion and the scenario satisfies certain conditions, then the distribution of sample proportions will appear to follow a bell-shaped curve called the *normal distribution*.

This is the point of the recent R Assignment. If we could sample repeatedly from a population, the shape from the statistics in those samples would be normal.

## Condition on $H_0$

Proportions:

-   Success Failure condition

    -   30 successes or $n(p_0) > 10$

    -   30 failures or $n(1-p_0) > 10$

-   Large Independent Samples (n\>30)

## Draw the Sampling Distribution

$$ p \sim N(p_0,SE)$$

With $$SE= \sqrt{\frac{p_0(1-p_0)}{n}}$$

## Conclusion

What is the probability of getting the $\hat{p}$ from our sample?

```{r}
#| eval: false
#| echo: true

pnorm(q = p-hat, mean = p, sd = SE )
```

## Practice 1. Exclusive relationships

Have a majority of college students had more than 1 `exclusive_relationship`?

```{r}
count(exclusive_relationship, num > 1)

```

-   Check Conditions.

-   Do the test with math.

-   Do the test with simulation.

## With math.

We are testing against 50%. We've already checked the conditions for the mathematical test. Now we:

1.  ~~Check conditions~~
2.  Write hypothesis notation.
3.  Write the notation for the distribution of sample proportions.
    i.  find the theoretical mean
    ii. find the standard error
4.  Find the probability we would get $\hat{p} = 152/203 = 0.749$ based on the null hypothesis.
5.  Make the conclusion.

## Hypothesis notation

$$
H_0: p = 0.5 \\
H_A: p > 0.5
$$

$$
\alpha = 0.05
$$

## Notation for the sampling distribution

We have $\mu =0.5$ We need to find the standard error.

$$
SE = \sqrt{\frac{(p)(1-p)}{n}}=\sqrt{\frac{(0.5)(0.5)}{203}} = 0.03509312
$$

$$
p \sim N(\mu = 0.5, SE = 0.035)
$$

## Probability of $\hat{p}$

If the distribution from the last slide is correct what is the probability we would find $\hat{p}=0.749$ from our sample.

```{r}
#| echo: true
normTail(m = 0.5, s = 0.03509312, U = 0.7487685)
pnorm(q = 0.7487685 , mean=0.5,sd = 0.03509312, lower.tail = FALSE)

```

## Conclusion

We get 6.763449e-13 (0.0000000000006), which is much smaller than 0.05. We reject the null hypothesis and state that its very likely that a majority of students have been in more than one exclusive relationship.

## Decision Error

We could have made a type 1 error, and rejected the null hypothesis if it were actually true.

More on decision errors later.

## Same problem with simulation.

1.  Make sample
2.  Write hypothesis notation.
3.  Create the simulated distribution.
4.  Find the probability we would get $\hat{p} = 152/203 = 0.749$ based on the null hypothesis.
5.  Make the conclusion.

## Make sample

```{r}
#| echo: true

# This creates a vector of 152 "Trues" and 51 "Falses"
more_than_1_relationship <- c(
  rep(TRUE, 152),
  rep(FALSE, 51)
) 

#This takes the vector and saves it as a data frame so we can us it. 
more_than_1_relationship <- as.data.frame(more_than_1_relationship)
```

## Hypothesis notation

This part is the same.

$$
H_0: p = 0.5 \\
H_A: p > 0.5
$$

$$
\alpha = 0.05
$$

## Side note the pipe \|\>

You may have noticed the occasional symbols `|>` or `%>%`.

This is called a pipe and it is an R operator that takes the output of the previous line of code and puts it into the first argument of the next line of code.

It often makes code easier to read, but can be confusing for first time programmers.

For this reason I have been avoiding it, until now.

## Create simulated distribution

```{r}
#| echo: true

library(infer)

# Saving all the proportions we'll make
null_distn_one_prop <- more_than_1_relationship  |>
  
  # Here we tell specify what is a success
  specify(response = more_than_1_relationship, success = "TRUE") |>
  
  # This is where we set the null hypothesis
  hypothesize(null = "point", p = 0.5) |>
  
  # Choosing 10000 replications
  generate(reps = 5000, type = "draw") |>
  
  # This is 
  calculate(stat = "prop")
```

## Examine the samples.

```{r}
#| echo: true

#visualize is a graphing function, based on ggplot, for the infer package. 

visualise(data = null_distn_one_prop)

```

## Calculate the p-value based on simulation

Visualize the pvalue

```{r}
#| echo: true

visualise(data = null_distn_one_prop) +
  shade_p_value(obs_stat = 0.749, direction = "greater")
```

## Calculate the p-value

```{r}
#| echo: true

get_p_value(x = null_distn_one_prop, 
            obs_stat = 0.749,
            direction = 'greater')
```

## Conclusion

The conclusion is the same. The pvalue is much smaller than 0.05 so it is likely that a majority of students have had more than 1 exclusive relationship.

## Mathematical vs. simulation

Both methods are valid and often end at the same conclusion

Math uses formula based on conditions which must be checked. A theoretical distribution is built and probabilities calculates.

Alternatively a simulated distribution is built, which makes a simulated sampling distribution which is very similar to the theoretical distribution, conditions can be relaxed because we can visibly verify that the distribution is normal.

## Homework

On your homework you will use the math formula to make a theoretical distribution and calculate probabilities.

## R Assignment

You will make a simulated distribution of your own and find pvalues in a future R Assignment.

We'll look at another example in the next video.
